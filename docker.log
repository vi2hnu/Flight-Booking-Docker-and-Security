Attaching to apigateway, authservice, bookingservice, configserver, emailservice, eureka, flightservice, kafkaQueue, redis, sql_db
eureka  | 
eureka  |   .   ____          _            __ _ _
eureka  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
eureka  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
eureka  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
eureka  |   '  |____| .__|_| |_|_| |_\__, | / / / /
eureka  |  =========|_|==============|___/=/_/_/_/
eureka  | 
eureka  |  :: Spring Boot ::                (v4.0.0)
eureka  | 
eureka  | 2025-12-08T17:07:53.658Z  INFO 1 --- [ServiceRegistry] [           main] o.e.s.ServiceRegistryApplication         : Starting ServiceRegistryApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/ServiceRegistry-0.0.1-SNAPSHOT.jar started by root in /app)
eureka  | 2025-12-08T17:07:53.663Z  INFO 1 --- [ServiceRegistry] [           main] o.e.s.ServiceRegistryApplication         : No active profile set, falling back to 1 default profile: "default"
eureka  | 2025-12-08T17:07:54.637Z  INFO 1 --- [ServiceRegistry] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=66c7ce29-e870-3c61-a4ed-996d3e0a2ece
eureka  | 2025-12-08T17:07:54.891Z  INFO 1 --- [ServiceRegistry] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8761 (http)
eureka  | 2025-12-08T17:07:54.902Z  INFO 1 --- [ServiceRegistry] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
eureka  | 2025-12-08T17:07:54.902Z  INFO 1 --- [ServiceRegistry] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
eureka  | 2025-12-08T17:07:54.920Z  INFO 1 --- [ServiceRegistry] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 1201 ms
eureka  | 2025-12-08T17:07:55.797Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
eureka  | 2025-12-08T17:07:55.797Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
eureka  | 2025-12-08T17:07:55.935Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
eureka  | 2025-12-08T17:07:55.935Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
eureka  | 2025-12-08T17:07:56.083Z  INFO 1 --- [ServiceRegistry] [           main] o.s.v.b.OptionalValidatorFactoryBean     : Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
eureka  | 2025-12-08T17:07:56.780Z  WARN 1 --- [ServiceRegistry] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
eureka  | 2025-12-08T17:07:56.810Z  INFO 1 --- [ServiceRegistry] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
eureka  | 2025-12-08T17:07:56.840Z  INFO 1 --- [ServiceRegistry] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
eureka  | 2025-12-08T17:07:56.841Z  INFO 1 --- [ServiceRegistry] [           main] com.netflix.discovery.DiscoveryClient    : Client configured to neither register nor query for data.
eureka  | 2025-12-08T17:07:56.843Z  INFO 1 --- [ServiceRegistry] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765213676842 with initial instances count: 0
eureka  | 2025-12-08T17:07:56.915Z  INFO 1 --- [ServiceRegistry] [           main] c.n.eureka.DefaultEurekaServerContext    : Initializing ...
eureka  | 2025-12-08T17:07:56.919Z  INFO 1 --- [ServiceRegistry] [           main] c.n.eureka.cluster.PeerEurekaNodes       : Adding new peer nodes [http://localhost:8761/eureka/]
eureka  | 2025-12-08T17:07:57.087Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
eureka  | 2025-12-08T17:07:57.087Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
eureka  | 2025-12-08T17:07:57.087Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
eureka  | 2025-12-08T17:07:57.087Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
eureka  | 2025-12-08T17:07:57.123Z  INFO 1 --- [ServiceRegistry] [           main] c.n.eureka.cluster.PeerEurekaNodes       : Replica node URL:  http://localhost:8761/eureka/
eureka  | 2025-12-08T17:07:57.134Z  INFO 1 --- [ServiceRegistry] [           main] c.n.e.registry.AbstractInstanceRegistry  : Finished initializing remote region registries. All known remote regions: []
eureka  | 2025-12-08T17:07:57.134Z  INFO 1 --- [ServiceRegistry] [           main] c.n.eureka.DefaultEurekaServerContext    : Initialized
eureka  | 2025-12-08T17:07:57.142Z  INFO 1 --- [ServiceRegistry] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 1 endpoint beneath base path '/actuator'
eureka  | 2025-12-08T17:07:57.190Z  INFO 1 --- [ServiceRegistry] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application SERVICEREGISTRY with eureka with status UP
eureka  | 2025-12-08T17:07:57.202Z  INFO 1 --- [ServiceRegistry] [       Thread-9] o.s.c.n.e.server.EurekaServerBootstrap   : isAws returned false
eureka  | 2025-12-08T17:07:57.202Z  INFO 1 --- [ServiceRegistry] [       Thread-9] o.s.c.n.e.server.EurekaServerBootstrap   : Initialized server context
eureka  | 2025-12-08T17:07:57.202Z  INFO 1 --- [ServiceRegistry] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Got 1 instances from neighboring DS node
eureka  | 2025-12-08T17:07:57.202Z  INFO 1 --- [ServiceRegistry] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Renew threshold is: 1
eureka  | 2025-12-08T17:07:57.203Z  INFO 1 --- [ServiceRegistry] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Changing status to UP
eureka  | 2025-12-08T17:07:57.205Z  INFO 1 --- [ServiceRegistry] [       Thread-9] e.s.EurekaServerInitializerConfiguration : Started Eureka Server
eureka  | 2025-12-08T17:07:57.211Z  INFO 1 --- [ServiceRegistry] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8761 (http) with context path '/'
eureka  | 2025-12-08T17:07:57.212Z  INFO 1 --- [ServiceRegistry] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8761
eureka  | 2025-12-08T17:07:57.222Z  INFO 1 --- [ServiceRegistry] [           main] o.e.s.ServiceRegistryApplication         : Started ServiceRegistryApplication in 3.939 seconds (process running for 4.546)
eureka  | 2025-12-08T17:07:57.753Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
eureka  | 2025-12-08T17:07:57.753Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
eureka  | 2025-12-08T17:07:57.755Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
configserver  | 
configserver  |   .   ____          _            __ _ _
configserver  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
configserver  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
configserver  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
configserver  |   '  |____| .__|_| |_|_| |_\__, | / / / /
configserver  |  =========|_|==============|___/=/_/_/_/
configserver  | 
configserver  |  :: Spring Boot ::                (v4.0.0)
configserver  | 
configserver  | 2025-12-08T17:07:59.099Z  INFO 1 --- [ConfigServer] [           main] o.e.c.ConfigServerApplication            : Starting ConfigServerApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/ConfigServer-0.0.1-SNAPSHOT.jar started by root in /app)
configserver  | 2025-12-08T17:07:59.101Z  INFO 1 --- [ConfigServer] [           main] o.e.c.ConfigServerApplication            : No active profile set, falling back to 1 default profile: "default"
configserver  | 2025-12-08T17:07:59.652Z  INFO 1 --- [ConfigServer] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=0cddbe66-053f-3dc9-884e-976511af59fa
configserver  | 2025-12-08T17:07:59.832Z  INFO 1 --- [ConfigServer] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8888 (http)
configserver  | 2025-12-08T17:07:59.840Z  INFO 1 --- [ConfigServer] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
configserver  | 2025-12-08T17:07:59.840Z  INFO 1 --- [ConfigServer] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
configserver  | 2025-12-08T17:07:59.854Z  INFO 1 --- [ConfigServer] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 708 ms
configserver  | 2025-12-08T17:08:00.430Z  INFO 1 --- [ConfigServer] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8888 (http) with context path '/'
configserver  | 2025-12-08T17:08:00.446Z  INFO 1 --- [ConfigServer] [           main] o.e.c.ConfigServerApplication            : Started ConfigServerApplication in 1.715 seconds (process running for 2.133)
configserver  | 2025-12-08T17:08:03.378Z  INFO 1 --- [ConfigServer] [nio-8888-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
configserver  | 2025-12-08T17:08:03.379Z  INFO 1 --- [ConfigServer] [nio-8888-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
configserver  | 2025-12-08T17:08:03.379Z  INFO 1 --- [ConfigServer] [nio-8888-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 0 ms
kafkaQueue    | ===> User
kafkaQueue    | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
kafkaQueue    | ===> Setting default values of environment variables if not already set.
kafkaQueue    | CLUSTER_ID not set. Setting it to default value: "5L6g3nShT-eMCtK--X86sw"
kafkaQueue    | ===> Configuring ...
kafkaQueue    | Running in KRaft mode...
kafkaQueue    | ===> Launching ... 
kafkaQueue    | ===> Using provided cluster id 5L6g3nShT-eMCtK--X86sw ...
redis         | Starting Redis Server
redis         | 1:C 08 Dec 2025 17:08:19.627 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
redis         | 1:C 08 Dec 2025 17:08:19.627 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
redis         | 1:C 08 Dec 2025 17:08:19.627 * Redis version=8.4.0, bits=64, commit=00000000, modified=1, pid=1, just started
redis         | 1:C 08 Dec 2025 17:08:19.627 * Configuration loaded
redis         | 1:M 08 Dec 2025 17:08:19.627 * Increased maximum number of open files to 10032 (it was originally set to 1024).
redis         | 1:M 08 Dec 2025 17:08:19.627 * monotonic clock: POSIX clock_gettime
redis         | 1:M 08 Dec 2025 17:08:19.628 * Running mode=standalone, port=6379.
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> RedisBloom version 8.4.0 (Git=unknown)
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> Registering configuration options: [
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> 	{ bf-error-rate       :      0.01 }
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> 	{ bf-initial-size     :       100 }
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> 	{ bf-expansion-factor :         2 }
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> 	{ cf-bucket-size      :         2 }
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> 	{ cf-initial-size     :      1024 }
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> 	{ cf-max-iterations   :        20 }
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> 	{ cf-expansion-factor :         1 }
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> 	{ cf-max-expansions   :        32 }
redis         | 1:M 08 Dec 2025 17:08:19.629 * <bf> ]
redis         | 1:M 08 Dec 2025 17:08:19.629 * Module 'bf' loaded from /usr/local/lib/redis/modules//redisbloom.so
redis         | 1:M 08 Dec 2025 17:08:19.638 * <search> Redis version found by RedisSearch : 8.4.0 - oss
redis         | 1:M 08 Dec 2025 17:08:19.638 * <search> RediSearch version 8.4.2 (Git=9e2b676)
redis         | 1:M 08 Dec 2025 17:08:19.638 * <search> Low level api version 1 initialized successfully
redis         | 1:M 08 Dec 2025 17:08:19.638 * <search> gc: ON, prefix min length: 2, min word length to stem: 4, prefix max expansions: 200, query timeout (ms): 500, timeout policy: return, oom policy: return, cursor read size: 1000, cursor max idle (ms): 300000, max doctable size: 1000000, max number of search results:  1000000, default scorer: BM25STD, 
redis         | 1:M 08 Dec 2025 17:08:19.638 * <search> Initialized thread pools!
redis         | 1:M 08 Dec 2025 17:08:19.638 * <search> Disabled workers threadpool of size 0
redis         | 1:M 08 Dec 2025 17:08:19.638 * <search> Subscribe to config changes
redis         | 1:M 08 Dec 2025 17:08:19.638 * <search> Subscribe to cluster slot migration events
redis         | 1:M 08 Dec 2025 17:08:19.638 * <search> Enabled role change notification
redis         | 1:M 08 Dec 2025 17:08:19.639 * <search> Cluster configuration: AUTO partitions, type: 0, coordinator timeout: 0ms
redis         | 1:M 08 Dec 2025 17:08:19.639 * <search> Register write commands
redis         | 1:M 08 Dec 2025 17:08:19.639 * Module 'search' loaded from /usr/local/lib/redis/modules//redisearch.so
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> RedisTimeSeries version 80400, git_sha=3520a1568ad69076d60885c70711fbdc9b448749
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> Redis version found by RedisTimeSeries : 8.4.0 - oss
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> Registering configuration options: [
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> 	{ ts-compaction-policy   :              }
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> 	{ ts-num-threads         :            3 }
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> 	{ ts-retention-policy    :            0 }
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> 	{ ts-duplicate-policy    :        block }
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> 	{ ts-chunk-size-bytes    :         4096 }
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> 	{ ts-encoding            :   compressed }
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> 	{ ts-ignore-max-time-diff:            0 }
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> 	{ ts-ignore-max-val-diff :     0.000000 }
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> ]
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> Detected redis oss
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> Subscribe to ASM events
redis         | 1:M 08 Dec 2025 17:08:19.641 * <timeseries> Enabled diskless replication
redis         | 1:M 08 Dec 2025 17:08:19.641 * Module 'timeseries' loaded from /usr/local/lib/redis/modules//redistimeseries.so
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> Created new data type 'ReJSON-RL'
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> version: 80400 git sha: unknown branch: unknown
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> Exported RedisJSON_V1 API
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> Exported RedisJSON_V2 API
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> Exported RedisJSON_V3 API
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> Exported RedisJSON_V4 API
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> Exported RedisJSON_V5 API
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> Exported RedisJSON_V6 API
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> Enabled diskless replication
redis         | 1:M 08 Dec 2025 17:08:19.645 * <ReJSON> Initialized shared string cache, thread safe: true.
redis         | 1:M 08 Dec 2025 17:08:19.645 * Module 'ReJSON' loaded from /usr/local/lib/redis/modules//rejson.so
redis         | 1:M 08 Dec 2025 17:08:19.645 * <search> Acquired RedisJSON_V6 API
redis         | 1:M 08 Dec 2025 17:08:19.645 * Server initialized
redis         | 1:M 08 Dec 2025 17:08:19.645 * Ready to accept connections tcp
sql_db        | SQL Server 2022 will run as non-root by default.
sql_db        | This container is running as user mssql.
sql_db        | Your master database file is owned by mssql.
sql_db        | To learn more visit https://go.microsoft.com/fwlink/?linkid=2099216.
kafkaQueue    | [2025-12-08 17:08:22,056] INFO Registered `kafka:type=kafka.Log4jController` MBean (kafka.utils.Log4jControllerRegistration$)
kafkaQueue    | [2025-12-08 17:08:22,281] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafkaQueue    | [2025-12-08 17:08:22,284] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
sql_db        | 2025-12-08 17:08:22.49 Server      Setup step is FORCE copying system data file 'C:\templatedata\model_replicatedmaster.mdf' to '/var/opt/mssql/data/model_replicatedmaster.mdf'.
sql_db        | 2025-12-08 17:08:22.52 Server      Setup step is FORCE copying system data file 'C:\templatedata\model_replicatedmaster.ldf' to '/var/opt/mssql/data/model_replicatedmaster.ldf'.
sql_db        | 2025-12-08 17:08:22.52 Server      Setup step is FORCE copying system data file 'C:\templatedata\model_msdbdata.mdf' to '/var/opt/mssql/data/model_msdbdata.mdf'.
sql_db        | 2025-12-08 17:08:22.54 Server      Setup step is FORCE copying system data file 'C:\templatedata\model_msdblog.ldf' to '/var/opt/mssql/data/model_msdblog.ldf'.
sql_db        | 2025-12-08 17:08:22.58 Server      Microsoft SQL Server 2022 (RTM-CU21) (KB5065865) - 16.0.4215.2 (X64) 
sql_db        | 	Aug 11 2025 13:24:21 
sql_db        | 	Copyright (C) 2022 Microsoft Corporation
sql_db        | 	Developer Edition (64-bit) on Linux (Ubuntu 22.04.5 LTS) <X64>
sql_db        | 2025-12-08 17:08:22.58 Server      UTC adjustment: 0:00
sql_db        | 2025-12-08 17:08:22.59 Server      (c) Microsoft Corporation.
sql_db        | 2025-12-08 17:08:22.59 Server      All rights reserved.
sql_db        | 2025-12-08 17:08:22.59 Server      Server process ID is 540.
sql_db        | 2025-12-08 17:08:22.59 Server      Logging SQL Server messages in file '/var/opt/mssql/log/errorlog'.
sql_db        | 2025-12-08 17:08:22.59 Server      Registry startup parameters: 
sql_db        | 	 -d /var/opt/mssql/data/master.mdf
sql_db        | 	 -l /var/opt/mssql/data/mastlog.ldf
sql_db        | 	 -e /var/opt/mssql/log/errorlog
sql_db        | 2025-12-08 17:08:22.59 Server      SQL Server detected 1 sockets with 8 cores per socket and 16 logical processors per socket, 16 total logical processors; using 16 logical processors based on SQL Server licensing. This is an informational message; no user action is required.
sql_db        | 2025-12-08 17:08:22.60 Server      SQL Server is starting at normal priority base (=7). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:22.60 Server      Detected 12518 MB of RAM, 4853 MB of available memory, 4853 MB of available page file. This is an informational message; no user action is required.
kafkaQueue    | [2025-12-08 17:08:22,613] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
sql_db        | 2025-12-08 17:08:22.61 Server      Using conventional memory in the memory manager.
sql_db        | 2025-12-08 17:08:22.61 Server      Detected pause instruction latency: 120 cycles.
sql_db        | 2025-12-08 17:08:22.61 Server      SQL Server detected the following NUMA node configuration (NUMA Node number 0, Processor Group number 0, CPU Mask 0x000000000000ffff).
kafkaQueue    | [2025-12-08 17:08:22,701] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
kafkaQueue    | [2025-12-08 17:08:22,707] INFO CONTROLLER: resolved wildcard host to abcee041bd95 (org.apache.kafka.metadata.ListenerInfo)
sql_db        | 2025-12-08 17:08:22.70 Server      Page exclusion bitmap is enabled.
kafkaQueue    | [2025-12-08 17:08:22,723] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafkaQueue    | [2025-12-08 17:08:22,727] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
kafkaQueue    | [2025-12-08 17:08:22,820] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2025-12-08 17:08:22,821] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2025-12-08 17:08:22,821] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
sql_db        | 2025-12-08 17:08:22.83 Server      Buffer pool extension is not supported on Linux platform.
kafkaQueue    | [2025-12-08 17:08:22,849] INFO Initialized snapshots with IDs SortedSet() from /tmp/kafka-logs/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
kafkaQueue    | [2025-12-08 17:08:22,858] INFO [raft-expiration-reaper]: Starting (org.apache.kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 17:08:22,863] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 17:08:22,865] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=kafkaQueue/172.20.0.4:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 17:08:22,868] INFO [RaftManager id=1] Starting request manager with static voters: [kafkaQueue:9093 (id: 1 rack: null isFenced: false)] (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 17:08:22,871] INFO [RaftManager id=1] Attempting durable transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1024, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
sql_db        | 2025-12-08 17:08:22.86 Server      Buffer Pool: Allocating 8388608 bytes for 769105 hashPages.
kafkaQueue    | [2025-12-08 17:08:22,884] INFO [RaftManager id=1] Completed transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1024, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 17:08:22,889] INFO [RaftManager id=1] Completed transition to ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1926, highWatermark=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1024, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 17:08:22,892] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=TRkAGGx19rpsp4EPMGfSQA, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1803) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1926, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 17:08:22,897] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=TRkAGGx19rpsp4EPMGfSQA, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1803) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1926, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 17:08:22,902] INFO [RaftManager id=1] Attempting durable transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=TRkAGGx19rpsp4EPMGfSQA), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=abcee041bd95/<unresolved>:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=TRkAGGx19rpsp4EPMGfSQA, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1803) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 17:08:22,915] INFO [RaftManager id=1] Completed transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=TRkAGGx19rpsp4EPMGfSQA), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=abcee041bd95/<unresolved>:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=TRkAGGx19rpsp4EPMGfSQA, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1803) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 17:08:22,945] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
kafkaQueue    | [2025-12-08 17:08:22,947] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
kafkaQueue    | [2025-12-08 17:08:22,961] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:22,963] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 17:08:22,964] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 17:08:22,971] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
kafkaQueue    | [2025-12-08 17:08:22,984] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@1044102576 (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 17:08:22,984] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@971672828 (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 17:08:22,987] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 17:08:22,987] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 17:08:22,988] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 17:08:22,990] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@1044102576 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 17:08:22,993] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@971672828 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 17:08:22,996] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,003] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 17:08:23,008] INFO [ExpirationReaper-1-AlterAcls]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 17:08:23,045] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 17:08:23,047] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 17:08:23,047] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 0, but the high water mark is 8 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,048] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafkaQueue    | [2025-12-08 17:08:23,049] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 8 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,052] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
kafkaQueue    | [2025-12-08 17:08:23,054] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,055] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,055] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,071] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 17:08:23,075] INFO [ControllerRegistrationManager id=1 incarnation=duELtEnWROq9okf74Dz_dw] initialized channel manager. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 17:08:23,076] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 17:08:23,076] INFO [ControllerRegistrationManager id=1 incarnation=duELtEnWROq9okf74Dz_dw] maybeSendControllerRegistration: cannot register yet because the metadata.version is not known yet. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 17:08:23,077] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 17:08:23,077] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 17:08:23,077] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 17:08:23,077] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
sql_db        | 2025-12-08 17:08:23.07 Server      Buffer pool extension is already disabled. No action is necessary.
kafkaQueue    | [2025-12-08 17:08:23,081] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,087] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,091] INFO [ControllerServer id=1] Loaded new metadata FinalizedFeatures[metadataVersion=4.1-IV1, finalizedFeatures={group.version=1, transaction.version=2, eligible.leader.replicas.version=1, metadata.version=27}, finalizedFeaturesEpoch=7]. (org.apache.kafka.metadata.publisher.FeaturesPublisher)
kafkaQueue    | [2025-12-08 17:08:23,091] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,092] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,092] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,095] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 17:08:23,096] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 17:08:23,097] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 17:08:23,098] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 17:08:23,109] INFO [DynamicConfigPublisher controller id=1] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafkaQueue    | [2025-12-08 17:08:23,115] INFO [ControllerRegistrationManager id=1 incarnation=duELtEnWROq9okf74Dz_dw] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=duELtEnWROq9okf74Dz_dw, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='abcee041bd95', port=9093, securityProtocol=0)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=27), Feature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1)]) (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 17:08:23,127] INFO KafkaConfig values: 
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.ms = 20
kafkaQueue    | 	advertised.listeners = PLAINTEXT://kafkaQueue:9092
kafkaQueue    | 	alter.config.policy.class.name = null
kafkaQueue    | 	alter.log.dirs.replication.quota.window.num = 11
kafkaQueue    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafkaQueue    | 	authorizer.class.name = 
kafkaQueue    | 	auto.create.topics.enable = true
kafkaQueue    | 	auto.leader.rebalance.enable = true
kafkaQueue    | 	background.threads = 10
kafkaQueue    | 	broker.heartbeat.interval.ms = 2000
kafkaQueue    | 	broker.id = 1
kafkaQueue    | 	broker.rack = null
kafkaQueue    | 	broker.session.timeout.ms = 9000
kafkaQueue    | 	client.quota.callback.class = null
kafkaQueue    | 	compression.gzip.level = -1
kafkaQueue    | 	compression.lz4.level = 9
kafkaQueue    | 	compression.type = producer
kafkaQueue    | 	compression.zstd.level = 3
kafkaQueue    | 	connection.failed.authentication.delay.ms = 100
kafkaQueue    | 	connections.max.idle.ms = 600000
kafkaQueue    | 	connections.max.reauth.ms = 0
kafkaQueue    | 	controlled.shutdown.enable = true
kafkaQueue    | 	controller.listener.names = CONTROLLER
kafkaQueue    | 	controller.performance.always.log.threshold.ms = 2000
kafkaQueue    | 	controller.performance.sample.period.ms = 60000
kafkaQueue    | 	controller.quorum.append.linger.ms = 25
kafkaQueue    | 	controller.quorum.bootstrap.servers = []
kafkaQueue    | 	controller.quorum.election.backoff.max.ms = 1000
kafkaQueue    | 	controller.quorum.election.timeout.ms = 1000
kafkaQueue    | 	controller.quorum.fetch.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.request.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.retry.backoff.ms = 20
kafkaQueue    | 	controller.quorum.voters = [1@kafkaQueue:9093]
kafkaQueue    | 	controller.quota.window.num = 11
kafkaQueue    | 	controller.quota.window.size.seconds = 1
kafkaQueue    | 	controller.socket.timeout.ms = 30000
kafkaQueue    | 	create.topic.policy.class.name = null
kafkaQueue    | 	default.replication.factor = 1
kafkaQueue    | 	delegation.token.expiry.check.interval.ms = 3600000
kafkaQueue    | 	delegation.token.expiry.time.ms = 86400000
kafkaQueue    | 	delegation.token.max.lifetime.ms = 604800000
kafkaQueue    | 	delegation.token.secret.key = null
kafkaQueue    | 	delete.records.purgatory.purge.interval.requests = 1
kafkaQueue    | 	delete.topic.enable = true
kafkaQueue    | 	early.start.listeners = null
kafkaQueue    | 	fetch.max.bytes = 57671680
kafkaQueue    | 	fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	group.consumer.assignors = [uniform, range]
kafkaQueue    | 	group.consumer.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.consumer.max.session.timeout.ms = 60000
kafkaQueue    | 	group.consumer.max.size = 2147483647
kafkaQueue    | 	group.consumer.migration.policy = bidirectional
kafkaQueue    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.min.session.timeout.ms = 45000
kafkaQueue    | 	group.consumer.regex.refresh.interval.ms = 600000
kafkaQueue    | 	group.consumer.session.timeout.ms = 45000
kafkaQueue    | 	group.coordinator.append.linger.ms = 5
kafkaQueue    | 	group.coordinator.rebalance.protocols = [classic, consumer, streams]
kafkaQueue    | 	group.coordinator.threads = 4
kafkaQueue    | 	group.initial.rebalance.delay.ms = 3000
kafkaQueue    | 	group.max.session.timeout.ms = 1800000
kafkaQueue    | 	group.max.size = 2147483647
kafkaQueue    | 	group.min.session.timeout.ms = 6000
kafkaQueue    | 	group.share.assignors = [simple]
kafkaQueue    | 	group.share.delivery.count.limit = 5
kafkaQueue    | 	group.share.enable = false
kafkaQueue    | 	group.share.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.share.max.record.lock.duration.ms = 60000
kafkaQueue    | 	group.share.max.session.timeout.ms = 60000
kafkaQueue    | 	group.share.max.share.sessions = 2000
kafkaQueue    | 	group.share.max.size = 200
kafkaQueue    | 	group.share.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.min.record.lock.duration.ms = 15000
kafkaQueue    | 	group.share.min.session.timeout.ms = 45000
kafkaQueue    | 	group.share.partition.max.record.locks = 2000
kafkaQueue    | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafkaQueue    | 	group.share.record.lock.duration.ms = 30000
kafkaQueue    | 	group.share.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.streams.max.session.timeout.ms = 60000
kafkaQueue    | 	group.streams.max.size = 2147483647
kafkaQueue    | 	group.streams.max.standby.replicas = 2
kafkaQueue    | 	group.streams.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.min.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.num.standby.replicas = 0
kafkaQueue    | 	group.streams.session.timeout.ms = 45000
kafkaQueue    | 	initial.broker.registration.timeout.ms = 60000
kafkaQueue    | 	inter.broker.listener.name = null
kafkaQueue    | 	internal.metadata.delete.delay.millis = 60000
kafkaQueue    | 	internal.metadata.log.segment.bytes = null
kafkaQueue    | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafkaQueue    | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafkaQueue    | 	kafka.metrics.polling.interval.secs = 10
kafkaQueue    | 	kafka.metrics.reporters = []
kafkaQueue    | 	leader.imbalance.check.interval.seconds = 300
kafkaQueue    | 	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
kafkaQueue    | 	listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
kafkaQueue    | 	log.cleaner.backoff.ms = 15000
kafkaQueue    | 	log.cleaner.dedupe.buffer.size = 134217728
kafkaQueue    | 	log.cleaner.delete.retention.ms = 86400000
kafkaQueue    | 	log.cleaner.enable = true
kafkaQueue    | 	log.cleaner.io.buffer.load.factor = 0.9
kafkaQueue    | 	log.cleaner.io.buffer.size = 524288
kafkaQueue    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafkaQueue    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafkaQueue    | 	log.cleaner.min.cleanable.ratio = 0.5
kafkaQueue    | 	log.cleaner.min.compaction.lag.ms = 0
kafkaQueue    | 	log.cleaner.threads = 1
kafkaQueue    | 	log.cleanup.policy = [delete]
kafkaQueue    | 	log.dir = /tmp/kafka-logs
kafkaQueue    | 	log.dir.failure.timeout.ms = 30000
kafkaQueue    | 	log.dirs = null
kafkaQueue    | 	log.flush.interval.messages = 9223372036854775807
kafkaQueue    | 	log.flush.interval.ms = null
kafkaQueue    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafkaQueue    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.index.interval.bytes = 4096
kafkaQueue    | 	log.index.size.max.bytes = 10485760
kafkaQueue    | 	log.initial.task.delay.ms = 30000
kafkaQueue    | 	log.local.retention.bytes = -2
kafkaQueue    | 	log.local.retention.ms = -2
kafkaQueue    | 	log.message.timestamp.after.max.ms = 3600000
kafkaQueue    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafkaQueue    | 	log.message.timestamp.type = CreateTime
kafkaQueue    | 	log.preallocate = false
kafkaQueue    | 	log.retention.bytes = -1
kafkaQueue    | 	log.retention.check.interval.ms = 300000
kafkaQueue    | 	log.retention.hours = 168
kafkaQueue    | 	log.retention.minutes = null
kafkaQueue    | 	log.retention.ms = null
kafkaQueue    | 	log.roll.hours = 168
kafkaQueue    | 	log.roll.jitter.hours = 0
kafkaQueue    | 	log.roll.jitter.ms = null
kafkaQueue    | 	log.roll.ms = null
kafkaQueue    | 	log.segment.bytes = 1073741824
kafkaQueue    | 	log.segment.delete.delay.ms = 60000
kafkaQueue    | 	max.connection.creation.rate = 2147483647
kafkaQueue    | 	max.connections = 2147483647
kafkaQueue    | 	max.connections.per.ip = 2147483647
kafkaQueue    | 	max.connections.per.ip.overrides = 
kafkaQueue    | 	max.incremental.fetch.session.cache.slots = 1000
kafkaQueue    | 	max.request.partition.size.limit = 2000
kafkaQueue    | 	message.max.bytes = 1048588
kafkaQueue    | 	metadata.log.dir = null
kafkaQueue    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafkaQueue    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafkaQueue    | 	metadata.log.segment.bytes = 1073741824
kafkaQueue    | 	metadata.log.segment.ms = 604800000
kafkaQueue    | 	metadata.max.idle.interval.ms = 500
kafkaQueue    | 	metadata.max.retention.bytes = 104857600
kafkaQueue    | 	metadata.max.retention.ms = 604800000
kafkaQueue    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafkaQueue    | 	metrics.num.samples = 2
kafkaQueue    | 	metrics.recording.level = INFO
kafkaQueue    | 	metrics.sample.window.ms = 30000
kafkaQueue    | 	min.insync.replicas = 1
kafkaQueue    | 	node.id = 1
kafkaQueue    | 	num.io.threads = 8
kafkaQueue    | 	num.network.threads = 3
kafkaQueue    | 	num.partitions = 1
kafkaQueue    | 	num.recovery.threads.per.data.dir = 2
kafkaQueue    | 	num.replica.alter.log.dirs.threads = null
kafkaQueue    | 	num.replica.fetchers = 1
kafkaQueue    | 	offset.metadata.max.bytes = 4096
kafkaQueue    | 	offsets.commit.timeout.ms = 5000
kafkaQueue    | 	offsets.load.buffer.size = 5242880
kafkaQueue    | 	offsets.retention.check.interval.ms = 600000
kafkaQueue    | 	offsets.retention.minutes = 10080
kafkaQueue    | 	offsets.topic.compression.codec = 0
kafkaQueue    | 	offsets.topic.num.partitions = 50
kafkaQueue    | 	offsets.topic.replication.factor = 1
kafkaQueue    | 	offsets.topic.segment.bytes = 104857600
kafkaQueue    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafkaQueue    | 	process.roles = [broker, controller]
kafkaQueue    | 	producer.id.expiration.check.interval.ms = 600000
kafkaQueue    | 	producer.id.expiration.ms = 86400000
kafkaQueue    | 	producer.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	queued.max.request.bytes = -1
kafkaQueue    | 	queued.max.requests = 500
kafkaQueue    | 	quota.window.num = 11
kafkaQueue    | 	quota.window.size.seconds = 1
kafkaQueue    | 	remote.fetch.max.wait.ms = 500
kafkaQueue    | 	remote.list.offsets.request.timeout.ms = 30000
kafkaQueue    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafkaQueue    | 	remote.log.manager.copier.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.copy.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.expiration.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.fetch.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.task.interval.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.ms = 500
kafkaQueue    | 	remote.log.manager.task.retry.jitter = 0.2
kafkaQueue    | 	remote.log.manager.thread.pool.size = 2
kafkaQueue    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafkaQueue    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafkaQueue    | 	remote.log.metadata.manager.class.path = null
kafkaQueue    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafkaQueue    | 	remote.log.metadata.manager.listener.name = null
kafkaQueue    | 	remote.log.reader.max.pending.tasks = 100
kafkaQueue    | 	remote.log.reader.threads = 10
kafkaQueue    | 	remote.log.storage.manager.class.name = null
kafkaQueue    | 	remote.log.storage.manager.class.path = null
kafkaQueue    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafkaQueue    | 	remote.log.storage.system.enable = false
kafkaQueue    | 	replica.fetch.backoff.ms = 1000
kafkaQueue    | 	replica.fetch.max.bytes = 1048576
kafkaQueue    | 	replica.fetch.min.bytes = 1
kafkaQueue    | 	replica.fetch.response.max.bytes = 10485760
kafkaQueue    | 	replica.fetch.wait.max.ms = 500
kafkaQueue    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafkaQueue    | 	replica.lag.time.max.ms = 30000
kafkaQueue    | 	replica.selector.class = null
kafkaQueue    | 	replica.socket.receive.buffer.bytes = 65536
kafkaQueue    | 	replica.socket.timeout.ms = 30000
kafkaQueue    | 	replication.quota.window.num = 11
kafkaQueue    | 	replication.quota.window.size.seconds = 1
kafkaQueue    | 	request.timeout.ms = 30000
kafkaQueue    | 	sasl.client.callback.handler.class = null
kafkaQueue    | 	sasl.enabled.mechanisms = [GSSAPI]
kafkaQueue    | 	sasl.jaas.config = null
kafkaQueue    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafkaQueue    | 	sasl.kerberos.min.time.before.relogin = 60000
kafkaQueue    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafkaQueue    | 	sasl.kerberos.service.name = null
kafkaQueue    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafkaQueue    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafkaQueue    | 	sasl.login.callback.handler.class = null
kafkaQueue    | 	sasl.login.class = null
kafkaQueue    | 	sasl.login.connect.timeout.ms = null
kafkaQueue    | 	sasl.login.read.timeout.ms = null
kafkaQueue    | 	sasl.login.refresh.buffer.seconds = 300
kafkaQueue    | 	sasl.login.refresh.min.period.seconds = 60
kafkaQueue    | 	sasl.login.refresh.window.factor = 0.8
kafkaQueue    | 	sasl.login.refresh.window.jitter = 0.05
kafkaQueue    | 	sasl.login.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.login.retry.backoff.ms = 100
kafkaQueue    | 	sasl.mechanism.controller.protocol = GSSAPI
kafkaQueue    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafkaQueue    | 	sasl.oauthbearer.assertion.algorithm = RS256
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.aud = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.iss = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.sub = null
kafkaQueue    | 	sasl.oauthbearer.assertion.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafkaQueue    | 	sasl.oauthbearer.assertion.template.file = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.id = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.secret = null
kafkaQueue    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafkaQueue    | 	sasl.oauthbearer.expected.audience = null
kafkaQueue    | 	sasl.oauthbearer.expected.issuer = null
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafkaQueue    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafkaQueue    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafkaQueue    | 	sasl.oauthbearer.scope = null
kafkaQueue    | 	sasl.oauthbearer.scope.claim.name = scope
kafkaQueue    | 	sasl.oauthbearer.sub.claim.name = sub
kafkaQueue    | 	sasl.oauthbearer.token.endpoint.url = null
kafkaQueue    | 	sasl.server.callback.handler.class = null
kafkaQueue    | 	sasl.server.max.receive.size = 524288
kafkaQueue    | 	security.inter.broker.protocol = PLAINTEXT
kafkaQueue    | 	security.providers = null
kafkaQueue    | 	server.max.startup.time.ms = 9223372036854775807
kafkaQueue    | 	share.coordinator.append.linger.ms = 5
kafkaQueue    | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafkaQueue    | 	share.coordinator.load.buffer.size = 5242880
kafkaQueue    | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafkaQueue    | 	share.coordinator.state.topic.compression.codec = 0
kafkaQueue    | 	share.coordinator.state.topic.min.isr = 2
kafkaQueue    | 	share.coordinator.state.topic.num.partitions = 50
kafkaQueue    | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafkaQueue    | 	share.coordinator.state.topic.replication.factor = 3
kafkaQueue    | 	share.coordinator.state.topic.segment.bytes = 104857600
kafkaQueue    | 	share.coordinator.threads = 1
kafkaQueue    | 	share.coordinator.write.timeout.ms = 5000
kafkaQueue    | 	share.fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	socket.connection.setup.timeout.max.ms = 30000
kafkaQueue    | 	socket.connection.setup.timeout.ms = 10000
kafkaQueue    | 	socket.listen.backlog.size = 50
kafkaQueue    | 	socket.receive.buffer.bytes = 102400
kafkaQueue    | 	socket.request.max.bytes = 104857600
kafkaQueue    | 	socket.send.buffer.bytes = 102400
kafkaQueue    | 	ssl.allow.dn.changes = false
kafkaQueue    | 	ssl.allow.san.changes = false
kafkaQueue    | 	ssl.cipher.suites = []
kafkaQueue    | 	ssl.client.auth = none
kafkaQueue    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafkaQueue    | 	ssl.endpoint.identification.algorithm = https
kafkaQueue    | 	ssl.engine.factory.class = null
kafkaQueue    | 	ssl.key.password = null
kafkaQueue    | 	ssl.keymanager.algorithm = SunX509
kafkaQueue    | 	ssl.keystore.certificate.chain = null
kafkaQueue    | 	ssl.keystore.key = null
kafkaQueue    | 	ssl.keystore.location = null
kafkaQueue    | 	ssl.keystore.password = null
kafkaQueue    | 	ssl.keystore.type = JKS
kafkaQueue    | 	ssl.principal.mapping.rules = DEFAULT
kafkaQueue    | 	ssl.protocol = TLSv1.3
kafkaQueue    | 	ssl.provider = null
kafkaQueue    | 	ssl.secure.random.implementation = null
kafkaQueue    | 	ssl.trustmanager.algorithm = PKIX
kafkaQueue    | 	ssl.truststore.certificates = null
kafkaQueue    | 	ssl.truststore.location = null
kafkaQueue    | 	ssl.truststore.password = null
kafkaQueue    | 	ssl.truststore.type = JKS
kafkaQueue    | 	telemetry.max.bytes = 1048576
kafkaQueue    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafkaQueue    | 	transaction.max.timeout.ms = 900000
kafkaQueue    | 	transaction.partition.verification.enable = true
kafkaQueue    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafkaQueue    | 	transaction.state.log.load.buffer.size = 5242880
kafkaQueue    | 	transaction.state.log.min.isr = 1
kafkaQueue    | 	transaction.state.log.num.partitions = 50
kafkaQueue    | 	transaction.state.log.replication.factor = 1
kafkaQueue    | 	transaction.state.log.segment.bytes = 104857600
kafkaQueue    | 	transaction.two.phase.commit.enable = false
kafkaQueue    | 	transactional.id.expiration.ms = 604800000
kafkaQueue    | 	unclean.leader.election.enable = false
kafkaQueue    | 	unclean.leader.election.interval.ms = 300000
kafkaQueue    | 	unstable.api.versions.enable = false
kafkaQueue    | 	unstable.feature.versions.enable = false
kafkaQueue    |  (org.apache.kafka.common.config.AbstractConfig)
kafkaQueue    | [2025-12-08 17:08:23,136] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,136] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,141] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 17:08:23,142] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 17:08:23,155] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 17:08:23,192] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,196] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicTopicClusterQuotaPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,197] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,199] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,211] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,212] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,221] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafkaQueue    | [2025-12-08 17:08:23,230] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafkaQueue    | [2025-12-08 17:08:23,233] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 17:08:23,234] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 17:08:23,242] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 17:08:23,243] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 17:08:23,253] INFO [ControllerRegistrationManager id=1 incarnation=duELtEnWROq9okf74Dz_dw] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 17:08:23,255] INFO [ExpirationReaper-1-Produce]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 17:08:23,256] INFO [ExpirationReaper-1-Fetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 17:08:23,257] INFO [ExpirationReaper-1-DeleteRecords]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 17:08:23,260] INFO [ExpirationReaper-1-RemoteFetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 17:08:23,260] INFO [ExpirationReaper-1-RemoteListOffsets]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 17:08:23,262] INFO [ExpirationReaper-1-ShareFetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 17:08:23,263] INFO [ControllerRegistrationManager id=1 incarnation=duELtEnWROq9okf74Dz_dw] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 17:08:23,281] INFO [share-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 17:08:23,294] INFO [share-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 17:08:23,298] INFO [persister-state-manager-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 17:08:23,298] INFO [PersisterStateManager]: Starting (org.apache.kafka.server.share.persister.PersisterStateManager$SendThread)
kafkaQueue    | [2025-12-08 17:08:23,300] INFO [group-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 17:08:23,305] INFO [group-coordinator-event-processor-1]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 17:08:23,305] INFO [group-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 17:08:23,305] INFO [group-coordinator-event-processor-2]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 17:08:23,307] INFO [group-coordinator-event-processor-3]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 17:08:23,321] INFO Unable to read the broker epoch in /tmp/kafka-logs. (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 17:08:23,322] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 17:08:23,323] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 17:08:23,327] INFO [BrokerLifecycleManager id=1] Incarnation _mXaN-OERQG2fLohyERzfg of broker 1 in cluster 5L6g3nShT-eMCtK--X86sw is now STARTING. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2025-12-08 17:08:23,330] INFO [share-group-lock-timeout-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 17:08:23,334] INFO [ExpirationReaper-1-AlterAcls]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 17:08:23,352] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,353] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,353] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,353] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,354] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,357] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch[offset=8, epoch=1] with metadata.version Optional[4.1-IV1]. (kafka.server.metadata.BrokerMetadataPublisher)
kafkaQueue    | [2025-12-08 17:08:23,359] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 17:08:23,364] INFO No logs found to be loaded in /tmp/kafka-logs (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 17:08:23,378] INFO Loaded 0 logs in 15ms (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 17:08:23,379] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 17:08:23,382] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 17:08:23,394] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 9 (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2025-12-08 17:08:23,472] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafkaQueue    | [2025-12-08 17:08:23,473] INFO [AddPartitionsToTxnSenderThread-1]: Starting (org.apache.kafka.server.transaction.AddPartitionsToTxnManager)
kafkaQueue    | [2025-12-08 17:08:23,474] INFO [GroupCoordinator id=1] Starting up. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
kafkaQueue    | [2025-12-08 17:08:23,476] INFO [GroupCoordinator id=1] Startup complete. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
kafkaQueue    | [2025-12-08 17:08:23,478] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafkaQueue    | [2025-12-08 17:08:23,482] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafkaQueue    | [2025-12-08 17:08:23,485] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafkaQueue    | [2025-12-08 17:08:23,487] INFO [ShareCoordinator id=1] Starting up. (org.apache.kafka.coordinator.share.ShareCoordinatorService)
kafkaQueue    | [2025-12-08 17:08:23,489] INFO [ShareCoordinator id=1] Startup complete. (org.apache.kafka.coordinator.share.ShareCoordinatorService)
kafkaQueue    | [2025-12-08 17:08:23,498] INFO [DynamicConfigPublisher broker id=1] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafkaQueue    | [2025-12-08 17:08:23,500] INFO KafkaConfig values: 
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.ms = 20
kafkaQueue    | 	advertised.listeners = PLAINTEXT://kafkaQueue:9092
kafkaQueue    | 	alter.config.policy.class.name = null
kafkaQueue    | 	alter.log.dirs.replication.quota.window.num = 11
kafkaQueue    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafkaQueue    | 	authorizer.class.name = 
kafkaQueue    | 	auto.create.topics.enable = true
kafkaQueue    | 	auto.leader.rebalance.enable = true
kafkaQueue    | 	background.threads = 10
kafkaQueue    | 	broker.heartbeat.interval.ms = 2000
kafkaQueue    | 	broker.id = 1
kafkaQueue    | 	broker.rack = null
kafkaQueue    | 	broker.session.timeout.ms = 9000
kafkaQueue    | 	client.quota.callback.class = null
kafkaQueue    | 	compression.gzip.level = -1
kafkaQueue    | 	compression.lz4.level = 9
kafkaQueue    | 	compression.type = producer
kafkaQueue    | 	compression.zstd.level = 3
kafkaQueue    | 	connection.failed.authentication.delay.ms = 100
kafkaQueue    | 	connections.max.idle.ms = 600000
kafkaQueue    | 	connections.max.reauth.ms = 0
kafkaQueue    | 	controlled.shutdown.enable = true
kafkaQueue    | 	controller.listener.names = CONTROLLER
kafkaQueue    | 	controller.performance.always.log.threshold.ms = 2000
kafkaQueue    | 	controller.performance.sample.period.ms = 60000
kafkaQueue    | 	controller.quorum.append.linger.ms = 25
kafkaQueue    | 	controller.quorum.bootstrap.servers = []
kafkaQueue    | 	controller.quorum.election.backoff.max.ms = 1000
kafkaQueue    | 	controller.quorum.election.timeout.ms = 1000
kafkaQueue    | 	controller.quorum.fetch.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.request.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.retry.backoff.ms = 20
kafkaQueue    | 	controller.quorum.voters = [1@kafkaQueue:9093]
kafkaQueue    | 	controller.quota.window.num = 11
kafkaQueue    | 	controller.quota.window.size.seconds = 1
kafkaQueue    | 	controller.socket.timeout.ms = 30000
kafkaQueue    | 	create.topic.policy.class.name = null
kafkaQueue    | 	default.replication.factor = 1
kafkaQueue    | 	delegation.token.expiry.check.interval.ms = 3600000
kafkaQueue    | 	delegation.token.expiry.time.ms = 86400000
kafkaQueue    | 	delegation.token.max.lifetime.ms = 604800000
kafkaQueue    | 	delegation.token.secret.key = null
kafkaQueue    | 	delete.records.purgatory.purge.interval.requests = 1
kafkaQueue    | 	delete.topic.enable = true
kafkaQueue    | 	early.start.listeners = null
kafkaQueue    | 	fetch.max.bytes = 57671680
kafkaQueue    | 	fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	group.consumer.assignors = [uniform, range]
kafkaQueue    | 	group.consumer.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.consumer.max.session.timeout.ms = 60000
kafkaQueue    | 	group.consumer.max.size = 2147483647
kafkaQueue    | 	group.consumer.migration.policy = bidirectional
kafkaQueue    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.min.session.timeout.ms = 45000
kafkaQueue    | 	group.consumer.regex.refresh.interval.ms = 600000
kafkaQueue    | 	group.consumer.session.timeout.ms = 45000
kafkaQueue    | 	group.coordinator.append.linger.ms = 5
kafkaQueue    | 	group.coordinator.rebalance.protocols = [classic, consumer, streams]
kafkaQueue    | 	group.coordinator.threads = 4
kafkaQueue    | 	group.initial.rebalance.delay.ms = 3000
kafkaQueue    | 	group.max.session.timeout.ms = 1800000
kafkaQueue    | 	group.max.size = 2147483647
kafkaQueue    | 	group.min.session.timeout.ms = 6000
kafkaQueue    | 	group.share.assignors = [simple]
kafkaQueue    | 	group.share.delivery.count.limit = 5
kafkaQueue    | 	group.share.enable = false
kafkaQueue    | 	group.share.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.share.max.record.lock.duration.ms = 60000
kafkaQueue    | 	group.share.max.session.timeout.ms = 60000
kafkaQueue    | 	group.share.max.share.sessions = 2000
kafkaQueue    | 	group.share.max.size = 200
kafkaQueue    | 	group.share.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.min.record.lock.duration.ms = 15000
kafkaQueue    | 	group.share.min.session.timeout.ms = 45000
kafkaQueue    | 	group.share.partition.max.record.locks = 2000
kafkaQueue    | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafkaQueue    | 	group.share.record.lock.duration.ms = 30000
kafkaQueue    | 	group.share.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.streams.max.session.timeout.ms = 60000
kafkaQueue    | 	group.streams.max.size = 2147483647
kafkaQueue    | 	group.streams.max.standby.replicas = 2
kafkaQueue    | 	group.streams.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.min.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.num.standby.replicas = 0
kafkaQueue    | 	group.streams.session.timeout.ms = 45000
kafkaQueue    | 	initial.broker.registration.timeout.ms = 60000
kafkaQueue    | 	inter.broker.listener.name = null
kafkaQueue    | 	internal.metadata.delete.delay.millis = 60000
kafkaQueue    | 	internal.metadata.log.segment.bytes = null
kafkaQueue    | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafkaQueue    | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafkaQueue    | 	kafka.metrics.polling.interval.secs = 10
kafkaQueue    | 	kafka.metrics.reporters = []
kafkaQueue    | 	leader.imbalance.check.interval.seconds = 300
kafkaQueue    | 	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
kafkaQueue    | 	listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
kafkaQueue    | 	log.cleaner.backoff.ms = 15000
kafkaQueue    | 	log.cleaner.dedupe.buffer.size = 134217728
kafkaQueue    | 	log.cleaner.delete.retention.ms = 86400000
kafkaQueue    | 	log.cleaner.enable = true
kafkaQueue    | 	log.cleaner.io.buffer.load.factor = 0.9
kafkaQueue    | 	log.cleaner.io.buffer.size = 524288
kafkaQueue    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafkaQueue    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafkaQueue    | 	log.cleaner.min.cleanable.ratio = 0.5
kafkaQueue    | 	log.cleaner.min.compaction.lag.ms = 0
kafkaQueue    | 	log.cleaner.threads = 1
kafkaQueue    | 	log.cleanup.policy = [delete]
kafkaQueue    | 	log.dir = /tmp/kafka-logs
kafkaQueue    | 	log.dir.failure.timeout.ms = 30000
kafkaQueue    | 	log.dirs = null
kafkaQueue    | 	log.flush.interval.messages = 9223372036854775807
kafkaQueue    | 	log.flush.interval.ms = null
kafkaQueue    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafkaQueue    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.index.interval.bytes = 4096
kafkaQueue    | 	log.index.size.max.bytes = 10485760
kafkaQueue    | 	log.initial.task.delay.ms = 30000
kafkaQueue    | 	log.local.retention.bytes = -2
kafkaQueue    | 	log.local.retention.ms = -2
kafkaQueue    | 	log.message.timestamp.after.max.ms = 3600000
kafkaQueue    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafkaQueue    | 	log.message.timestamp.type = CreateTime
kafkaQueue    | 	log.preallocate = false
kafkaQueue    | 	log.retention.bytes = -1
kafkaQueue    | 	log.retention.check.interval.ms = 300000
kafkaQueue    | 	log.retention.hours = 168
kafkaQueue    | 	log.retention.minutes = null
kafkaQueue    | 	log.retention.ms = null
kafkaQueue    | 	log.roll.hours = 168
kafkaQueue    | 	log.roll.jitter.hours = 0
kafkaQueue    | 	log.roll.jitter.ms = null
kafkaQueue    | 	log.roll.ms = null
kafkaQueue    | 	log.segment.bytes = 1073741824
kafkaQueue    | 	log.segment.delete.delay.ms = 60000
kafkaQueue    | 	max.connection.creation.rate = 2147483647
kafkaQueue    | 	max.connections = 2147483647
kafkaQueue    | 	max.connections.per.ip = 2147483647
kafkaQueue    | 	max.connections.per.ip.overrides = 
kafkaQueue    | 	max.incremental.fetch.session.cache.slots = 1000
kafkaQueue    | 	max.request.partition.size.limit = 2000
kafkaQueue    | 	message.max.bytes = 1048588
kafkaQueue    | 	metadata.log.dir = null
kafkaQueue    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafkaQueue    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafkaQueue    | 	metadata.log.segment.bytes = 1073741824
kafkaQueue    | 	metadata.log.segment.ms = 604800000
kafkaQueue    | 	metadata.max.idle.interval.ms = 500
kafkaQueue    | 	metadata.max.retention.bytes = 104857600
kafkaQueue    | 	metadata.max.retention.ms = 604800000
kafkaQueue    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafkaQueue    | 	metrics.num.samples = 2
kafkaQueue    | 	metrics.recording.level = INFO
kafkaQueue    | 	metrics.sample.window.ms = 30000
kafkaQueue    | 	min.insync.replicas = 1
kafkaQueue    | 	node.id = 1
kafkaQueue    | 	num.io.threads = 8
kafkaQueue    | 	num.network.threads = 3
kafkaQueue    | 	num.partitions = 1
kafkaQueue    | 	num.recovery.threads.per.data.dir = 2
kafkaQueue    | 	num.replica.alter.log.dirs.threads = null
kafkaQueue    | 	num.replica.fetchers = 1
kafkaQueue    | 	offset.metadata.max.bytes = 4096
kafkaQueue    | 	offsets.commit.timeout.ms = 5000
kafkaQueue    | 	offsets.load.buffer.size = 5242880
kafkaQueue    | 	offsets.retention.check.interval.ms = 600000
kafkaQueue    | 	offsets.retention.minutes = 10080
kafkaQueue    | 	offsets.topic.compression.codec = 0
kafkaQueue    | 	offsets.topic.num.partitions = 50
kafkaQueue    | 	offsets.topic.replication.factor = 1
kafkaQueue    | 	offsets.topic.segment.bytes = 104857600
kafkaQueue    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafkaQueue    | 	process.roles = [broker, controller]
kafkaQueue    | 	producer.id.expiration.check.interval.ms = 600000
kafkaQueue    | 	producer.id.expiration.ms = 86400000
kafkaQueue    | 	producer.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	queued.max.request.bytes = -1
kafkaQueue    | 	queued.max.requests = 500
kafkaQueue    | 	quota.window.num = 11
kafkaQueue    | 	quota.window.size.seconds = 1
kafkaQueue    | 	remote.fetch.max.wait.ms = 500
kafkaQueue    | 	remote.list.offsets.request.timeout.ms = 30000
kafkaQueue    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafkaQueue    | 	remote.log.manager.copier.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.copy.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.expiration.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.fetch.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.task.interval.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.ms = 500
kafkaQueue    | 	remote.log.manager.task.retry.jitter = 0.2
kafkaQueue    | 	remote.log.manager.thread.pool.size = 2
kafkaQueue    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafkaQueue    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafkaQueue    | 	remote.log.metadata.manager.class.path = null
kafkaQueue    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafkaQueue    | 	remote.log.metadata.manager.listener.name = null
kafkaQueue    | 	remote.log.reader.max.pending.tasks = 100
kafkaQueue    | 	remote.log.reader.threads = 10
kafkaQueue    | 	remote.log.storage.manager.class.name = null
kafkaQueue    | 	remote.log.storage.manager.class.path = null
kafkaQueue    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafkaQueue    | 	remote.log.storage.system.enable = false
kafkaQueue    | 	replica.fetch.backoff.ms = 1000
kafkaQueue    | 	replica.fetch.max.bytes = 1048576
kafkaQueue    | 	replica.fetch.min.bytes = 1
kafkaQueue    | 	replica.fetch.response.max.bytes = 10485760
kafkaQueue    | 	replica.fetch.wait.max.ms = 500
kafkaQueue    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafkaQueue    | 	replica.lag.time.max.ms = 30000
kafkaQueue    | 	replica.selector.class = null
kafkaQueue    | 	replica.socket.receive.buffer.bytes = 65536
kafkaQueue    | 	replica.socket.timeout.ms = 30000
kafkaQueue    | 	replication.quota.window.num = 11
kafkaQueue    | 	replication.quota.window.size.seconds = 1
kafkaQueue    | 	request.timeout.ms = 30000
kafkaQueue    | 	sasl.client.callback.handler.class = null
kafkaQueue    | 	sasl.enabled.mechanisms = [GSSAPI]
kafkaQueue    | 	sasl.jaas.config = null
kafkaQueue    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafkaQueue    | 	sasl.kerberos.min.time.before.relogin = 60000
kafkaQueue    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafkaQueue    | 	sasl.kerberos.service.name = null
kafkaQueue    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafkaQueue    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafkaQueue    | 	sasl.login.callback.handler.class = null
kafkaQueue    | 	sasl.login.class = null
kafkaQueue    | 	sasl.login.connect.timeout.ms = null
kafkaQueue    | 	sasl.login.read.timeout.ms = null
kafkaQueue    | 	sasl.login.refresh.buffer.seconds = 300
kafkaQueue    | 	sasl.login.refresh.min.period.seconds = 60
kafkaQueue    | 	sasl.login.refresh.window.factor = 0.8
kafkaQueue    | 	sasl.login.refresh.window.jitter = 0.05
kafkaQueue    | 	sasl.login.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.login.retry.backoff.ms = 100
kafkaQueue    | 	sasl.mechanism.controller.protocol = GSSAPI
kafkaQueue    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafkaQueue    | 	sasl.oauthbearer.assertion.algorithm = RS256
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.aud = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.iss = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.sub = null
kafkaQueue    | 	sasl.oauthbearer.assertion.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafkaQueue    | 	sasl.oauthbearer.assertion.template.file = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.id = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.secret = null
kafkaQueue    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafkaQueue    | 	sasl.oauthbearer.expected.audience = null
kafkaQueue    | 	sasl.oauthbearer.expected.issuer = null
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafkaQueue    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafkaQueue    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafkaQueue    | 	sasl.oauthbearer.scope = null
kafkaQueue    | 	sasl.oauthbearer.scope.claim.name = scope
kafkaQueue    | 	sasl.oauthbearer.sub.claim.name = sub
kafkaQueue    | 	sasl.oauthbearer.token.endpoint.url = null
kafkaQueue    | 	sasl.server.callback.handler.class = null
kafkaQueue    | 	sasl.server.max.receive.size = 524288
kafkaQueue    | 	security.inter.broker.protocol = PLAINTEXT
kafkaQueue    | 	security.providers = null
kafkaQueue    | 	server.max.startup.time.ms = 9223372036854775807
kafkaQueue    | 	share.coordinator.append.linger.ms = 5
kafkaQueue    | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafkaQueue    | 	share.coordinator.load.buffer.size = 5242880
kafkaQueue    | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafkaQueue    | 	share.coordinator.state.topic.compression.codec = 0
kafkaQueue    | 	share.coordinator.state.topic.min.isr = 2
kafkaQueue    | 	share.coordinator.state.topic.num.partitions = 50
kafkaQueue    | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafkaQueue    | 	share.coordinator.state.topic.replication.factor = 3
kafkaQueue    | 	share.coordinator.state.topic.segment.bytes = 104857600
kafkaQueue    | 	share.coordinator.threads = 1
kafkaQueue    | 	share.coordinator.write.timeout.ms = 5000
kafkaQueue    | 	share.fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	socket.connection.setup.timeout.max.ms = 30000
kafkaQueue    | 	socket.connection.setup.timeout.ms = 10000
kafkaQueue    | 	socket.listen.backlog.size = 50
kafkaQueue    | 	socket.receive.buffer.bytes = 102400
kafkaQueue    | 	socket.request.max.bytes = 104857600
kafkaQueue    | 	socket.send.buffer.bytes = 102400
kafkaQueue    | 	ssl.allow.dn.changes = false
kafkaQueue    | 	ssl.allow.san.changes = false
kafkaQueue    | 	ssl.cipher.suites = []
kafkaQueue    | 	ssl.client.auth = none
kafkaQueue    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafkaQueue    | 	ssl.endpoint.identification.algorithm = https
kafkaQueue    | 	ssl.engine.factory.class = null
kafkaQueue    | 	ssl.key.password = null
kafkaQueue    | 	ssl.keymanager.algorithm = SunX509
kafkaQueue    | 	ssl.keystore.certificate.chain = null
kafkaQueue    | 	ssl.keystore.key = null
kafkaQueue    | 	ssl.keystore.location = null
kafkaQueue    | 	ssl.keystore.password = null
kafkaQueue    | 	ssl.keystore.type = JKS
kafkaQueue    | 	ssl.principal.mapping.rules = DEFAULT
kafkaQueue    | 	ssl.protocol = TLSv1.3
kafkaQueue    | 	ssl.provider = null
kafkaQueue    | 	ssl.secure.random.implementation = null
kafkaQueue    | 	ssl.trustmanager.algorithm = PKIX
kafkaQueue    | 	ssl.truststore.certificates = null
kafkaQueue    | 	ssl.truststore.location = null
kafkaQueue    | 	ssl.truststore.password = null
kafkaQueue    | 	ssl.truststore.type = JKS
kafkaQueue    | 	telemetry.max.bytes = 1048576
kafkaQueue    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafkaQueue    | 	transaction.max.timeout.ms = 900000
kafkaQueue    | 	transaction.partition.verification.enable = true
kafkaQueue    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafkaQueue    | 	transaction.state.log.load.buffer.size = 5242880
kafkaQueue    | 	transaction.state.log.min.isr = 1
kafkaQueue    | 	transaction.state.log.num.partitions = 50
kafkaQueue    | 	transaction.state.log.replication.factor = 1
kafkaQueue    | 	transaction.state.log.segment.bytes = 104857600
kafkaQueue    | 	transaction.two.phase.commit.enable = false
kafkaQueue    | 	transactional.id.expiration.ms = 604800000
kafkaQueue    | 	unclean.leader.election.enable = false
kafkaQueue    | 	unclean.leader.election.interval.ms = 300000
kafkaQueue    | 	unstable.api.versions.enable = false
kafkaQueue    | 	unstable.feature.versions.enable = false
kafkaQueue    |  (org.apache.kafka.common.config.AbstractConfig)
kafkaQueue    | [2025-12-08 17:08:23,512] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 17:08:23,546] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2025-12-08 17:08:23,546] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,546] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,546] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,548] INFO KafkaConfig values: 
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.ms = 20
kafkaQueue    | 	advertised.listeners = PLAINTEXT://kafkaQueue:9092
kafkaQueue    | 	alter.config.policy.class.name = null
kafkaQueue    | 	alter.log.dirs.replication.quota.window.num = 11
kafkaQueue    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafkaQueue    | 	authorizer.class.name = 
kafkaQueue    | 	auto.create.topics.enable = true
kafkaQueue    | 	auto.leader.rebalance.enable = true
kafkaQueue    | 	background.threads = 10
kafkaQueue    | 	broker.heartbeat.interval.ms = 2000
kafkaQueue    | 	broker.id = 1
kafkaQueue    | 	broker.rack = null
kafkaQueue    | 	broker.session.timeout.ms = 9000
kafkaQueue    | 	client.quota.callback.class = null
kafkaQueue    | 	compression.gzip.level = -1
kafkaQueue    | 	compression.lz4.level = 9
kafkaQueue    | 	compression.type = producer
kafkaQueue    | 	compression.zstd.level = 3
kafkaQueue    | 	connection.failed.authentication.delay.ms = 100
kafkaQueue    | 	connections.max.idle.ms = 600000
kafkaQueue    | 	connections.max.reauth.ms = 0
kafkaQueue    | 	controlled.shutdown.enable = true
kafkaQueue    | 	controller.listener.names = CONTROLLER
kafkaQueue    | 	controller.performance.always.log.threshold.ms = 2000
kafkaQueue    | 	controller.performance.sample.period.ms = 60000
kafkaQueue    | 	controller.quorum.append.linger.ms = 25
kafkaQueue    | 	controller.quorum.bootstrap.servers = []
kafkaQueue    | 	controller.quorum.election.backoff.max.ms = 1000
kafkaQueue    | 	controller.quorum.election.timeout.ms = 1000
kafkaQueue    | 	controller.quorum.fetch.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.request.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.retry.backoff.ms = 20
kafkaQueue    | 	controller.quorum.voters = [1@kafkaQueue:9093]
kafkaQueue    | 	controller.quota.window.num = 11
kafkaQueue    | 	controller.quota.window.size.seconds = 1
kafkaQueue    | 	controller.socket.timeout.ms = 30000
kafkaQueue    | 	create.topic.policy.class.name = null
kafkaQueue    | 	default.replication.factor = 1
kafkaQueue    | 	delegation.token.expiry.check.interval.ms = 3600000
kafkaQueue    | 	delegation.token.expiry.time.ms = 86400000
kafkaQueue    | 	delegation.token.max.lifetime.ms = 604800000
kafkaQueue    | 	delegation.token.secret.key = null
kafkaQueue    | 	delete.records.purgatory.purge.interval.requests = 1
kafkaQueue    | 	delete.topic.enable = true
kafkaQueue    | 	early.start.listeners = null
kafkaQueue    | 	fetch.max.bytes = 57671680
kafkaQueue    | 	fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	group.consumer.assignors = [uniform, range]
kafkaQueue    | 	group.consumer.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.consumer.max.session.timeout.ms = 60000
kafkaQueue    | 	group.consumer.max.size = 2147483647
kafkaQueue    | 	group.consumer.migration.policy = bidirectional
kafkaQueue    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.min.session.timeout.ms = 45000
kafkaQueue    | 	group.consumer.regex.refresh.interval.ms = 600000
kafkaQueue    | 	group.consumer.session.timeout.ms = 45000
kafkaQueue    | 	group.coordinator.append.linger.ms = 5
kafkaQueue    | 	group.coordinator.rebalance.protocols = [classic, consumer, streams]
kafkaQueue    | 	group.coordinator.threads = 4
kafkaQueue    | 	group.initial.rebalance.delay.ms = 3000
kafkaQueue    | 	group.max.session.timeout.ms = 1800000
kafkaQueue    | 	group.max.size = 2147483647
kafkaQueue    | 	group.min.session.timeout.ms = 6000
kafkaQueue    | 	group.share.assignors = [simple]
kafkaQueue    | 	group.share.delivery.count.limit = 5
kafkaQueue    | 	group.share.enable = false
kafkaQueue    | 	group.share.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.share.max.record.lock.duration.ms = 60000
kafkaQueue    | 	group.share.max.session.timeout.ms = 60000
kafkaQueue    | 	group.share.max.share.sessions = 2000
kafkaQueue    | 	group.share.max.size = 200
kafkaQueue    | 	group.share.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.min.record.lock.duration.ms = 15000
kafkaQueue    | 	group.share.min.session.timeout.ms = 45000
kafkaQueue    | 	group.share.partition.max.record.locks = 2000
kafkaQueue    | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafkaQueue    | 	group.share.record.lock.duration.ms = 30000
kafkaQueue    | 	group.share.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.streams.max.session.timeout.ms = 60000
kafkaQueue    | 	group.streams.max.size = 2147483647
kafkaQueue    | 	group.streams.max.standby.replicas = 2
kafkaQueue    | 	group.streams.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.min.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.num.standby.replicas = 0
kafkaQueue    | 	group.streams.session.timeout.ms = 45000
kafkaQueue    | 	initial.broker.registration.timeout.ms = 60000
kafkaQueue    | 	inter.broker.listener.name = null
kafkaQueue    | 	internal.metadata.delete.delay.millis = 60000
kafkaQueue    | 	internal.metadata.log.segment.bytes = null
kafkaQueue    | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafkaQueue    | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafkaQueue    | 	kafka.metrics.polling.interval.secs = 10
kafkaQueue    | 	kafka.metrics.reporters = []
kafkaQueue    | 	leader.imbalance.check.interval.seconds = 300
kafkaQueue    | 	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
kafkaQueue    | 	listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
kafkaQueue    | 	log.cleaner.backoff.ms = 15000
kafkaQueue    | 	log.cleaner.dedupe.buffer.size = 134217728
kafkaQueue    | 	log.cleaner.delete.retention.ms = 86400000
kafkaQueue    | 	log.cleaner.enable = true
kafkaQueue    | 	log.cleaner.io.buffer.load.factor = 0.9
kafkaQueue    | 	log.cleaner.io.buffer.size = 524288
kafkaQueue    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafkaQueue    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafkaQueue    | 	log.cleaner.min.cleanable.ratio = 0.5
kafkaQueue    | 	log.cleaner.min.compaction.lag.ms = 0
kafkaQueue    | 	log.cleaner.threads = 1
kafkaQueue    | 	log.cleanup.policy = [delete]
kafkaQueue    | 	log.dir = /tmp/kafka-logs
kafkaQueue    | 	log.dir.failure.timeout.ms = 30000
kafkaQueue    | 	log.dirs = null
kafkaQueue    | 	log.flush.interval.messages = 9223372036854775807
kafkaQueue    | 	log.flush.interval.ms = null
kafkaQueue    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafkaQueue    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.index.interval.bytes = 4096
kafkaQueue    | 	log.index.size.max.bytes = 10485760
kafkaQueue    | 	log.initial.task.delay.ms = 30000
kafkaQueue    | 	log.local.retention.bytes = -2
kafkaQueue    | 	log.local.retention.ms = -2
kafkaQueue    | 	log.message.timestamp.after.max.ms = 3600000
kafkaQueue    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafkaQueue    | 	log.message.timestamp.type = CreateTime
kafkaQueue    | 	log.preallocate = false
kafkaQueue    | 	log.retention.bytes = -1
kafkaQueue    | 	log.retention.check.interval.ms = 300000
kafkaQueue    | 	log.retention.hours = 168
kafkaQueue    | 	log.retention.minutes = null
kafkaQueue    | 	log.retention.ms = null
kafkaQueue    | 	log.roll.hours = 168
kafkaQueue    | 	log.roll.jitter.hours = 0
kafkaQueue    | 	log.roll.jitter.ms = null
kafkaQueue    | 	log.roll.ms = null
kafkaQueue    | 	log.segment.bytes = 1073741824
kafkaQueue    | 	log.segment.delete.delay.ms = 60000
kafkaQueue    | 	max.connection.creation.rate = 2147483647
kafkaQueue    | 	max.connections = 2147483647
kafkaQueue    | 	max.connections.per.ip = 2147483647
kafkaQueue    | 	max.connections.per.ip.overrides = 
kafkaQueue    | 	max.incremental.fetch.session.cache.slots = 1000
kafkaQueue    | 	max.request.partition.size.limit = 2000
kafkaQueue    | 	message.max.bytes = 1048588
kafkaQueue    | 	metadata.log.dir = null
kafkaQueue    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafkaQueue    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafkaQueue    | 	metadata.log.segment.bytes = 1073741824
kafkaQueue    | 	metadata.log.segment.ms = 604800000
kafkaQueue    | 	metadata.max.idle.interval.ms = 500
kafkaQueue    | 	metadata.max.retention.bytes = 104857600
kafkaQueue    | 	metadata.max.retention.ms = 604800000
kafkaQueue    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafkaQueue    | 	metrics.num.samples = 2
kafkaQueue    | 	metrics.recording.level = INFO
kafkaQueue    | 	metrics.sample.window.ms = 30000
kafkaQueue    | 	min.insync.replicas = 1
kafkaQueue    | 	node.id = 1
kafkaQueue    | 	num.io.threads = 8
kafkaQueue    | 	num.network.threads = 3
kafkaQueue    | 	num.partitions = 1
kafkaQueue    | 	num.recovery.threads.per.data.dir = 2
kafkaQueue    | 	num.replica.alter.log.dirs.threads = null
kafkaQueue    | 	num.replica.fetchers = 1
kafkaQueue    | 	offset.metadata.max.bytes = 4096
kafkaQueue    | 	offsets.commit.timeout.ms = 5000
kafkaQueue    | 	offsets.load.buffer.size = 5242880
kafkaQueue    | 	offsets.retention.check.interval.ms = 600000
kafkaQueue    | 	offsets.retention.minutes = 10080
kafkaQueue    | 	offsets.topic.compression.codec = 0
kafkaQueue    | 	offsets.topic.num.partitions = 50
kafkaQueue    | 	offsets.topic.replication.factor = 1
kafkaQueue    | 	offsets.topic.segment.bytes = 104857600
kafkaQueue    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafkaQueue    | 	process.roles = [broker, controller]
kafkaQueue    | 	producer.id.expiration.check.interval.ms = 600000
kafkaQueue    | 	producer.id.expiration.ms = 86400000
kafkaQueue    | 	producer.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	queued.max.request.bytes = -1
kafkaQueue    | 	queued.max.requests = 500
kafkaQueue    | 	quota.window.num = 11
kafkaQueue    | 	quota.window.size.seconds = 1
kafkaQueue    | 	remote.fetch.max.wait.ms = 500
kafkaQueue    | 	remote.list.offsets.request.timeout.ms = 30000
kafkaQueue    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafkaQueue    | 	remote.log.manager.copier.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.copy.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.expiration.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.fetch.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.task.interval.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.ms = 500
kafkaQueue    | 	remote.log.manager.task.retry.jitter = 0.2
kafkaQueue    | 	remote.log.manager.thread.pool.size = 2
kafkaQueue    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafkaQueue    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafkaQueue    | 	remote.log.metadata.manager.class.path = null
kafkaQueue    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafkaQueue    | 	remote.log.metadata.manager.listener.name = null
kafkaQueue    | 	remote.log.reader.max.pending.tasks = 100
kafkaQueue    | 	remote.log.reader.threads = 10
kafkaQueue    | 	remote.log.storage.manager.class.name = null
kafkaQueue    | 	remote.log.storage.manager.class.path = null
kafkaQueue    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafkaQueue    | 	remote.log.storage.system.enable = false
kafkaQueue    | 	replica.fetch.backoff.ms = 1000
kafkaQueue    | 	replica.fetch.max.bytes = 1048576
kafkaQueue    | 	replica.fetch.min.bytes = 1
kafkaQueue    | 	replica.fetch.response.max.bytes = 10485760
kafkaQueue    | 	replica.fetch.wait.max.ms = 500
kafkaQueue    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafkaQueue    | 	replica.lag.time.max.ms = 30000
kafkaQueue    | 	replica.selector.class = null
kafkaQueue    | 	replica.socket.receive.buffer.bytes = 65536
kafkaQueue    | 	replica.socket.timeout.ms = 30000
kafkaQueue    | 	replication.quota.window.num = 11
kafkaQueue    | 	replication.quota.window.size.seconds = 1
kafkaQueue    | 	request.timeout.ms = 30000
kafkaQueue    | 	sasl.client.callback.handler.class = null
kafkaQueue    | 	sasl.enabled.mechanisms = [GSSAPI]
kafkaQueue    | 	sasl.jaas.config = null
kafkaQueue    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafkaQueue    | 	sasl.kerberos.min.time.before.relogin = 60000
kafkaQueue    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafkaQueue    | 	sasl.kerberos.service.name = null
kafkaQueue    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafkaQueue    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafkaQueue    | 	sasl.login.callback.handler.class = null
kafkaQueue    | 	sasl.login.class = null
kafkaQueue    | 	sasl.login.connect.timeout.ms = null
kafkaQueue    | 	sasl.login.read.timeout.ms = null
kafkaQueue    | 	sasl.login.refresh.buffer.seconds = 300
kafkaQueue    | 	sasl.login.refresh.min.period.seconds = 60
kafkaQueue    | 	sasl.login.refresh.window.factor = 0.8
kafkaQueue    | 	sasl.login.refresh.window.jitter = 0.05
kafkaQueue    | 	sasl.login.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.login.retry.backoff.ms = 100
kafkaQueue    | 	sasl.mechanism.controller.protocol = GSSAPI
kafkaQueue    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafkaQueue    | 	sasl.oauthbearer.assertion.algorithm = RS256
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.aud = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.iss = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.sub = null
kafkaQueue    | 	sasl.oauthbearer.assertion.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafkaQueue    | 	sasl.oauthbearer.assertion.template.file = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.id = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.secret = null
kafkaQueue    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafkaQueue    | 	sasl.oauthbearer.expected.audience = null
kafkaQueue    | 	sasl.oauthbearer.expected.issuer = null
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafkaQueue    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafkaQueue    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafkaQueue    | 	sasl.oauthbearer.scope = null
kafkaQueue    | 	sasl.oauthbearer.scope.claim.name = scope
kafkaQueue    | 	sasl.oauthbearer.sub.claim.name = sub
kafkaQueue    | 	sasl.oauthbearer.token.endpoint.url = null
kafkaQueue    | 	sasl.server.callback.handler.class = null
kafkaQueue    | 	sasl.server.max.receive.size = 524288
kafkaQueue    | 	security.inter.broker.protocol = PLAINTEXT
kafkaQueue    | 	security.providers = null
kafkaQueue    | 	server.max.startup.time.ms = 9223372036854775807
kafkaQueue    | 	share.coordinator.append.linger.ms = 5
kafkaQueue    | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafkaQueue    | 	share.coordinator.load.buffer.size = 5242880
kafkaQueue    | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafkaQueue    | 	share.coordinator.state.topic.compression.codec = 0
kafkaQueue    | 	share.coordinator.state.topic.min.isr = 2
kafkaQueue    | 	share.coordinator.state.topic.num.partitions = 50
kafkaQueue    | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafkaQueue    | 	share.coordinator.state.topic.replication.factor = 3
kafkaQueue    | 	share.coordinator.state.topic.segment.bytes = 104857600
kafkaQueue    | 	share.coordinator.threads = 1
kafkaQueue    | 	share.coordinator.write.timeout.ms = 5000
kafkaQueue    | 	share.fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	socket.connection.setup.timeout.max.ms = 30000
kafkaQueue    | 	socket.connection.setup.timeout.ms = 10000
kafkaQueue    | 	socket.listen.backlog.size = 50
kafkaQueue    | 	socket.receive.buffer.bytes = 102400
kafkaQueue    | 	socket.request.max.bytes = 104857600
kafkaQueue    | 	socket.send.buffer.bytes = 102400
kafkaQueue    | 	ssl.allow.dn.changes = false
kafkaQueue    | 	ssl.allow.san.changes = false
kafkaQueue    | 	ssl.cipher.suites = []
kafkaQueue    | 	ssl.client.auth = none
kafkaQueue    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafkaQueue    | 	ssl.endpoint.identification.algorithm = https
kafkaQueue    | 	ssl.engine.factory.class = null
kafkaQueue    | 	ssl.key.password = null
kafkaQueue    | 	ssl.keymanager.algorithm = SunX509
kafkaQueue    | 	ssl.keystore.certificate.chain = null
kafkaQueue    | 	ssl.keystore.key = null
kafkaQueue    | 	ssl.keystore.location = null
kafkaQueue    | 	ssl.keystore.password = null
kafkaQueue    | 	ssl.keystore.type = JKS
kafkaQueue    | 	ssl.principal.mapping.rules = DEFAULT
kafkaQueue    | 	ssl.protocol = TLSv1.3
kafkaQueue    | 	ssl.provider = null
kafkaQueue    | 	ssl.secure.random.implementation = null
kafkaQueue    | 	ssl.trustmanager.algorithm = PKIX
kafkaQueue    | 	ssl.truststore.certificates = null
kafkaQueue    | 	ssl.truststore.location = null
kafkaQueue    | 	ssl.truststore.password = null
kafkaQueue    | 	ssl.truststore.type = JKS
kafkaQueue    | 	telemetry.max.bytes = 1048576
kafkaQueue    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafkaQueue    | 	transaction.max.timeout.ms = 900000
kafkaQueue    | 	transaction.partition.verification.enable = true
kafkaQueue    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafkaQueue    | 	transaction.state.log.load.buffer.size = 5242880
kafkaQueue    | 	transaction.state.log.min.isr = 1
kafkaQueue    | 	transaction.state.log.num.partitions = 50
kafkaQueue    | 	transaction.state.log.replication.factor = 1
kafkaQueue    | 	transaction.state.log.segment.bytes = 104857600
kafkaQueue    | 	transaction.two.phase.commit.enable = false
kafkaQueue    | 	transactional.id.expiration.ms = 604800000
kafkaQueue    | 	unclean.leader.election.enable = false
kafkaQueue    | 	unclean.leader.election.interval.ms = 300000
kafkaQueue    | 	unstable.api.versions.enable = false
kafkaQueue    | 	unstable.feature.versions.enable = false
kafkaQueue    |  (org.apache.kafka.common.config.AbstractConfig)
kafkaQueue    | [2025-12-08 17:08:23,553] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,584] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2025-12-08 17:08:23,584] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,585] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafkaQueue    | [2025-12-08 17:08:23,586] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafkaQueue    | [2025-12-08 17:08:23,586] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
kafkaQueue    | [2025-12-08 17:08:23,587] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,587] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,587] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,587] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,587] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 17:08:23,588] INFO Kafka version: 4.1.1 (org.apache.kafka.common.utils.AppInfoParser)
kafkaQueue    | [2025-12-08 17:08:23,588] INFO Kafka commitId: be816b82d25370ce (org.apache.kafka.common.utils.AppInfoParser)
kafkaQueue    | [2025-12-08 17:08:23,588] INFO Kafka startTimeMs: 1765213703587 (org.apache.kafka.common.utils.AppInfoParser)
kafkaQueue    | [2025-12-08 17:08:23,589] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
sql_db        | 2025-12-08 17:08:23.65 Server      Installing Client TLS certificates to the store.
sql_db        | 2025-12-08 17:08:23.66 Server      CPU vectorization level(s) detected:  SSE SSE2 SSE3 SSSE3 SSE41 SSE42 AVX AVX2 POPCNT BMI1 BMI2
sql_db        | 2025-12-08 17:08:23.72 Server      Successfully initialized the TLS configuration. Allowed TLS protocol versions are ['1.0 1.1 1.2']. Allowed TLS ciphers are ['ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-ECDSA-AES128-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:!DHE-RSA-AES256-GCM-SHA384:!DHE-RSA-AES128-GCM-SHA256:!DHE-RSA-AES256-SHA:!DHE-RSA-AES128-SHA'].
sql_db        | 2025-12-08 17:08:23.74 Server      Query Store settings initialized with enabled = 1, 
sql_db        | 2025-12-08 17:08:23.76 Server      The maximum number of dedicated administrator connections for this instance is '1'
sql_db        | 2025-12-08 17:08:23.77 Server      Node configuration: node 0: CPU mask: 0x000000000000ffff:0 Active CPU mask: 0x000000000000ffff:0. This message provides a description of the NUMA configuration for this computer. This is an informational message only. No user action is required.
configserver  | 2025-12-08T17:08:23.798Z  INFO 1 --- [ConfigServer] [nio-8888-exec-3] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-5970477714589687880/AuthService.properties]' via location 'file:/tmp/config-repo-5970477714589687880/'
sql_db        | 2025-12-08 17:08:23.80 Server      Using dynamic lock allocation.  Initial allocation of 2500 Lock blocks and 5000 Lock Owner blocks per node.  This is an informational message only.  No user action is required.
sql_db        | 2025-12-08 17:08:23.80 Server      Lock partitioning is enabled.  This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:23.83 Server      In-Memory OLTP initialized on lowend machine.
sql_db        | 2025-12-08 17:08:23.86 Server      [INFO] Created Extended Events session 'hkenginexesession'
sql_db        | 2025-12-08 17:08:23.86 Server      Database Instant File Initialization: enabled. For security and performance considerations see the topic 'Database Instant File Initialization' in SQL Server Books Online. This is an informational message only. No user action is required.
sql_db        | ForceFlush is enabled for this instance. 
sql_db        | 2025-12-08 17:08:23.87 Server      Total Log Writer threads: 2. This is an informational message; no user action is required.
sql_db        | 2025-12-08 17:08:23.87 Server      clwb is selected for pmem flush operation.
sql_db        | 2025-12-08 17:08:23.88 Server      Software Usage Metrics is disabled.
sql_db        | 2025-12-08 17:08:23.88 Server      CLR version v4.0.30319 loaded.
sql_db        | 2025-12-08 17:08:23.89 spid44s     [1]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:23.89 spid44s     Starting up database 'master'.
sql_db        | ForceFlush feature is enabled for log durability.
sql_db        | 2025-12-08 17:08:23.94 spid44s     25 transactions rolled forward in database 'master' (1:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:23.95 spid44s     0 transactions rolled back in database 'master' (1:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:23.95 spid44s     Recovery is writing a checkpoint in database 'master' (1). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:24.01 spid44s     [32762]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:24.01 spid46s     [32767]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:24.01 spid44s     Starting up database 'model_replicatedmaster'.
sql_db        | 2025-12-08 17:08:24.02 spid46s     Starting up database 'mssqlsystemresource'.
sql_db        | 2025-12-08 17:08:24.03 spid46s     The resource database build version is 16.00.4215. This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:24.06 spid46s     [3]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:24.06 spid46s     Starting up database 'model'.
sql_db        | 2025-12-08 17:08:24.07 spid44s     Converting database 'model_replicatedmaster' from version 927 to the current version 957.
sql_db        | 2025-12-08 17:08:24.07 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 927 to version 928.
sql_db        | 2025-12-08 17:08:24.08 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 928 to version 929.
sql_db        | 2025-12-08 17:08:24.11 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 929 to version 930.
sql_db        | 2025-12-08 17:08:24.13 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 930 to version 931.
sql_db        | 2025-12-08 17:08:24.14 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 931 to version 932.
sql_db        | 2025-12-08 17:08:24.15 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 932 to version 933.
sql_db        | 2025-12-08 17:08:24.16 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 933 to version 934.
sql_db        | 2025-12-08 17:08:24.17 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 934 to version 935.
authservice   | 
authservice   |   .   ____          _            __ _ _
authservice   |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
authservice   | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
authservice   |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
authservice   |   '  |____| .__|_| |_|_| |_\__, | / / / /
authservice   |  =========|_|==============|___/=/_/_/_/
authservice   | 
authservice   |  :: Spring Boot ::                (v4.0.0)
authservice   | 
sql_db        | 2025-12-08 17:08:24.18 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 935 to version 936.
sql_db        | 2025-12-08 17:08:24.19 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 936 to version 937.
sql_db        | 2025-12-08 17:08:24.20 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 937 to version 938.
sql_db        | 2025-12-08 17:08:24.21 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 938 to version 939.
sql_db        | 2025-12-08 17:08:24.22 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 939 to version 940.
sql_db        | 2025-12-08 17:08:24.23 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 940 to version 941.
sql_db        | 2025-12-08 17:08:24.24 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 941 to version 942.
sql_db        | 2025-12-08 17:08:24.24 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 942 to version 943.
sql_db        | 2025-12-08 17:08:24.25 Server      Common language runtime (CLR) functionality initialized.
sql_db        | 2025-12-08 17:08:24.28 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 943 to version 944.
sql_db        | 2025-12-08 17:08:24.29 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 944 to version 945.
sql_db        | 2025-12-08 17:08:24.30 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 945 to version 946.
sql_db        | 2025-12-08 17:08:24.31 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 946 to version 947.
authservice   | 2025-12-08T17:08:24.325Z  INFO 1 --- [AuthService] [           main] o.e.authservice.AuthServiceApplication   : Starting AuthServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/AuthService-0.0.1-SNAPSHOT.jar started by root in /app)
sql_db        | 2025-12-08 17:08:24.32 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 947 to version 948.
sql_db        | 2025-12-08 17:08:24.32 Server      External governance manager initialized
authservice   | 2025-12-08T17:08:24.329Z  INFO 1 --- [AuthService] [           main] o.e.authservice.AuthServiceApplication   : No active profile set, falling back to 1 default profile: "default"
sql_db        | 2025-12-08 17:08:24.32 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 948 to version 949.
sql_db        | 2025-12-08 17:08:24.33 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 949 to version 950.
sql_db        | 2025-12-08 17:08:24.34 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 950 to version 951.
sql_db        | 2025-12-08 17:08:24.36 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 951 to version 952.
sql_db        | 2025-12-08 17:08:24.37 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 952 to version 953.
sql_db        | 2025-12-08 17:08:24.39 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 953 to version 954.
sql_db        | 2025-12-08 17:08:24.39 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 954 to version 955.
authservice   | 2025-12-08T17:08:24.402Z  INFO 1 --- [AuthService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
authservice   | 2025-12-08T17:08:24.402Z  INFO 1 --- [AuthService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=AuthService, profiles=[default], label=null, version=3c509b534a06809c030dd922c414b4ec98cb7e59, state=
sql_db        | 2025-12-08 17:08:24.40 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 955 to version 956.
sql_db        | 2025-12-08 17:08:24.41 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 956 to version 957.
sql_db        | 2025-12-08 17:08:24.45 spid44s     [32761]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:24.46 spid44s     Starting up database 'model_msdb'.
sql_db        | 2025-12-08 17:08:24.46 spid53s     A self-generated certificate was successfully loaded for encryption.
sql_db        | 2025-12-08 17:08:24.46 spid53s     Server is listening on [ 'any' <ipv6> 1433] accept sockets 1.
sql_db        | 2025-12-08 17:08:24.46 spid53s     Server is listening on [ 'any' <ipv4> 1433] accept sockets 1.
sql_db        | 2025-12-08 17:08:24.46 Server      Server is listening on [ ::1 <ipv6> 1434] accept sockets 1.
sql_db        | 2025-12-08 17:08:24.46 Server      Server is listening on [ 127.0.0.1 <ipv4> 1434] accept sockets 1.
sql_db        | 2025-12-08 17:08:24.47 Server      Dedicated admin connection support was established for listening locally on port 1434.
sql_db        | 2025-12-08 17:08:24.47 spid53s     Server is listening on [ ::1 <ipv6> 1431] accept sockets 1.
sql_db        | 2025-12-08 17:08:24.47 spid53s     Server is listening on [ 127.0.0.1 <ipv4> 1431] accept sockets 1.
sql_db        | 2025-12-08 17:08:24.47 spid53s     SQL Server is now ready for client connections. This is an informational message; no user action is required.
sql_db        | 2025-12-08 17:08:24.49 spid44s     Converting database 'model_msdb' from version 927 to the current version 957.
sql_db        | 2025-12-08 17:08:24.49 spid44s     Database 'model_msdb' running the upgrade step from version 927 to version 928.
sql_db        | 2025-12-08 17:08:24.50 spid44s     Database 'model_msdb' running the upgrade step from version 928 to version 929.
sql_db        | 2025-12-08 17:08:24.53 spid44s     Database 'model_msdb' running the upgrade step from version 929 to version 930.
sql_db        | 2025-12-08 17:08:24.54 spid44s     Database 'model_msdb' running the upgrade step from version 930 to version 931.
sql_db        | 2025-12-08 17:08:24.55 spid44s     Database 'model_msdb' running the upgrade step from version 931 to version 932.
sql_db        | 2025-12-08 17:08:24.56 spid44s     Database 'model_msdb' running the upgrade step from version 932 to version 933.
sql_db        | 2025-12-08 17:08:24.57 spid44s     Database 'model_msdb' running the upgrade step from version 933 to version 934.
sql_db        | 2025-12-08 17:08:24.58 spid44s     Database 'model_msdb' running the upgrade step from version 934 to version 935.
sql_db        | 2025-12-08 17:08:24.58 spid44s     Database 'model_msdb' running the upgrade step from version 935 to version 936.
sql_db        | 2025-12-08 17:08:24.59 spid44s     Database 'model_msdb' running the upgrade step from version 936 to version 937.
sql_db        | 2025-12-08 17:08:24.60 spid44s     Database 'model_msdb' running the upgrade step from version 937 to version 938.
configserver  | 2025-12-08T17:08:24.611Z  INFO 1 --- [ConfigServer] [nio-8888-exec-6] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-5970477714589687880/EmailService.properties]' via location 'file:/tmp/config-repo-5970477714589687880/'
sql_db        | 2025-12-08 17:08:24.60 spid44s     Database 'model_msdb' running the upgrade step from version 938 to version 939.
sql_db        | 2025-12-08 17:08:24.61 spid44s     Database 'model_msdb' running the upgrade step from version 939 to version 940.
sql_db        | 2025-12-08 17:08:24.62 spid44s     Database 'model_msdb' running the upgrade step from version 940 to version 941.
sql_db        | 2025-12-08 17:08:24.63 spid44s     Database 'model_msdb' running the upgrade step from version 941 to version 942.
sql_db        | 2025-12-08 17:08:24.63 spid44s     Database 'model_msdb' running the upgrade step from version 942 to version 943.
sql_db        | 2025-12-08 17:08:24.66 spid44s     Database 'model_msdb' running the upgrade step from version 943 to version 944.
sql_db        | 2025-12-08 17:08:24.67 spid44s     Database 'model_msdb' running the upgrade step from version 944 to version 945.
sql_db        | 2025-12-08 17:08:24.69 spid44s     Database 'model_msdb' running the upgrade step from version 945 to version 946.
sql_db        | 2025-12-08 17:08:24.69 spid44s     Database 'model_msdb' running the upgrade step from version 946 to version 947.
sql_db        | 2025-12-08 17:08:24.70 spid44s     Database 'model_msdb' running the upgrade step from version 947 to version 948.
sql_db        | 2025-12-08 17:08:24.71 spid44s     Database 'model_msdb' running the upgrade step from version 948 to version 949.
sql_db        | 2025-12-08 17:08:24.72 spid44s     Database 'model_msdb' running the upgrade step from version 949 to version 950.
sql_db        | 2025-12-08 17:08:24.73 spid44s     Database 'model_msdb' running the upgrade step from version 950 to version 951.
sql_db        | 2025-12-08 17:08:24.74 spid44s     Database 'model_msdb' running the upgrade step from version 951 to version 952.
sql_db        | 2025-12-08 17:08:24.75 spid44s     Database 'model_msdb' running the upgrade step from version 952 to version 953.
sql_db        | 2025-12-08 17:08:24.76 spid44s     Database 'model_msdb' running the upgrade step from version 953 to version 954.
sql_db        | 2025-12-08 17:08:24.77 spid44s     Database 'model_msdb' running the upgrade step from version 954 to version 955.
sql_db        | 2025-12-08 17:08:24.77 spid44s     Database 'model_msdb' running the upgrade step from version 955 to version 956.
sql_db        | 2025-12-08 17:08:24.80 spid44s     Database 'model_msdb' running the upgrade step from version 956 to version 957.
sql_db        | 2025-12-08 17:08:24.85 spid44s     Resource governor reconfiguration succeeded.
sql_db        | 2025-12-08 17:08:24.85 spid58s     Attribute synchronization initialized
sql_db        | 2025-12-08 17:08:24.85 spid44s     SQL Server Audit is starting the audits. This is an informational message. No user action is required.
sql_db        | 2025-12-08 17:08:24.85 spid58s     Attribute synchronization manager initialized
sql_db        | 2025-12-08 17:08:24.85 spid44s     SQL Server Audit has started the audits. This is an informational message. No user action is required.
emailservice  | 
emailservice  |   .   ____          _            __ _ _
emailservice  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
emailservice  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
emailservice  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
emailservice  |   '  |____| .__|_| |_|_| |_\__, | / / / /
emailservice  |  =========|_|==============|___/=/_/_/_/
emailservice  | 
emailservice  |  :: Spring Boot ::                (v4.0.0)
emailservice  | 
sql_db        | 2025-12-08 17:08:24.90 spid44s     SQL Trace ID 1 was started by login "sa".
sql_db        | 2025-12-08 17:08:24.91 spid44s     Server name is '5d03cb505ff1'. This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:24.93 spid46s     Clearing tempdb database.
sql_db        | 2025-12-08 17:08:24.93 spid64s     Always On: The availability replica manager is starting. This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:24.93 spid67s     [6]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:24.93 spid69s     [8]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:24.93 spid66s     [5]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:24.93 spid65s     [4]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:24.93 spid68s     [7]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:24.93 spid64s     Always On: The availability replica manager is waiting for the instance of SQL Server to allow client connections. This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:24.93 spid67s     Starting up database 'springtest'.
sql_db        | 2025-12-08 17:08:24.93 spid69s     Starting up database 'UserDB'.
sql_db        | 2025-12-08 17:08:24.94 spid66s     Starting up database 'FlightBooking'.
sql_db        | 2025-12-08 17:08:24.94 spid65s     Starting up database 'msdb'.
sql_db        | 2025-12-08 17:08:24.94 spid68s     Starting up database 'TicketDB'.
sql_db        | 2025-12-08 17:08:24.94 spid67s     RemoveStaleDbEntries: Cleanup of stale DB entries called for database ID: [6]
sql_db        | 2025-12-08 17:08:24.94 spid69s     RemoveStaleDbEntries: Cleanup of stale DB entries called for database ID: [8]
sql_db        | 2025-12-08 17:08:24.94 spid66s     RemoveStaleDbEntries: Cleanup of stale DB entries called for database ID: [5]
sql_db        | 2025-12-08 17:08:24.94 spid68s     RemoveStaleDbEntries: Cleanup of stale DB entries called for database ID: [7]
sql_db        | 2025-12-08 17:08:24.95 spid67s     RemoveStaleDbEntries: Cleanup of stale DB entries skipped because master db is not memory optimized. DbId: 6.
sql_db        | 2025-12-08 17:08:24.95 spid69s     RemoveStaleDbEntries: Cleanup of stale DB entries skipped because master db is not memory optimized. DbId: 8.
sql_db        | 2025-12-08 17:08:24.95 spid66s     RemoveStaleDbEntries: Cleanup of stale DB entries skipped because master db is not memory optimized. DbId: 5.
sql_db        | 2025-12-08 17:08:24.95 spid68s     RemoveStaleDbEntries: Cleanup of stale DB entries skipped because master db is not memory optimized. DbId: 7.
sql_db        | 2025-12-08 17:08:24.98 spid66s     Parallel redo is started for database 'FlightBooking' with worker pool size [8].
sql_db        | 2025-12-08 17:08:24.98 spid69s     Parallel redo is started for database 'UserDB' with worker pool size [8].
sql_db        | 2025-12-08 17:08:24.99 spid67s     Parallel redo is started for database 'springtest' with worker pool size [8].
sql_db        | 2025-12-08 17:08:24.99 spid68s     Parallel redo is started for database 'TicketDB' with worker pool size [8].
sql_db        | 2025-12-08 17:08:25.05 spid67s     102 transactions rolled forward in database 'springtest' (6:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:25.05 spid46s     [2]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 17:08:25.06 spid46s     Starting up database 'tempdb'.
emailservice  | 2025-12-08T17:08:25.062Z  INFO 1 --- [EmailService] [           main] o.e.e.EmailServiceApplication            : Starting EmailServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/EmailService-0.0.1-SNAPSHOT.jar started by root in /app)
sql_db        | 2025-12-08 17:08:25.06 spid68s     35 transactions rolled forward in database 'TicketDB' (7:0). This is an informational message only. No user action is required.
emailservice  | 2025-12-08T17:08:25.068Z  INFO 1 --- [EmailService] [           main] o.e.e.EmailServiceApplication            : No active profile set, falling back to 1 default profile: "default"
sql_db        | 2025-12-08 17:08:25.06 spid69s     46 transactions rolled forward in database 'UserDB' (8:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:25.07 spid65s     0 transactions rolled back in database 'springtest' (6:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:25.07 spid65s     Parallel redo is shutdown for database 'springtest' with worker pool size [8].
sql_db        | 2025-12-08 17:08:25.09 spid69s     0 transactions rolled back in database 'UserDB' (8:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:25.09 spid69s     Parallel redo is shutdown for database 'UserDB' with worker pool size [8].
sql_db        | 2025-12-08 17:08:25.11 spid68s     0 transactions rolled back in database 'TicketDB' (7:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:25.11 spid68s     Parallel redo is shutdown for database 'TicketDB' with worker pool size [8].
emailservice  | 2025-12-08T17:08:25.144Z  INFO 1 --- [EmailService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
emailservice  | 2025-12-08T17:08:25.144Z  INFO 1 --- [EmailService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=EmailService, profiles=[default], label=null, version=3c509b534a06809c030dd922c414b4ec98cb7e59, state=
sql_db        | 2025-12-08 17:08:25.22 spid66s     Recovery of database 'FlightBooking' (5) is 0% complete (approximately 37 seconds remain). Phase 2 of 3. This is an informational message only. No user action is required.
authservice   | 2025-12-08T17:08:25.332Z  INFO 1 --- [AuthService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
sql_db        | 2025-12-08 17:08:25.34 spid46s     The tempdb database has 8 data file(s).
sql_db        | 2025-12-08 17:08:25.35 spid56s     The Service Broker endpoint is in disabled or stopped state.
sql_db        | 2025-12-08 17:08:25.35 spid56s     The Database Mirroring endpoint is in disabled or stopped state.
sql_db        | 2025-12-08 17:08:25.36 spid56s     Service Broker manager has started.
configserver  | 2025-12-08T17:08:25.396Z  INFO 1 --- [ConfigServer] [nio-8888-exec-5] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-5970477714589687880/FlightService.properties]' via location 'file:/tmp/config-repo-5970477714589687880/'
sql_db        | 2025-12-08 17:08:25.40 spid66s     215 transactions rolled forward in database 'FlightBooking' (5:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:25.44 spid66s     0 transactions rolled back in database 'FlightBooking' (5:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 17:08:25.44 spid66s     Parallel redo is shutdown for database 'FlightBooking' with worker pool size [8].
sql_db        | 2025-12-08 17:08:25.45 spid44s     Recovery is complete. This is an informational message only. No user action is required.
authservice   | 2025-12-08T17:08:25.518Z  INFO 1 --- [AuthService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 170 ms. Found 2 JPA repository interfaces.
flightservice  | 
flightservice  |   .   ____          _            __ _ _
flightservice  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
flightservice  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
flightservice  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
flightservice  |   '  |____| .__|_| |_|_| |_\__, | / / / /
flightservice  |  =========|_|==============|___/=/_/_/_/
flightservice  | 
flightservice  |  :: Spring Boot ::                (v4.0.0)
flightservice  | 
flightservice  | 2025-12-08T17:08:25.813Z  INFO 1 --- [FlightService] [           main] o.e.f.FlightServiceApplication           : Starting FlightServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/FlightService-0.0.1-SNAPSHOT.jar started by root in /app)
flightservice  | 2025-12-08T17:08:25.816Z  INFO 1 --- [FlightService] [           main] o.e.f.FlightServiceApplication           : No active profile set, falling back to 1 default profile: "default"
authservice    | 2025-12-08T17:08:25.845Z  INFO 1 --- [AuthService] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=faa00cb5-5d72-3e77-9798-bd8143851520
flightservice  | 2025-12-08T17:08:25.878Z  INFO 1 --- [FlightService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
flightservice  | 2025-12-08T17:08:25.878Z  INFO 1 --- [FlightService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=FlightService, profiles=[default], label=null, version=3c509b534a06809c030dd922c414b4ec98cb7e59, state=
emailservice   | 2025-12-08T17:08:26.126Z  INFO 1 --- [EmailService] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=53d4c282-6f6e-32c3-8e94-119279e67d6a
configserver   | 2025-12-08T17:08:26.225Z  INFO 1 --- [ConfigServer] [nio-8888-exec-4] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-5970477714589687880/BookingService.properties]' via location 'file:/tmp/config-repo-5970477714589687880/'
authservice    | 2025-12-08T17:08:26.473Z  INFO 1 --- [AuthService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 9091 (http)
authservice    | 2025-12-08T17:08:26.490Z  INFO 1 --- [AuthService] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
authservice    | 2025-12-08T17:08:26.490Z  INFO 1 --- [AuthService] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
emailservice   | 2025-12-08T17:08:26.491Z  INFO 1 --- [EmailService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8082 (http)
bookingservice  | 
bookingservice  |   .   ____          _            __ _ _
bookingservice  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
bookingservice  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
bookingservice  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
bookingservice  |   '  |____| .__|_| |_|_| |_\__, | / / / /
bookingservice  |  =========|_|==============|___/=/_/_/_/
bookingservice  | 
bookingservice  |  :: Spring Boot ::                (v4.0.0)
bookingservice  | 
emailservice    | 2025-12-08T17:08:26.517Z  INFO 1 --- [EmailService] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
emailservice    | 2025-12-08T17:08:26.517Z  INFO 1 --- [EmailService] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
authservice     | 2025-12-08T17:08:26.537Z  INFO 1 --- [AuthService] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 2130 ms
emailservice    | 2025-12-08T17:08:26.555Z  INFO 1 --- [EmailService] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 1405 ms
bookingservice  | 2025-12-08T17:08:26.647Z  INFO 1 --- [BookingService] [           main] o.e.b.BookingServiceApplication          : Starting BookingServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/BookingService-0.0.1-SNAPSHOT.jar started by root in /app)
bookingservice  | 2025-12-08T17:08:26.665Z  INFO 1 --- [BookingService] [           main] o.e.b.BookingServiceApplication          : No active profile set, falling back to 1 default profile: "default"
authservice     | 2025-12-08T17:08:26.732Z  INFO 1 --- [AuthService] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
bookingservice  | 2025-12-08T17:08:26.758Z  INFO 1 --- [BookingService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
bookingservice  | 2025-12-08T17:08:26.758Z  INFO 1 --- [BookingService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=BookingService, profiles=[default], label=null, version=3c509b534a06809c030dd922c414b4ec98cb7e59, state=
authservice     | 2025-12-08T17:08:26.815Z  INFO 1 --- [AuthService] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 7.1.8.Final
configserver    | 2025-12-08T17:08:27.056Z  INFO 1 --- [ConfigServer] [nio-8888-exec-7] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-5970477714589687880/ApiGateway.properties]' via location 'file:/tmp/config-repo-5970477714589687880/'
flightservice   | 2025-12-08T17:08:27.148Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
flightservice   | 2025-12-08T17:08:27.151Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
apigateway      | 
apigateway      |   .   ____          _            __ _ _
apigateway      |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
apigateway      | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
apigateway      |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
apigateway      |   '  |____| .__|_| |_|_| |_\__, | / / / /
apigateway      |  =========|_|==============|___/=/_/_/_/
apigateway      | 
apigateway      |  :: Spring Boot ::                (v3.4.0)
apigateway      | 
apigateway      | 2025-12-08T17:08:27.451Z  INFO 1 --- [ApiGateway] [           main] o.e.apigateway.ApiGatewayApplication     : Starting ApiGatewayApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/ApiGateway-0.0.1-SNAPSHOT.jar started by root in /app)
apigateway      | 2025-12-08T17:08:27.455Z  INFO 1 --- [ApiGateway] [           main] o.e.apigateway.ApiGatewayApplication     : No active profile set, falling back to 1 default profile: "default"
authservice     | 2025-12-08T17:08:27.463Z  INFO 1 --- [AuthService] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
authservice     | 2025-12-08T17:08:27.512Z  INFO 1 --- [AuthService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
apigateway      | 2025-12-08T17:08:27.528Z  INFO 1 --- [ApiGateway] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
apigateway      | 2025-12-08T17:08:27.528Z  INFO 1 --- [ApiGateway] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=ApiGateway, profiles=[default], label=null, version=3c509b534a06809c030dd922c414b4ec98cb7e59, state=
flightservice   | 2025-12-08T17:08:27.772Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 607 ms. Found 5 JPA repository interfaces.
emailservice    | 2025-12-08T17:08:27.777Z  INFO 1 --- [EmailService] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
flightservice   | 2025-12-08T17:08:27.811Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
flightservice   | 2025-12-08T17:08:27.813Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
flightservice   | 2025-12-08T17:08:27.841Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.AirLineRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T17:08:27.841Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.BookedSeatsRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T17:08:27.841Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.CityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T17:08:27.843Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.FlightRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T17:08:27.843Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.ScheduleRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T17:08:27.843Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 10 ms. Found 0 Redis repository interfaces.
emailservice    | 2025-12-08T17:08:27.858Z  WARN 1 --- [EmailService] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
authservice     | 2025-12-08T17:08:27.905Z  INFO 1 --- [AuthService] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection ConnectionID:1 ClientConnectionId: 454f4836-79e3-4804-863f-fd552acf9213
authservice     | 2025-12-08T17:08:27.909Z  INFO 1 --- [AuthService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
emailservice    | 2025-12-08T17:08:27.972Z  INFO 1 --- [EmailService] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
emailservice    | 2025-12-08T17:08:28.028Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
authservice     | 2025-12-08T17:08:28.028Z  WARN 1 --- [AuthService] [           main] org.hibernate.orm.deprecation            : HHH90000025: SQLServerDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
emailservice    | 2025-12-08T17:08:28.037Z  INFO 1 --- [EmailService] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
authservice     | 2025-12-08T17:08:28.056Z  INFO 1 --- [AuthService] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
authservice     | 	Database JDBC URL [jdbc:sqlserver://sql_db:1433;concatNullYieldsNull=ON;quotedIdentifier=ON;connectRetryInterval=10;connectRetryCount=1;maxResultBuffer=-1;sendTemporalDataTypesAsStringForBulkCopy=true;delayLoadingLobs=true;useFmtOnly=false;vectorTypeSupport=v1;cacheBulkCopyMetadata=false;bulkCopyForBatchInsertAllowEncryptedValueModifications=false;bulkCopyForBatchInsertTableLock=false;bulkCopyForBatchInsertKeepNulls=false;bulkCopyForBatchInsertKeepIdentity=false;bulkCopyForBatchInsertFireTriggers=false;bulkCopyForBatchInsertCheckConstraints=false;bulkCopyForBatchInsertBatchSize=0;useBulkCopyForBatchInsert=false;cancelQueryTimeout=-1;sslProtocol=TLS;calcBigDecimalPrecision=false;useDefaultJaasConfig=false;jaasConfigurationName=SQLJDBCDriver;statementPoolingCacheSize=0;serverPreparedStatementDiscardThreshold=10;enablePrepareOnFirstPreparedStatementCall=false;fips=false;socketTimeout=0;authentication=NotSpecified;authenticationScheme=nativeAuthentication;xopenStates=false;datetimeParameterType=datetime2;sendTimeAsDatetime=true;replication=false;trustStoreType=JKS;trustServerCertificate=true;TransparentNetworkIPResolution=true;iPAddressPreference=IPv4First;serverNameAsACE=false;sendStringParametersAsUnicode=true;selectMethod=direct;responseBuffering=adaptive;queryTimeout=-1;packetSize=8000;multiSubnetFailover=false;loginTimeout=30;lockTimeout=-1;lastUpdateCount=true;useDefaultGSSCredential=false;prepareMethod=prepexec;encrypt=true;disableStatementPooling=true;databaseName=UserDB;columnEncryptionSetting=Disabled;applicationName=Microsoft JDBC Driver for SQL Server;applicationIntent=readwrite;]
authservice     | 	Database driver: Microsoft JDBC Driver 13.2 for SQL Server
authservice     | 	Database dialect: SQLServerDialect
authservice     | 	Database version: 16.0
authservice     | 	Default catalog/schema: UserDB/dbo
authservice     | 	Autocommit mode: undefined/unknown
authservice     | 	Isolation level: READ_COMMITTED [default READ_COMMITTED]
authservice     | 	JDBC fetch size: 128
authservice     | 	Pool: DatasourceConnectionProviderImpl
authservice     | 	Minimum pool size: undefined/unknown
authservice     | 	Maximum pool size: undefined/unknown
emailservice    | 2025-12-08T17:08:28.058Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
emailservice    | 2025-12-08T17:08:28.058Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
emailservice    | 2025-12-08T17:08:28.058Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
emailservice    | 2025-12-08T17:08:28.058Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
emailservice    | 2025-12-08T17:08:28.058Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
emailservice    | 2025-12-08T17:08:28.058Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
emailservice    | 2025-12-08T17:08:28.058Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-08T17:08:28.372Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
bookingservice  | 2025-12-08T17:08:28.375Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
flightservice   | 2025-12-08T17:08:28.454Z  INFO 1 --- [FlightService] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=0a6497e2-90da-31d3-a8d7-36470356a157
bookingservice  | 2025-12-08T17:08:28.655Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 260 ms. Found 3 JPA repository interfaces.
bookingservice  | 2025-12-08T17:08:28.711Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
bookingservice  | 2025-12-08T17:08:28.714Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
emailservice    | 2025-12-08T17:08:28.735Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
emailservice    | 2025-12-08T17:08:28.737Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
bookingservice  | 2025-12-08T17:08:28.740Z  INFO 1 --- [BookingService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.bookingservice.repository.PassengerRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
bookingservice  | 2025-12-08T17:08:28.741Z  INFO 1 --- [BookingService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.bookingservice.repository.TicketRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
bookingservice  | 2025-12-08T17:08:28.741Z  INFO 1 --- [BookingService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.bookingservice.repository.UsersRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
emailservice    | 2025-12-08T17:08:28.741Z  INFO 1 --- [EmailService] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
bookingservice  | 2025-12-08T17:08:28.741Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 5 ms. Found 0 Redis repository interfaces.
emailservice    | 2025-12-08T17:08:28.744Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765213708743 with initial instances count: 0
emailservice    | 2025-12-08T17:08:28.750Z  INFO 1 --- [EmailService] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application EMAILSERVICE with eureka with status UP
emailservice    | 2025-12-08T17:08:28.751Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765213708751, current=UP, previous=STARTING]
emailservice    | 2025-12-08T17:08:28.754Z  INFO 1 --- [EmailService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_EMAILSERVICE/3e3bdec73b8c:EmailService:8082: registering service...
emailservice    | 2025-12-08T17:08:28.777Z  INFO 1 --- [EmailService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8082 (http) with context path '/'
emailservice    | 2025-12-08T17:08:28.779Z  INFO 1 --- [EmailService] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8082
emailservice    | 2025-12-08T17:08:28.833Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice    | 	allow.auto.create.topics = true
emailservice    | 	auto.commit.interval.ms = 5000
emailservice    | 	auto.offset.reset = latest
emailservice    | 	bootstrap.servers = [kafkaQueue:9092]
emailservice    | 	check.crcs = true
emailservice    | 	client.dns.lookup = use_all_dns_ips
emailservice    | 	client.id = consumer-email-service-group-1
emailservice    | 	client.rack = 
emailservice    | 	connections.max.idle.ms = 540000
emailservice    | 	default.api.timeout.ms = 60000
emailservice    | 	enable.auto.commit = false
emailservice    | 	enable.metrics.push = true
emailservice    | 	exclude.internal.topics = true
emailservice    | 	fetch.max.bytes = 52428800
emailservice    | 	fetch.max.wait.ms = 500
emailservice    | 	fetch.min.bytes = 1
emailservice    | 	group.id = email-service-group
emailservice    | 	group.instance.id = null
emailservice    | 	group.protocol = classic
emailservice    | 	group.remote.assignor = null
emailservice    | 	heartbeat.interval.ms = 3000
emailservice    | 	interceptor.classes = []
emailservice    | 	internal.leave.group.on.close = true
emailservice    | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice    | 	isolation.level = read_uncommitted
emailservice    | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice    | 	max.partition.fetch.bytes = 1048576
emailservice    | 	max.poll.interval.ms = 300000
emailservice    | 	max.poll.records = 500
emailservice    | 	metadata.max.age.ms = 300000
emailservice    | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice    | 	metadata.recovery.strategy = rebootstrap
emailservice    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice    | 	metrics.num.samples = 2
emailservice    | 	metrics.recording.level = INFO
emailservice    | 	metrics.sample.window.ms = 30000
emailservice    | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice    | 	receive.buffer.bytes = 65536
emailservice    | 	reconnect.backoff.max.ms = 1000
emailservice    | 	reconnect.backoff.ms = 50
emailservice    | 	request.timeout.ms = 30000
emailservice    | 	retry.backoff.max.ms = 1000
emailservice    | 	retry.backoff.ms = 100
emailservice    | 	sasl.client.callback.handler.class = null
emailservice    | 	sasl.jaas.config = null
emailservice    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice    | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice    | 	sasl.kerberos.service.name = null
emailservice    | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice    | 	sasl.login.callback.handler.class = null
emailservice    | 	sasl.login.class = null
emailservice    | 	sasl.login.connect.timeout.ms = null
emailservice    | 	sasl.login.read.timeout.ms = null
emailservice    | 	sasl.login.refresh.buffer.seconds = 300
emailservice    | 	sasl.login.refresh.min.period.seconds = 60
emailservice    | 	sasl.login.refresh.window.factor = 0.8
emailservice    | 	sasl.login.refresh.window.jitter = 0.05
emailservice    | 	sasl.login.retry.backoff.max.ms = 10000
emailservice    | 	sasl.login.retry.backoff.ms = 100
emailservice    | 	sasl.mechanism = GSSAPI
emailservice    | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice    | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice    | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice    | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice    | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice    | 	sasl.oauthbearer.assertion.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice    | 	sasl.oauthbearer.assertion.template.file = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice    | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice    | 	sasl.oauthbearer.expected.audience = null
emailservice    | 	sasl.oauthbearer.expected.issuer = null
emailservice    | 	sasl.oauthbearer.header.urlencode = false
emailservice    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice    | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice    | 	sasl.oauthbearer.scope = null
emailservice    | 	sasl.oauthbearer.scope.claim.name = scope
emailservice    | 	sasl.oauthbearer.sub.claim.name = sub
emailservice    | 	sasl.oauthbearer.token.endpoint.url = null
emailservice    | 	security.protocol = PLAINTEXT
emailservice    | 	security.providers = null
emailservice    | 	send.buffer.bytes = 131072
emailservice    | 	session.timeout.ms = 45000
emailservice    | 	share.acknowledgement.mode = implicit
emailservice    | 	socket.connection.setup.timeout.max.ms = 30000
emailservice    | 	socket.connection.setup.timeout.ms = 10000
emailservice    | 	ssl.cipher.suites = null
emailservice    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice    | 	ssl.endpoint.identification.algorithm = https
emailservice    | 	ssl.engine.factory.class = null
emailservice    | 	ssl.key.password = null
emailservice    | 	ssl.keymanager.algorithm = SunX509
emailservice    | 	ssl.keystore.certificate.chain = null
emailservice    | 	ssl.keystore.key = null
emailservice    | 	ssl.keystore.location = null
emailservice    | 	ssl.keystore.password = null
emailservice    | 	ssl.keystore.type = JKS
emailservice    | 	ssl.protocol = TLSv1.3
emailservice    | 	ssl.provider = null
emailservice    | 	ssl.secure.random.implementation = null
emailservice    | 	ssl.trustmanager.algorithm = PKIX
emailservice    | 	ssl.truststore.certificates = null
emailservice    | 	ssl.truststore.location = null
emailservice    | 	ssl.truststore.password = null
emailservice    | 	ssl.truststore.type = JKS
emailservice    | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice    | 
emailservice    | 2025-12-08T17:08:28.891Z  INFO 1 --- [EmailService] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
eureka          | 2025-12-08T17:08:28.968Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : Registered instance EMAILSERVICE/3e3bdec73b8c:EmailService:8082 with status UP (replication=false)
emailservice    | 2025-12-08T17:08:28.977Z  INFO 1 --- [EmailService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_EMAILSERVICE/3e3bdec73b8c:EmailService:8082 - registration status: 204
apigateway      | 2025-12-08T17:08:28.992Z  INFO 1 --- [ApiGateway] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=f3f2424c-8de8-3273-b0fb-8226e559bab7
emailservice    | 2025-12-08T17:08:29.155Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice    | 2025-12-08T17:08:29.155Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice    | 2025-12-08T17:08:29.155Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1765213709153
emailservice    | 2025-12-08T17:08:29.160Z  INFO 1 --- [EmailService] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Subscribed to topic(s): ticket.cancelled
emailservice    | 2025-12-08T17:08:29.182Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice    | 	allow.auto.create.topics = true
emailservice    | 	auto.commit.interval.ms = 5000
emailservice    | 	auto.offset.reset = latest
emailservice    | 	bootstrap.servers = [kafkaQueue:9092]
emailservice    | 	check.crcs = true
emailservice    | 	client.dns.lookup = use_all_dns_ips
emailservice    | 	client.id = consumer-email-service-group-2
emailservice    | 	client.rack = 
emailservice    | 	connections.max.idle.ms = 540000
emailservice    | 	default.api.timeout.ms = 60000
emailservice    | 	enable.auto.commit = false
emailservice    | 	enable.metrics.push = true
emailservice    | 	exclude.internal.topics = true
emailservice    | 	fetch.max.bytes = 52428800
emailservice    | 	fetch.max.wait.ms = 500
emailservice    | 	fetch.min.bytes = 1
emailservice    | 	group.id = email-service-group
emailservice    | 	group.instance.id = null
emailservice    | 	group.protocol = classic
emailservice    | 	group.remote.assignor = null
emailservice    | 	heartbeat.interval.ms = 3000
emailservice    | 	interceptor.classes = []
emailservice    | 	internal.leave.group.on.close = true
emailservice    | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice    | 	isolation.level = read_uncommitted
emailservice    | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice    | 	max.partition.fetch.bytes = 1048576
emailservice    | 	max.poll.interval.ms = 300000
emailservice    | 	max.poll.records = 500
emailservice    | 	metadata.max.age.ms = 300000
emailservice    | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice    | 	metadata.recovery.strategy = rebootstrap
emailservice    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice    | 	metrics.num.samples = 2
emailservice    | 	metrics.recording.level = INFO
emailservice    | 	metrics.sample.window.ms = 30000
emailservice    | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice    | 	receive.buffer.bytes = 65536
emailservice    | 	reconnect.backoff.max.ms = 1000
emailservice    | 	reconnect.backoff.ms = 50
emailservice    | 	request.timeout.ms = 30000
emailservice    | 	retry.backoff.max.ms = 1000
emailservice    | 	retry.backoff.ms = 100
emailservice    | 	sasl.client.callback.handler.class = null
emailservice    | 	sasl.jaas.config = null
emailservice    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice    | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice    | 	sasl.kerberos.service.name = null
emailservice    | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice    | 	sasl.login.callback.handler.class = null
emailservice    | 	sasl.login.class = null
emailservice    | 	sasl.login.connect.timeout.ms = null
emailservice    | 	sasl.login.read.timeout.ms = null
emailservice    | 	sasl.login.refresh.buffer.seconds = 300
emailservice    | 	sasl.login.refresh.min.period.seconds = 60
emailservice    | 	sasl.login.refresh.window.factor = 0.8
emailservice    | 	sasl.login.refresh.window.jitter = 0.05
emailservice    | 	sasl.login.retry.backoff.max.ms = 10000
emailservice    | 	sasl.login.retry.backoff.ms = 100
emailservice    | 	sasl.mechanism = GSSAPI
emailservice    | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice    | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice    | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice    | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice    | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice    | 	sasl.oauthbearer.assertion.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice    | 	sasl.oauthbearer.assertion.template.file = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice    | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice    | 	sasl.oauthbearer.expected.audience = null
emailservice    | 	sasl.oauthbearer.expected.issuer = null
emailservice    | 	sasl.oauthbearer.header.urlencode = false
emailservice    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice    | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice    | 	sasl.oauthbearer.scope = null
emailservice    | 	sasl.oauthbearer.scope.claim.name = scope
emailservice    | 	sasl.oauthbearer.sub.claim.name = sub
emailservice    | 	sasl.oauthbearer.token.endpoint.url = null
emailservice    | 	security.protocol = PLAINTEXT
emailservice    | 	security.providers = null
emailservice    | 	send.buffer.bytes = 131072
emailservice    | 	session.timeout.ms = 45000
emailservice    | 	share.acknowledgement.mode = implicit
emailservice    | 	socket.connection.setup.timeout.max.ms = 30000
emailservice    | 	socket.connection.setup.timeout.ms = 10000
emailservice    | 	ssl.cipher.suites = null
emailservice    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice    | 	ssl.endpoint.identification.algorithm = https
emailservice    | 	ssl.engine.factory.class = null
emailservice    | 	ssl.key.password = null
emailservice    | 	ssl.keymanager.algorithm = SunX509
emailservice    | 	ssl.keystore.certificate.chain = null
emailservice    | 	ssl.keystore.key = null
emailservice    | 	ssl.keystore.location = null
emailservice    | 	ssl.keystore.password = null
emailservice    | 	ssl.keystore.type = JKS
emailservice    | 	ssl.protocol = TLSv1.3
emailservice    | 	ssl.provider = null
emailservice    | 	ssl.secure.random.implementation = null
emailservice    | 	ssl.trustmanager.algorithm = PKIX
emailservice    | 	ssl.truststore.certificates = null
emailservice    | 	ssl.truststore.location = null
emailservice    | 	ssl.truststore.password = null
emailservice    | 	ssl.truststore.type = JKS
emailservice    | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice    | 
emailservice    | 2025-12-08T17:08:29.183Z  INFO 1 --- [EmailService] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice    | 2025-12-08T17:08:29.217Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice    | 2025-12-08T17:08:29.217Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice    | 2025-12-08T17:08:29.217Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1765213709217
emailservice    | 2025-12-08T17:08:29.222Z  INFO 1 --- [EmailService] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Subscribed to topic(s): schedule.added
emailservice    | 2025-12-08T17:08:29.230Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice    | 	allow.auto.create.topics = true
emailservice    | 	auto.commit.interval.ms = 5000
emailservice    | 	auto.offset.reset = latest
emailservice    | 	bootstrap.servers = [kafkaQueue:9092]
emailservice    | 	check.crcs = true
emailservice    | 	client.dns.lookup = use_all_dns_ips
emailservice    | 	client.id = consumer-email-service-group-3
emailservice    | 	client.rack = 
emailservice    | 	connections.max.idle.ms = 540000
emailservice    | 	default.api.timeout.ms = 60000
emailservice    | 	enable.auto.commit = false
emailservice    | 	enable.metrics.push = true
emailservice    | 	exclude.internal.topics = true
emailservice    | 	fetch.max.bytes = 52428800
emailservice    | 	fetch.max.wait.ms = 500
emailservice    | 	fetch.min.bytes = 1
emailservice    | 	group.id = email-service-group
emailservice    | 	group.instance.id = null
emailservice    | 	group.protocol = classic
emailservice    | 	group.remote.assignor = null
emailservice    | 	heartbeat.interval.ms = 3000
emailservice    | 	interceptor.classes = []
emailservice    | 	internal.leave.group.on.close = true
emailservice    | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice    | 	isolation.level = read_uncommitted
emailservice    | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice    | 	max.partition.fetch.bytes = 1048576
emailservice    | 	max.poll.interval.ms = 300000
emailservice    | 	max.poll.records = 500
emailservice    | 	metadata.max.age.ms = 300000
emailservice    | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice    | 	metadata.recovery.strategy = rebootstrap
emailservice    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice    | 	metrics.num.samples = 2
emailservice    | 	metrics.recording.level = INFO
emailservice    | 	metrics.sample.window.ms = 30000
emailservice    | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice    | 	receive.buffer.bytes = 65536
emailservice    | 	reconnect.backoff.max.ms = 1000
emailservice    | 	reconnect.backoff.ms = 50
emailservice    | 	request.timeout.ms = 30000
emailservice    | 	retry.backoff.max.ms = 1000
emailservice    | 	retry.backoff.ms = 100
emailservice    | 	sasl.client.callback.handler.class = null
emailservice    | 	sasl.jaas.config = null
emailservice    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice    | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice    | 	sasl.kerberos.service.name = null
emailservice    | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice    | 	sasl.login.callback.handler.class = null
emailservice    | 	sasl.login.class = null
emailservice    | 	sasl.login.connect.timeout.ms = null
emailservice    | 	sasl.login.read.timeout.ms = null
emailservice    | 	sasl.login.refresh.buffer.seconds = 300
emailservice    | 	sasl.login.refresh.min.period.seconds = 60
emailservice    | 	sasl.login.refresh.window.factor = 0.8
emailservice    | 	sasl.login.refresh.window.jitter = 0.05
emailservice    | 	sasl.login.retry.backoff.max.ms = 10000
emailservice    | 	sasl.login.retry.backoff.ms = 100
emailservice    | 	sasl.mechanism = GSSAPI
emailservice    | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice    | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice    | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice    | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice    | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice    | 	sasl.oauthbearer.assertion.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice    | 	sasl.oauthbearer.assertion.template.file = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice    | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice    | 	sasl.oauthbearer.expected.audience = null
emailservice    | 	sasl.oauthbearer.expected.issuer = null
emailservice    | 	sasl.oauthbearer.header.urlencode = false
emailservice    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice    | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice    | 	sasl.oauthbearer.scope = null
emailservice    | 	sasl.oauthbearer.scope.claim.name = scope
emailservice    | 	sasl.oauthbearer.sub.claim.name = sub
emailservice    | 	sasl.oauthbearer.token.endpoint.url = null
emailservice    | 	security.protocol = PLAINTEXT
emailservice    | 	security.providers = null
emailservice    | 	send.buffer.bytes = 131072
emailservice    | 	session.timeout.ms = 45000
emailservice    | 	share.acknowledgement.mode = implicit
emailservice    | 	socket.connection.setup.timeout.max.ms = 30000
emailservice    | 	socket.connection.setup.timeout.ms = 10000
emailservice    | 	ssl.cipher.suites = null
emailservice    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice    | 	ssl.endpoint.identification.algorithm = https
emailservice    | 	ssl.engine.factory.class = null
emailservice    | 	ssl.key.password = null
emailservice    | 	ssl.keymanager.algorithm = SunX509
emailservice    | 	ssl.keystore.certificate.chain = null
emailservice    | 	ssl.keystore.key = null
emailservice    | 	ssl.keystore.location = null
emailservice    | 	ssl.keystore.password = null
emailservice    | 	ssl.keystore.type = JKS
emailservice    | 	ssl.protocol = TLSv1.3
emailservice    | 	ssl.provider = null
emailservice    | 	ssl.secure.random.implementation = null
emailservice    | 	ssl.trustmanager.algorithm = PKIX
emailservice    | 	ssl.truststore.certificates = null
emailservice    | 	ssl.truststore.location = null
emailservice    | 	ssl.truststore.password = null
emailservice    | 	ssl.truststore.type = JKS
emailservice    | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice    | 
emailservice    | 2025-12-08T17:08:29.232Z  INFO 1 --- [EmailService] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice    | 2025-12-08T17:08:29.241Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice    | 2025-12-08T17:08:29.241Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice    | 2025-12-08T17:08:29.242Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1765213709241
emailservice    | 2025-12-08T17:08:29.243Z  INFO 1 --- [EmailService] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Subscribed to topic(s): ticket.booked
emailservice    | 2025-12-08T17:08:29.256Z  INFO 1 --- [EmailService] [           main] o.e.e.EmailServiceApplication            : Started EmailServiceApplication in 6.947 seconds (process running for 7.961)
authservice     | 2025-12-08T17:08:29.403Z  INFO 1 --- [AuthService] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
bookingservice  | 2025-12-08T17:08:29.477Z  INFO 1 --- [BookingService] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=8922e5d5-be11-3bd2-8ac6-6f5dc10dcc0d
kafkaQueue      | [2025-12-08 17:08:29,728] INFO Sent auto-creation request for Set(schedule.added) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
kafkaQueue      | [2025-12-08 17:08:29,728] INFO Sent auto-creation request for Set(ticket.booked) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
kafkaQueue      | [2025-12-08 17:08:29,728] INFO Sent auto-creation request for Set(ticket.cancelled) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
eureka          | 2025-12-08T17:08:29.732Z  INFO 1 --- [ServiceRegistry] [io-8761-exec-10] c.n.e.registry.AbstractInstanceRegistry  : Registered instance EMAILSERVICE/3e3bdec73b8c:EmailService:8082 with status UP (replication=true)
kafkaQueue      | [2025-12-08 17:08:29,740] INFO Sent auto-creation request for Set(__consumer_offsets) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
emailservice    | 2025-12-08T17:08:29.742Z  WARN 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {schedule.added=UNKNOWN_TOPIC_OR_PARTITION}
emailservice    | 2025-12-08T17:08:29.743Z  WARN 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {ticket.booked=UNKNOWN_TOPIC_OR_PARTITION}
emailservice    | 2025-12-08T17:08:29.743Z  WARN 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {ticket.cancelled=UNKNOWN_TOPIC_OR_PARTITION}
emailservice    | 2025-12-08T17:08:29.745Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice    | 2025-12-08T17:08:29.746Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice    | 2025-12-08T17:08:29.745Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
flightservice   | 2025-12-08T17:08:29.750Z  INFO 1 --- [FlightService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8080 (http)
flightservice   | 2025-12-08T17:08:29.770Z  INFO 1 --- [FlightService] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
flightservice   | 2025-12-08T17:08:29.771Z  INFO 1 --- [FlightService] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
kafkaQueue      | [2025-12-08 17:08:29,785] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ticket.booked-0) (kafka.server.ReplicaFetcherManager)
kafkaQueue      | [2025-12-08 17:08:29,805] INFO [LogLoader partition=ticket.booked-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,812] INFO Created log for partition ticket.booked-0 in /tmp/kafka-logs/ticket.booked-0 with properties {} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,814] INFO [Partition ticket.booked-0 broker=1] No checkpointed highwatermark is found for partition ticket.booked-0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,817] INFO [Partition ticket.booked-0 broker=1] Log loaded for partition ticket.booked-0 with initial high watermark 0 (kafka.cluster.Partition)
flightservice   | 2025-12-08T17:08:29.831Z  INFO 1 --- [FlightService] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 3949 ms
kafkaQueue      | [2025-12-08 17:08:29,837] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ticket.cancelled-0) (kafka.server.ReplicaFetcherManager)
kafkaQueue      | [2025-12-08 17:08:29,844] INFO [LogLoader partition=ticket.cancelled-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,846] INFO Created log for partition ticket.cancelled-0 in /tmp/kafka-logs/ticket.cancelled-0 with properties {} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,850] INFO [Partition ticket.cancelled-0 broker=1] No checkpointed highwatermark is found for partition ticket.cancelled-0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,851] INFO [Partition ticket.cancelled-0 broker=1] Log loaded for partition ticket.cancelled-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,858] INFO Sent auto-creation request for Set(schedule.added) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
kafkaQueue      | [2025-12-08 17:08:29,860] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(schedule.added-0) (kafka.server.ReplicaFetcherManager)
emailservice    | 2025-12-08T17:08:29.860Z  WARN 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {schedule.added=UNKNOWN_TOPIC_OR_PARTITION}
kafkaQueue      | [2025-12-08 17:08:29,866] INFO [LogLoader partition=schedule.added-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,870] INFO Created log for partition schedule.added-0 in /tmp/kafka-logs/schedule.added-0 with properties {} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,871] INFO [Partition schedule.added-0 broker=1] No checkpointed highwatermark is found for partition schedule.added-0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,872] INFO [Partition schedule.added-0 broker=1] Log loaded for partition schedule.added-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,898] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
kafkaQueue      | [2025-12-08 17:08:29,905] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,906] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,908] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,908] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,918] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,919] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,919] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,920] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,929] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,931] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,931] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,932] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,941] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,942] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,943] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,943] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,952] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,953] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,954] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,954] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,963] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,965] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,965] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,965] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,974] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,975] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,976] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,976] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,985] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:29,987] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:29,988] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,988] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:29,999] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,000] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,001] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,001] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,012] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,013] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,013] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,013] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,023] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,025] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,026] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,026] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,040] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,041] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,042] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,042] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,055] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,056] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,058] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,058] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,070] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,080] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,081] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,081] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.092Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.092Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,095] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,097] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
emailservice    | 2025-12-08T17:08:30.097Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,098] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,098] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.100Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.100Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.101Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 17:08:30,113] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,114] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,115] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,115] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,126] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,129] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,129] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,131] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.141Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.142Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.147Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.148Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.148Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.149Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.150Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.150Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T17:08:30.151Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.151Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.151Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Client requested disconnect from node 2147483646
kafkaQueue      | [2025-12-08 17:08:30,152] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T17:08:30.151Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Client requested disconnect from node 2147483646
kafkaQueue      | [2025-12-08 17:08:30,155] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,156] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,156] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.167Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.167Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.170Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.170Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.173Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.173Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.173Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.174Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.174Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,178] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,179] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,180] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,181] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,191] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,192] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,192] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,192] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,204] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,205] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,205] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,206] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,218] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,221] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,222] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,222] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,234] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,235] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,236] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,236] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,248] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,249] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,249] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,249] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,261] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,262] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,263] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,263] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.272Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.275Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T17:08:30.277Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 17:08:30,279] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,281] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,281] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,281] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.284Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.285Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T17:08:30.285Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.286Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.287Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.288Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T17:08:30.288Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.295Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.296Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.296Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T17:08:30.296Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.296Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.296Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.297Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.299Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T17:08:30.296Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.300Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.304Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,305] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T17:08:30.305Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
authservice     | 2025-12-08T17:08:30.305Z  INFO 1 --- [AuthService] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
emailservice    | 2025-12-08T17:08:30.306Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.311Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.311Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,311] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,312] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,312] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.311Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.311Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T17:08:30.316Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.316Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.316Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,326] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,329] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,330] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,330] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,342] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,343] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,343] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,344] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,354] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,355] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,355] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,356] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,365] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,367] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,368] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,368] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,375] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,376] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,376] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,376] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,390] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,391] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,392] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,392] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.395Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.399Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T17:08:30.403Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 17:08:30,404] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,405] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,405] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,406] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.416Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.419Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
flightservice   | 2025-12-08T17:08:30.421Z  INFO 1 --- [FlightService] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
kafkaQueue      | [2025-12-08 17:08:30,422] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,423] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,423] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,423] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.424Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.424Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.425Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.425Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.425Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T17:08:30.430Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.430Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.430Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.430Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.430Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.431Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.431Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Client requested disconnect from node 2147483646
kafkaQueue      | [2025-12-08 17:08:30,432] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,432] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,433] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,433] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.436Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.438Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.438Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.440Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.441Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
kafkaQueue      | [2025-12-08 17:08:30,443] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,444] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,445] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,445] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.444Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 17:08:30,458] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,459] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,461] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,461] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.454Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.463Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.463Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.464Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Client requested disconnect from node 2147483646
kafkaQueue      | [2025-12-08 17:08:30,472] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,474] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
authservice     | 2025-12-08T17:08:30.474Z  INFO 1 --- [AuthService] [           main] o.s.d.j.r.query.QueryEnhancerFactories   : Hibernate is in classpath; If applicable, HQL parser will be used.
emailservice    | 2025-12-08T17:08:30.474Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.475Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
kafkaQueue      | [2025-12-08 17:08:30,475] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,475] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.476Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,486] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,489] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,490] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,491] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,502] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,502] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,503] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,503] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
apigateway      | 2025-12-08T17:08:30.507Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [After]
apigateway      | 2025-12-08T17:08:30.508Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Before]
apigateway      | 2025-12-08T17:08:30.508Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Between]
apigateway      | 2025-12-08T17:08:30.508Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Cookie]
apigateway      | 2025-12-08T17:08:30.508Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Header]
apigateway      | 2025-12-08T17:08:30.508Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Host]
apigateway      | 2025-12-08T17:08:30.509Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Method]
apigateway      | 2025-12-08T17:08:30.509Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Path]
apigateway      | 2025-12-08T17:08:30.509Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Query]
apigateway      | 2025-12-08T17:08:30.509Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [ReadBody]
apigateway      | 2025-12-08T17:08:30.509Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [RemoteAddr]
apigateway      | 2025-12-08T17:08:30.509Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [XForwardedRemoteAddr]
apigateway      | 2025-12-08T17:08:30.509Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Weight]
apigateway      | 2025-12-08T17:08:30.509Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [CloudFoundryRouteService]
kafkaQueue      | [2025-12-08 17:08:30,513] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,514] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,514] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,515] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,524] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T17:08:30.527Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,528] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,528] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,529] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.529Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T17:08:30.530Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.534Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.534Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.534Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.534Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T17:08:30.540Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.541Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.542Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,541] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,542] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,543] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,543] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
flightservice   | 2025-12-08T17:08:30.549Z  INFO 1 --- [FlightService] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 7.1.8.Final
kafkaQueue      | [2025-12-08 17:08:30,554] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,555] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,576] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,577] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.579Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.581Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T17:08:30.582Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.584Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,585] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T17:08:30.586Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
kafkaQueue      | [2025-12-08 17:08:30,587] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,587] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,588] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.589Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.589Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.590Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.590Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.590Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T17:08:30.594Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.594Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.595Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.595Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.595Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.595Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T17:08:30.596Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T17:08:30.596Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Client requested disconnect from node 2147483646
kafkaQueue      | [2025-12-08 17:08:30,597] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,598] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,599] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,599] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T17:08:30.600Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.600Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T17:08:30.601Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,608] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,609] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,609] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,609] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,617] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,618] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,618] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,618] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,628] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 17:08:30,630] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 17:08:30,630] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,630] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 17:08:30,640] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-13 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,644] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-46 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,644] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-9 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-42 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-21 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-17 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-30 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-26 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-5 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-38 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-1 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-34 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,645] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-16 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,646] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-45 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,646] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-12 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,647] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-41 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,648] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-24 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,649] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-20 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,649] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-49 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,650] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-0 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,651] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-29 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,651] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-25 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,651] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-8 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,651] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-37 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,652] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-4 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,652] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-33 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,652] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-15 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,652] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-48 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,652] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-11 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,653] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-44 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,653] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-23 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,653] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-19 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,653] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-32 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,653] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-28 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,653] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-7 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,653] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-40 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,653] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-3 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,654] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-36 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,654] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-47 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,654] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-14 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,656] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-43 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,656] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-10 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T17:08:30.657Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,658] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-22 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,659] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-18 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,659] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-31 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,660] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-27 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T17:08:30.660Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
kafkaQueue      | [2025-12-08 17:08:30,660] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-39 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,660] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-6 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,661] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-35 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T17:08:30.661Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 17:08:30,661] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-2 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,662] INFO [DynamicConfigPublisher broker id=1] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
kafkaQueue      | [2025-12-08 17:08:30,665] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-10 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,665] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-32 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,665] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-39 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,666] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-45 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,666] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-20 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,666] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-34 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,666] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-1 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,667] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-16 with epoch 0 in 2ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,667] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-19 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,667] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-26 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,667] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-2 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-35 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-7 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-21 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-0 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-41 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-28 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-14 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-18 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-12 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-40 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,668] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-13 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,670] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-11 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,669] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-38 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,671] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-46 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,669] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-8 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,673] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-43 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,673] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-9 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,675] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-33 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,674] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Empty state. Created a new member id consumer-email-service-group-2-bbbc69c9-c246-44df-816d-4632a96bd66e and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue      | [2025-12-08 17:08:30,674] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-48 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,676] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-6 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,677] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-37 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,677] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-5 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,677] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-30 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,676] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-49 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,678] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-42 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,678] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-4 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,678] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-31 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,679] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-3 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,679] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-29 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,679] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-25 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,679] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-15 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,679] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-24 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,680] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-44 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,680] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-23 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,680] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-17 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,680] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-27 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,676] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-22 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 17:08:30,680] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-47 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T17:08:30.680Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-2-bbbc69c9-c246-44df-816d-4632a96bd66e
kafkaQueue      | [2025-12-08 17:08:30,681] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-36 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T17:08:30.681Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 17:08:30,683] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-2-bbbc69c9-c246-44df-816d-4632a96bd66e joins group email-service-group in Empty state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue      | [2025-12-08 17:08:30,684] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Preparing to rebalance group email-service-group in state PreparingRebalance with old generation 0 (reason: Adding new member consumer-email-service-group-2-bbbc69c9-c246-44df-816d-4632a96bd66e with group instance id null; client reason: need to re-join with the given member-id: consumer-email-service-group-2-bbbc69c9-c246-44df-816d-4632a96bd66e). (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice    | 2025-12-08T17:08:30.706Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T17:08:30.708Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T17:08:30.712Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.719Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 17:08:30,720] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in PreparingRebalance state. Created a new member id consumer-email-service-group-1-054a4c66-d38d-4115-9c4b-6b403ed6e405 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice    | 2025-12-08T17:08:30.721Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T17:08:30.721Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-1-054a4c66-d38d-4115-9c4b-6b403ed6e405
emailservice    | 2025-12-08T17:08:30.722Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 17:08:30,725] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-1-054a4c66-d38d-4115-9c4b-6b403ed6e405 joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue      | [2025-12-08 17:08:30,729] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in PreparingRebalance state. Created a new member id consumer-email-service-group-3-c58d74eb-39eb-47e3-ac81-7f1065106016 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice    | 2025-12-08T17:08:30.734Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-3-c58d74eb-39eb-47e3-ac81-7f1065106016
emailservice    | 2025-12-08T17:08:30.735Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 17:08:30,738] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-3-c58d74eb-39eb-47e3-ac81-7f1065106016 joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
apigateway      | 2025-12-08T17:08:30.891Z  INFO 1 --- [ApiGateway] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
apigateway      | 2025-12-08T17:08:30.954Z  WARN 1 --- [ApiGateway] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
apigateway      | 2025-12-08T17:08:31.023Z  INFO 1 --- [ApiGateway] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
bookingservice  | 2025-12-08T17:08:31.033Z  INFO 1 --- [BookingService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8081 (http)
bookingservice  | 2025-12-08T17:08:31.055Z  INFO 1 --- [BookingService] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
bookingservice  | 2025-12-08T17:08:31.055Z  INFO 1 --- [BookingService] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
apigateway      | 2025-12-08T17:08:31.054Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
apigateway      | 2025-12-08T17:08:31.062Z  INFO 1 --- [ApiGateway] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
apigateway      | 2025-12-08T17:08:31.075Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
apigateway      | 2025-12-08T17:08:31.075Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
apigateway      | 2025-12-08T17:08:31.075Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
apigateway      | 2025-12-08T17:08:31.075Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
apigateway      | 2025-12-08T17:08:31.076Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
apigateway      | 2025-12-08T17:08:31.076Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
apigateway      | 2025-12-08T17:08:31.076Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-08T17:08:31.090Z  INFO 1 --- [BookingService] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 4325 ms
authservice     | 2025-12-08T17:08:31.099Z  INFO 1 --- [AuthService] [           main] eAuthenticationProviderManagerConfigurer : Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
authservice     | 2025-12-08T17:08:31.100Z  WARN 1 --- [AuthService] [           main] r$InitializeUserDetailsManagerConfigurer : Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
authservice     | 2025-12-08T17:08:31.203Z  WARN 1 --- [AuthService] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
flightservice   | 2025-12-08T17:08:31.325Z  INFO 1 --- [FlightService] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
flightservice   | 2025-12-08T17:08:31.362Z  INFO 1 --- [FlightService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
apigateway      | 2025-12-08T17:08:31.440Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
apigateway      | 2025-12-08T17:08:31.443Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
apigateway      | 2025-12-08T17:08:31.446Z  INFO 1 --- [ApiGateway] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
apigateway      | 2025-12-08T17:08:31.447Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765213711447 with initial instances count: 1
apigateway      | 2025-12-08T17:08:31.451Z  INFO 1 --- [ApiGateway] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application APIGATEWAY with eureka with status UP
apigateway      | 2025-12-08T17:08:31.452Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765213711452, current=UP, previous=STARTING]
apigateway      | 2025-12-08T17:08:31.454Z  INFO 1 --- [ApiGateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/84a992112de8:ApiGateway:9000: registering service...
eureka          | 2025-12-08T17:08:31.505Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance APIGATEWAY/84a992112de8:ApiGateway:9000 with status UP (replication=false)
apigateway      | 2025-12-08T17:08:31.506Z  INFO 1 --- [ApiGateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/84a992112de8:ApiGateway:9000 - registration status: 204
bookingservice  | 2025-12-08T17:08:31.531Z  INFO 1 --- [BookingService] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
apigateway      | 2025-12-08T17:08:31.617Z  INFO 1 --- [ApiGateway] [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 9000 (http)
apigateway      | 2025-12-08T17:08:31.619Z  INFO 1 --- [ApiGateway] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 9000
bookingservice  | 2025-12-08T17:08:31.621Z  INFO 1 --- [BookingService] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 7.1.8.Final
apigateway      | 2025-12-08T17:08:31.663Z  INFO 1 --- [ApiGateway] [           main] o.e.apigateway.ApiGatewayApplication     : Started ApiGatewayApplication in 8.281 seconds (process running for 9.643)
flightservice   | 2025-12-08T17:08:31.682Z  INFO 1 --- [FlightService] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection ConnectionID:1 ClientConnectionId: f88cc754-1daf-4ca6-ad43-475095886db8
flightservice   | 2025-12-08T17:08:31.684Z  INFO 1 --- [FlightService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
flightservice   | 2025-12-08T17:08:31.759Z  WARN 1 --- [FlightService] [           main] org.hibernate.orm.deprecation            : HHH90000025: SQLServerDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
flightservice   | 2025-12-08T17:08:31.781Z  INFO 1 --- [FlightService] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
flightservice   | 	Database JDBC URL [jdbc:sqlserver://sql_db:1433;concatNullYieldsNull=ON;quotedIdentifier=ON;connectRetryInterval=10;connectRetryCount=1;maxResultBuffer=-1;sendTemporalDataTypesAsStringForBulkCopy=true;delayLoadingLobs=true;useFmtOnly=false;vectorTypeSupport=v1;cacheBulkCopyMetadata=false;bulkCopyForBatchInsertAllowEncryptedValueModifications=false;bulkCopyForBatchInsertTableLock=false;bulkCopyForBatchInsertKeepNulls=false;bulkCopyForBatchInsertKeepIdentity=false;bulkCopyForBatchInsertFireTriggers=false;bulkCopyForBatchInsertCheckConstraints=false;bulkCopyForBatchInsertBatchSize=0;useBulkCopyForBatchInsert=false;cancelQueryTimeout=-1;sslProtocol=TLS;calcBigDecimalPrecision=false;useDefaultJaasConfig=false;jaasConfigurationName=SQLJDBCDriver;statementPoolingCacheSize=0;serverPreparedStatementDiscardThreshold=10;enablePrepareOnFirstPreparedStatementCall=false;fips=false;socketTimeout=0;authentication=NotSpecified;authenticationScheme=nativeAuthentication;xopenStates=false;datetimeParameterType=datetime2;sendTimeAsDatetime=true;replication=false;trustStoreType=JKS;trustServerCertificate=true;TransparentNetworkIPResolution=true;iPAddressPreference=IPv4First;serverNameAsACE=false;sendStringParametersAsUnicode=true;selectMethod=direct;responseBuffering=adaptive;queryTimeout=-1;packetSize=8000;multiSubnetFailover=false;loginTimeout=30;lockTimeout=-1;lastUpdateCount=true;useDefaultGSSCredential=false;prepareMethod=prepexec;encrypt=true;disableStatementPooling=true;databaseName=FlightBooking;columnEncryptionSetting=Disabled;applicationName=Microsoft JDBC Driver for SQL Server;applicationIntent=readwrite;]
flightservice   | 	Database driver: Microsoft JDBC Driver 13.2 for SQL Server
flightservice   | 	Database dialect: SQLServerDialect
flightservice   | 	Database version: 16.0
flightservice   | 	Default catalog/schema: FlightBooking/dbo
flightservice   | 	Autocommit mode: undefined/unknown
flightservice   | 	Isolation level: READ_COMMITTED [default READ_COMMITTED]
flightservice   | 	JDBC fetch size: 128
flightservice   | 	Pool: DatasourceConnectionProviderImpl
flightservice   | 	Minimum pool size: undefined/unknown
flightservice   | 	Maximum pool size: undefined/unknown
eureka          | 2025-12-08T17:08:32.021Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-3] c.n.e.registry.AbstractInstanceRegistry  : Registered instance APIGATEWAY/84a992112de8:ApiGateway:9000 with status UP (replication=true)
authservice     | 2025-12-08T17:08:32.160Z  INFO 1 --- [AuthService] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
authservice     | 2025-12-08T17:08:32.210Z  WARN 1 --- [AuthService] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
authservice     | 2025-12-08T17:08:32.233Z  INFO 1 --- [AuthService] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
bookingservice  | 2025-12-08T17:08:32.246Z  INFO 1 --- [BookingService] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
authservice     | 2025-12-08T17:08:32.277Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
authservice     | 2025-12-08T17:08:32.283Z  INFO 1 --- [AuthService] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
bookingservice  | 2025-12-08T17:08:32.288Z  INFO 1 --- [BookingService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
authservice     | 2025-12-08T17:08:32.299Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
authservice     | 2025-12-08T17:08:32.299Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
authservice     | 2025-12-08T17:08:32.299Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
authservice     | 2025-12-08T17:08:32.299Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
authservice     | 2025-12-08T17:08:32.299Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
authservice     | 2025-12-08T17:08:32.299Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
authservice     | 2025-12-08T17:08:32.299Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-08T17:08:32.610Z  INFO 1 --- [BookingService] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection ConnectionID:1 ClientConnectionId: c3a43baa-b6e6-4dcb-a37f-ba6593d57366
bookingservice  | 2025-12-08T17:08:32.611Z  INFO 1 --- [BookingService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
bookingservice  | 2025-12-08T17:08:32.668Z  WARN 1 --- [BookingService] [           main] org.hibernate.orm.deprecation            : HHH90000025: SQLServerDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
bookingservice  | 2025-12-08T17:08:32.685Z  INFO 1 --- [BookingService] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
bookingservice  | 	Database JDBC URL [jdbc:sqlserver://sql_db:1433;concatNullYieldsNull=ON;quotedIdentifier=ON;connectRetryInterval=10;connectRetryCount=1;maxResultBuffer=-1;sendTemporalDataTypesAsStringForBulkCopy=true;delayLoadingLobs=true;useFmtOnly=false;vectorTypeSupport=v1;cacheBulkCopyMetadata=false;bulkCopyForBatchInsertAllowEncryptedValueModifications=false;bulkCopyForBatchInsertTableLock=false;bulkCopyForBatchInsertKeepNulls=false;bulkCopyForBatchInsertKeepIdentity=false;bulkCopyForBatchInsertFireTriggers=false;bulkCopyForBatchInsertCheckConstraints=false;bulkCopyForBatchInsertBatchSize=0;useBulkCopyForBatchInsert=false;cancelQueryTimeout=-1;sslProtocol=TLS;calcBigDecimalPrecision=false;useDefaultJaasConfig=false;jaasConfigurationName=SQLJDBCDriver;statementPoolingCacheSize=0;serverPreparedStatementDiscardThreshold=10;enablePrepareOnFirstPreparedStatementCall=false;fips=false;socketTimeout=0;authentication=NotSpecified;authenticationScheme=nativeAuthentication;xopenStates=false;datetimeParameterType=datetime2;sendTimeAsDatetime=true;replication=false;trustStoreType=JKS;trustServerCertificate=true;TransparentNetworkIPResolution=true;iPAddressPreference=IPv4First;serverNameAsACE=false;sendStringParametersAsUnicode=true;selectMethod=direct;responseBuffering=adaptive;queryTimeout=-1;packetSize=8000;multiSubnetFailover=false;loginTimeout=30;lockTimeout=-1;lastUpdateCount=true;useDefaultGSSCredential=false;prepareMethod=prepexec;encrypt=true;disableStatementPooling=true;databaseName=TicketDB;columnEncryptionSetting=Disabled;applicationName=Microsoft JDBC Driver for SQL Server;applicationIntent=readwrite;]
bookingservice  | 	Database driver: Microsoft JDBC Driver 13.2 for SQL Server
bookingservice  | 	Database dialect: SQLServerDialect
bookingservice  | 	Database version: 16.0
bookingservice  | 	Default catalog/schema: TicketDB/dbo
bookingservice  | 	Autocommit mode: undefined/unknown
bookingservice  | 	Isolation level: READ_COMMITTED [default READ_COMMITTED]
bookingservice  | 	JDBC fetch size: 128
bookingservice  | 	Pool: DatasourceConnectionProviderImpl
bookingservice  | 	Minimum pool size: undefined/unknown
bookingservice  | 	Maximum pool size: undefined/unknown
authservice     | 2025-12-08T17:08:32.756Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
authservice     | 2025-12-08T17:08:32.758Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
authservice     | 2025-12-08T17:08:32.761Z  INFO 1 --- [AuthService] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
authservice     | 2025-12-08T17:08:32.764Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765213712763 with initial instances count: 1
authservice     | 2025-12-08T17:08:32.770Z  INFO 1 --- [AuthService] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application AUTHSERVICE with eureka with status UP
authservice     | 2025-12-08T17:08:32.771Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765213712771, current=UP, previous=STARTING]
authservice     | 2025-12-08T17:08:32.773Z  INFO 1 --- [AuthService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/39d5f6093c68:AuthService:9091: registering service...
authservice     | 2025-12-08T17:08:32.795Z  INFO 1 --- [AuthService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 9091 (http) with context path '/'
authservice     | 2025-12-08T17:08:32.796Z  INFO 1 --- [AuthService] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 9091
authservice     | 2025-12-08T17:08:32.811Z  INFO 1 --- [AuthService] [           main] o.e.authservice.AuthServiceApplication   : Started AuthServiceApplication in 11.291 seconds (process running for 12.277)
eureka          | 2025-12-08T17:08:32.817Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-5] c.n.e.registry.AbstractInstanceRegistry  : Registered instance AUTHSERVICE/39d5f6093c68:AuthService:9091 with status UP (replication=false)
authservice     | 2025-12-08T17:08:32.819Z  INFO 1 --- [AuthService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/39d5f6093c68:AuthService:9091 - registration status: 204
flightservice   | 2025-12-08T17:08:32.850Z  INFO 1 --- [FlightService] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
flightservice   | 2025-12-08T17:08:33.229Z  INFO 1 --- [FlightService] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
eureka          | 2025-12-08T17:08:33.329Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-6] c.n.e.registry.AbstractInstanceRegistry  : Registered instance AUTHSERVICE/39d5f6093c68:AuthService:9091 with status UP (replication=true)
flightservice   | 2025-12-08T17:08:33.478Z  INFO 1 --- [FlightService] [           main] o.s.d.j.r.query.QueryEnhancerFactories   : Hibernate is in classpath; If applicable, HQL parser will be used.
bookingservice  | 2025-12-08T17:08:33.579Z  INFO 1 --- [BookingService] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
flightservice   | 2025-12-08T17:08:33.883Z  INFO 1 --- [FlightService] [           main] org.redisson.Version                     : Redisson 3.45.0
bookingservice  | 2025-12-08T17:08:33.909Z  INFO 1 --- [BookingService] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
bookingservice  | 2025-12-08T17:08:34.080Z  INFO 1 --- [BookingService] [           main] o.s.d.j.r.query.QueryEnhancerFactories   : Hibernate is in classpath; If applicable, HQL parser will be used.
bookingservice  | 2025-12-08T17:08:34.368Z  WARN 1 --- [BookingService] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
flightservice   | 2025-12-08T17:08:34.402Z  INFO 1 --- [FlightService] [isson-netty-1-6] o.redisson.connection.ConnectionsHolder  : 1 connections initialized for redis/172.20.0.5:6379
flightservice   | 2025-12-08T17:08:34.479Z  INFO 1 --- [FlightService] [sson-netty-1-20] o.redisson.connection.ConnectionsHolder  : 24 connections initialized for redis/172.20.0.5:6379
bookingservice  | 2025-12-08T17:08:34.532Z  INFO 1 --- [BookingService] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'FlightService' URL not provided. Will try picking an instance via load-balancing.
flightservice   | 2025-12-08T17:08:34.945Z  WARN 1 --- [FlightService] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
flightservice   | 2025-12-08T17:08:36.321Z  INFO 1 --- [FlightService] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
flightservice   | 2025-12-08T17:08:36.403Z  WARN 1 --- [FlightService] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
flightservice   | 2025-12-08T17:08:36.447Z  INFO 1 --- [FlightService] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
flightservice   | 2025-12-08T17:08:36.473Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
flightservice   | 2025-12-08T17:08:36.476Z  INFO 1 --- [FlightService] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
flightservice   | 2025-12-08T17:08:36.485Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
flightservice   | 2025-12-08T17:08:36.485Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
flightservice   | 2025-12-08T17:08:36.485Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
flightservice   | 2025-12-08T17:08:36.485Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
flightservice   | 2025-12-08T17:08:36.485Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
flightservice   | 2025-12-08T17:08:36.485Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
flightservice   | 2025-12-08T17:08:36.485Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-08T17:08:36.488Z  INFO 1 --- [BookingService] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
bookingservice  | 2025-12-08T17:08:36.556Z  WARN 1 --- [BookingService] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
bookingservice  | 2025-12-08T17:08:36.598Z  INFO 1 --- [BookingService] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
bookingservice  | 2025-12-08T17:08:36.625Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
bookingservice  | 2025-12-08T17:08:36.628Z  INFO 1 --- [BookingService] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
bookingservice  | 2025-12-08T17:08:36.634Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
bookingservice  | 2025-12-08T17:08:36.635Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
bookingservice  | 2025-12-08T17:08:36.635Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
bookingservice  | 2025-12-08T17:08:36.635Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
bookingservice  | 2025-12-08T17:08:36.635Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
bookingservice  | 2025-12-08T17:08:36.635Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
bookingservice  | 2025-12-08T17:08:36.635Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
kafkaQueue      | [2025-12-08 17:08:36,687] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Stabilized group email-service-group generation 1 with 3 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice    | 2025-12-08T17:08:36.688Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-email-service-group-2-bbbc69c9-c246-44df-816d-4632a96bd66e', protocol='range'}
emailservice    | 2025-12-08T17:08:36.688Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-email-service-group-3-c58d74eb-39eb-47e3-ac81-7f1065106016', protocol='range'}
emailservice    | 2025-12-08T17:08:36.688Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-email-service-group-1-054a4c66-d38d-4115-9c4b-6b403ed6e405', protocol='range'}
emailservice    | 2025-12-08T17:08:36.703Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Finished assignment for group at generation 1: {consumer-email-service-group-1-054a4c66-d38d-4115-9c4b-6b403ed6e405=Assignment(partitions=[ticket.cancelled-0]), consumer-email-service-group-2-bbbc69c9-c246-44df-816d-4632a96bd66e=Assignment(partitions=[schedule.added-0]), consumer-email-service-group-3-c58d74eb-39eb-47e3-ac81-7f1065106016=Assignment(partitions=[ticket.booked-0])}
kafkaQueue      | [2025-12-08 17:08:36,708] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Assignment received from leader consumer-email-service-group-2-bbbc69c9-c246-44df-816d-4632a96bd66e for group email-service-group for generation 1. The group has 3 members, 0 of which are static. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice    | 2025-12-08T17:08:36.717Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-email-service-group-3-c58d74eb-39eb-47e3-ac81-7f1065106016', protocol='range'}
emailservice    | 2025-12-08T17:08:36.717Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-email-service-group-1-054a4c66-d38d-4115-9c4b-6b403ed6e405', protocol='range'}
emailservice    | 2025-12-08T17:08:36.717Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-email-service-group-2-bbbc69c9-c246-44df-816d-4632a96bd66e', protocol='range'}
emailservice    | 2025-12-08T17:08:36.718Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[schedule.added-0])
emailservice    | 2025-12-08T17:08:36.718Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[ticket.booked-0])
emailservice    | 2025-12-08T17:08:36.718Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[ticket.cancelled-0])
emailservice    | 2025-12-08T17:08:36.721Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Adding newly assigned partitions: [schedule.added-0]
emailservice    | 2025-12-08T17:08:36.721Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Adding newly assigned partitions: [ticket.booked-0]
emailservice    | 2025-12-08T17:08:36.721Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Adding newly assigned partitions: [ticket.cancelled-0]
emailservice    | 2025-12-08T17:08:36.729Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Found no committed offset for partition ticket.booked-0
emailservice    | 2025-12-08T17:08:36.729Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Found no committed offset for partition ticket.cancelled-0
emailservice    | 2025-12-08T17:08:36.729Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Found no committed offset for partition schedule.added-0
emailservice    | 2025-12-08T17:08:36.735Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Found no committed offset for partition ticket.booked-0
emailservice    | 2025-12-08T17:08:36.735Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Found no committed offset for partition ticket.cancelled-0
emailservice    | 2025-12-08T17:08:36.735Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Found no committed offset for partition schedule.added-0
emailservice    | 2025-12-08T17:08:36.750Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Resetting offset for partition ticket.booked-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=0}}.
emailservice    | 2025-12-08T17:08:36.750Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Resetting offset for partition schedule.added-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=0}}.
emailservice    | 2025-12-08T17:08:36.750Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Resetting offset for partition ticket.cancelled-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=0}}.
flightservice   | 2025-12-08T17:08:36.758Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
flightservice   | 2025-12-08T17:08:36.760Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
flightservice   | 2025-12-08T17:08:36.762Z  INFO 1 --- [FlightService] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
flightservice   | 2025-12-08T17:08:36.763Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765213716762 with initial instances count: 1
emailservice    | 2025-12-08T17:08:36.772Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [ticket.cancelled-0]
emailservice    | 2025-12-08T17:08:36.772Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [schedule.added-0]
emailservice    | 2025-12-08T17:08:36.772Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [ticket.booked-0]
flightservice   | 2025-12-08T17:08:36.775Z  INFO 1 --- [FlightService] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application FLIGHTSERVICE with eureka with status UP
flightservice   | 2025-12-08T17:08:36.775Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765213716775, current=UP, previous=STARTING]
flightservice   | 2025-12-08T17:08:36.777Z  INFO 1 --- [FlightService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/5737213135fb:FlightService:8080: registering service...
flightservice   | 2025-12-08T17:08:36.795Z  INFO 1 --- [FlightService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8080 (http) with context path '/'
flightservice   | 2025-12-08T17:08:36.796Z  INFO 1 --- [FlightService] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8080
flightservice   | 2025-12-08T17:08:36.821Z  INFO 1 --- [FlightService] [           main] o.e.f.FlightServiceApplication           : Started FlightServiceApplication in 15.153 seconds (process running for 16.332)
eureka          | 2025-12-08T17:08:36.825Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : Registered instance FLIGHTSERVICE/5737213135fb:FlightService:8080 with status UP (replication=false)
flightservice   | 2025-12-08T17:08:36.828Z  INFO 1 --- [FlightService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/5737213135fb:FlightService:8080 - registration status: 204
bookingservice  | 2025-12-08T17:08:36.934Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
bookingservice  | 2025-12-08T17:08:36.936Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
bookingservice  | 2025-12-08T17:08:36.938Z  INFO 1 --- [BookingService] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
bookingservice  | 2025-12-08T17:08:36.939Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765213716939 with initial instances count: 1
bookingservice  | 2025-12-08T17:08:36.952Z  INFO 1 --- [BookingService] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application BOOKINGSERVICE with eureka with status UP
bookingservice  | 2025-12-08T17:08:36.952Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765213716952, current=UP, previous=STARTING]
bookingservice  | 2025-12-08T17:08:36.954Z  INFO 1 --- [BookingService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/5f7ffc0c4eab:BookingService:8081: registering service...
bookingservice  | 2025-12-08T17:08:36.971Z  INFO 1 --- [BookingService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8081 (http) with context path '/'
bookingservice  | 2025-12-08T17:08:36.972Z  INFO 1 --- [BookingService] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8081
bookingservice  | 2025-12-08T17:08:36.986Z  INFO 1 --- [BookingService] [           main] o.e.b.BookingServiceApplication          : Started BookingServiceApplication in 15.347 seconds (process running for 16.535)
eureka          | 2025-12-08T17:08:36.995Z  INFO 1 --- [ServiceRegistry] [io-8761-exec-10] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BOOKINGSERVICE/5f7ffc0c4eab:BookingService:8081 with status UP (replication=false)
bookingservice  | 2025-12-08T17:08:36.997Z  INFO 1 --- [BookingService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/5f7ffc0c4eab:BookingService:8081 - registration status: 204
eureka          | 2025-12-08T17:08:37.339Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] c.n.e.registry.AbstractInstanceRegistry  : Registered instance FLIGHTSERVICE/5737213135fb:FlightService:8080 with status UP (replication=true)
eureka          | 2025-12-08T17:08:37.339Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BOOKINGSERVICE/5f7ffc0c4eab:BookingService:8081 with status UP (replication=true)
eureka          | 2025-12-08T17:08:57.204Z  INFO 1 --- [ServiceRegistry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
emailservice    | 2025-12-08T17:08:58.738Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
emailservice    | 2025-12-08T17:08:58.738Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
emailservice    | 2025-12-08T17:08:58.738Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
emailservice    | 2025-12-08T17:08:58.738Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
emailservice    | 2025-12-08T17:08:58.738Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
emailservice    | 2025-12-08T17:08:58.738Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
emailservice    | 2025-12-08T17:08:58.738Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
emailservice    | 2025-12-08T17:08:58.759Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
authservice     | 2025-12-08T17:09:00.526Z  INFO 1 --- [AuthService] [nio-9091-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
authservice     | 2025-12-08T17:09:00.527Z  INFO 1 --- [AuthService] [nio-9091-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
authservice     | 2025-12-08T17:09:00.528Z  INFO 1 --- [AuthService] [nio-9091-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
authservice     | 2025-12-08T17:09:00.564Z ERROR 1 --- [AuthService] [nio-9091-exec-2] o.e.a.service.jwt.AuthEntryPointJwt      : Unauthorized error: 
authservice     | 
authservice     | org.springframework.security.authentication.InsufficientAuthenticationException: Full authentication is required to access this resource
authservice     | 	at org.springframework.security.web.access.ExceptionTranslationFilter.handleAccessDeniedException(ExceptionTranslationFilter.java:198) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.access.ExceptionTranslationFilter.handleSpringSecurityException(ExceptionTranslationFilter.java:178) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:147) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:120) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:92) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.session.SessionManagementFilter.doFilter(SessionManagementFilter.java:86) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.authentication.AnonymousAuthenticationFilter.doFilter(AnonymousAuthenticationFilter.java:100) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.servletapi.SecurityContextHolderAwareRequestFilter.doFilter(SecurityContextHolderAwareRequestFilter.java:181) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.savedrequest.RequestCacheAwareFilter.doFilter(RequestCacheAwareFilter.java:63) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:110) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java:96) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.context.SecurityContextHolderFilter.doFilter(SecurityContextHolderFilter.java:82) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.context.SecurityContextHolderFilter.doFilter(SecurityContextHolderFilter.java:69) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:237) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:195) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.web.filter.CompositeFilter$VirtualFilterChain.doFilter(CompositeFilter.java:113) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.web.filter.ServletRequestPathFilter.doFilter(ServletRequestPathFilter.java:52) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.web.filter.CompositeFilter$VirtualFilterChain.doFilter(CompositeFilter.java:113) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.web.filter.CompositeFilter.doFilter(CompositeFilter.java:74) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.security.config.annotation.web.configuration.WebSecurityConfiguration$CompositeFilterChainProxy.doFilter(WebSecurityConfiguration.java:317) ~[spring-security-config-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:355) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:272) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:116) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:101) ~[spring-web-7.0.1.jar!/:7.0.1]
authservice     | 	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:107) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.catalina.core.ApplicationDispatcher.invoke(ApplicationDispatcher.java:513) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.catalina.core.ApplicationDispatcher.processRequest(ApplicationDispatcher.java:335) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.catalina.core.ApplicationDispatcher.forward(ApplicationDispatcher.java:262) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.catalina.core.StandardHostValve.custom(StandardHostValve.java:375) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.catalina.core.StandardHostValve.status(StandardHostValve.java:206) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:149) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:83) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:72) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:341) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:397) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:63) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:903) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1778) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:52) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.tomcat.util.threads.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:946) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.tomcat.util.threads.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:480) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:57) ~[tomcat-embed-core-11.0.14.jar!/:na]
authservice     | 	at java.base/java.lang.Thread.run(Thread.java:1583) ~[na:na]
authservice     | Caused by: org.springframework.security.authorization.AuthorizationDeniedException: Access Denied
authservice     | 	at org.springframework.security.web.access.intercept.AuthorizationFilter.doFilter(AuthorizationFilter.java:99) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java:380) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	at org.springframework.security.web.access.ExceptionTranslationFilter.doFilter(ExceptionTranslationFilter.java:126) ~[spring-security-web-7.0.0.jar!/:7.0.0]
authservice     | 	... 60 common frames omitted
authservice     | 
authservice     | 2025-12-08T17:09:17.407Z  INFO 1 --- [AuthService] [nio-9091-exec-3] o.e.a.s.user.UserDetailsServiceImpl      : user Users(id=10, username=roy, password=$2a$10$CbG8cWo6uvIYurhmwM4veeD6FftnSLJbe9LTcJUrmHJaN51n.IsYG, email=roy@gmail.com, roles=[Role(id=1, name=ADMIN), Role(id=2, name=USER)])
authservice     | 2025-12-08T17:09:17.496Z  INFO 1 --- [AuthService] [nio-9091-exec-3] o.e.authservice.service.jwt.JwtUtils     : 3600000
flightservice   | 2025-12-08T17:09:36.916Z  INFO 1 --- [FlightService] [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
flightservice   | 2025-12-08T17:09:36.916Z  INFO 1 --- [FlightService] [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
flightservice   | 2025-12-08T17:09:36.918Z  INFO 1 --- [FlightService] [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 2 ms
eureka          | 2025-12-08T17:09:57.203Z  INFO 1 --- [ServiceRegistry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
Gracefully Stopping... press Ctrl+C again to force
[K Container authservice  [32mStopping[0m
[K Container apigateway  [32mStopping[0m
