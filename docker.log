Attaching to apigateway, authservice, bookingservice, configserver, emailservice, eureka, flightservice, kafkaQueue, redis, sql_db
eureka  | 
eureka  |   .   ____          _            __ _ _
eureka  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
eureka  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
eureka  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
eureka  |   '  |____| .__|_| |_|_| |_\__, | / / / /
eureka  |  =========|_|==============|___/=/_/_/_/
eureka  | 
eureka  |  :: Spring Boot ::                (v4.0.0)
eureka  | 
eureka  | 2025-12-08T14:40:29.805Z  INFO 1 --- [ServiceRegistry] [           main] o.e.s.ServiceRegistryApplication         : Starting ServiceRegistryApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/ServiceRegistry-0.0.1-SNAPSHOT.jar started by root in /app)
eureka  | 2025-12-08T14:40:29.812Z  INFO 1 --- [ServiceRegistry] [           main] o.e.s.ServiceRegistryApplication         : No active profile set, falling back to 1 default profile: "default"
eureka  | 2025-12-08T14:40:30.801Z  INFO 1 --- [ServiceRegistry] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=66c7ce29-e870-3c61-a4ed-996d3e0a2ece
eureka  | 2025-12-08T14:40:31.050Z  INFO 1 --- [ServiceRegistry] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8761 (http)
eureka  | 2025-12-08T14:40:31.059Z  INFO 1 --- [ServiceRegistry] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
eureka  | 2025-12-08T14:40:31.059Z  INFO 1 --- [ServiceRegistry] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
eureka  | 2025-12-08T14:40:31.075Z  INFO 1 --- [ServiceRegistry] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 1210 ms
eureka  | 2025-12-08T14:40:31.917Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
eureka  | 2025-12-08T14:40:31.917Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
eureka  | 2025-12-08T14:40:32.086Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
eureka  | 2025-12-08T14:40:32.086Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
eureka  | 2025-12-08T14:40:32.218Z  INFO 1 --- [ServiceRegistry] [           main] o.s.v.b.OptionalValidatorFactoryBean     : Failed to set up a Bean Validation provider: jakarta.validation.NoProviderFoundException: Unable to create a Configuration, because no Jakarta Validation provider could be found. Add a provider like Hibernate Validator (RI) to your classpath.
eureka  | 2025-12-08T14:40:32.850Z  WARN 1 --- [ServiceRegistry] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
eureka  | 2025-12-08T14:40:32.871Z  INFO 1 --- [ServiceRegistry] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
eureka  | 2025-12-08T14:40:32.888Z  INFO 1 --- [ServiceRegistry] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
eureka  | 2025-12-08T14:40:32.889Z  INFO 1 --- [ServiceRegistry] [           main] com.netflix.discovery.DiscoveryClient    : Client configured to neither register nor query for data.
eureka  | 2025-12-08T14:40:32.890Z  INFO 1 --- [ServiceRegistry] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765204832889 with initial instances count: 0
eureka  | 2025-12-08T14:40:32.926Z  INFO 1 --- [ServiceRegistry] [           main] c.n.eureka.DefaultEurekaServerContext    : Initializing ...
eureka  | 2025-12-08T14:40:32.929Z  INFO 1 --- [ServiceRegistry] [           main] c.n.eureka.cluster.PeerEurekaNodes       : Adding new peer nodes [http://localhost:8761/eureka/]
eureka  | 2025-12-08T14:40:33.059Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
eureka  | 2025-12-08T14:40:33.059Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
eureka  | 2025-12-08T14:40:33.059Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
eureka  | 2025-12-08T14:40:33.059Z  INFO 1 --- [ServiceRegistry] [           main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
eureka  | 2025-12-08T14:40:33.094Z  INFO 1 --- [ServiceRegistry] [           main] c.n.eureka.cluster.PeerEurekaNodes       : Replica node URL:  http://localhost:8761/eureka/
eureka  | 2025-12-08T14:40:33.104Z  INFO 1 --- [ServiceRegistry] [           main] c.n.e.registry.AbstractInstanceRegistry  : Finished initializing remote region registries. All known remote regions: []
eureka  | 2025-12-08T14:40:33.104Z  INFO 1 --- [ServiceRegistry] [           main] c.n.eureka.DefaultEurekaServerContext    : Initialized
eureka  | 2025-12-08T14:40:33.112Z  INFO 1 --- [ServiceRegistry] [           main] o.s.b.a.e.web.EndpointLinksResolver      : Exposing 1 endpoint beneath base path '/actuator'
eureka  | 2025-12-08T14:40:33.161Z  INFO 1 --- [ServiceRegistry] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application SERVICEREGISTRY with eureka with status UP
eureka  | 2025-12-08T14:40:33.177Z  INFO 1 --- [ServiceRegistry] [       Thread-9] o.s.c.n.e.server.EurekaServerBootstrap   : isAws returned false
eureka  | 2025-12-08T14:40:33.177Z  INFO 1 --- [ServiceRegistry] [       Thread-9] o.s.c.n.e.server.EurekaServerBootstrap   : Initialized server context
eureka  | 2025-12-08T14:40:33.178Z  INFO 1 --- [ServiceRegistry] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Got 1 instances from neighboring DS node
eureka  | 2025-12-08T14:40:33.178Z  INFO 1 --- [ServiceRegistry] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Renew threshold is: 1
eureka  | 2025-12-08T14:40:33.178Z  INFO 1 --- [ServiceRegistry] [       Thread-9] c.n.e.r.PeerAwareInstanceRegistryImpl    : Changing status to UP
eureka  | 2025-12-08T14:40:33.181Z  INFO 1 --- [ServiceRegistry] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8761 (http) with context path '/'
eureka  | 2025-12-08T14:40:33.181Z  INFO 1 --- [ServiceRegistry] [       Thread-9] e.s.EurekaServerInitializerConfiguration : Started Eureka Server
eureka  | 2025-12-08T14:40:33.182Z  INFO 1 --- [ServiceRegistry] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8761
eureka  | 2025-12-08T14:40:33.191Z  INFO 1 --- [ServiceRegistry] [           main] o.e.s.ServiceRegistryApplication         : Started ServiceRegistryApplication in 3.792 seconds (process running for 4.312)
eureka  | 2025-12-08T14:40:33.958Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
eureka  | 2025-12-08T14:40:33.958Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
eureka  | 2025-12-08T14:40:33.960Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 2 ms
configserver  | 
configserver  |   .   ____          _            __ _ _
configserver  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
configserver  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
configserver  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
configserver  |   '  |____| .__|_| |_|_| |_\__, | / / / /
configserver  |  =========|_|==============|___/=/_/_/_/
configserver  | 
configserver  |  :: Spring Boot ::                (v4.0.0)
configserver  | 
configserver  | 2025-12-08T14:40:35.305Z  INFO 1 --- [ConfigServer] [           main] o.e.c.ConfigServerApplication            : Starting ConfigServerApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/ConfigServer-0.0.1-SNAPSHOT.jar started by root in /app)
configserver  | 2025-12-08T14:40:35.308Z  INFO 1 --- [ConfigServer] [           main] o.e.c.ConfigServerApplication            : No active profile set, falling back to 1 default profile: "default"
configserver  | 2025-12-08T14:40:35.888Z  INFO 1 --- [ConfigServer] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=0cddbe66-053f-3dc9-884e-976511af59fa
configserver  | 2025-12-08T14:40:36.100Z  INFO 1 --- [ConfigServer] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8888 (http)
configserver  | 2025-12-08T14:40:36.109Z  INFO 1 --- [ConfigServer] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
configserver  | 2025-12-08T14:40:36.110Z  INFO 1 --- [ConfigServer] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
configserver  | 2025-12-08T14:40:36.124Z  INFO 1 --- [ConfigServer] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 762 ms
configserver  | 2025-12-08T14:40:36.773Z  INFO 1 --- [ConfigServer] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8888 (http) with context path '/'
configserver  | 2025-12-08T14:40:36.791Z  INFO 1 --- [ConfigServer] [           main] o.e.c.ConfigServerApplication            : Started ConfigServerApplication in 1.845 seconds (process running for 2.272)
configserver  | 2025-12-08T14:40:39.595Z  INFO 1 --- [ConfigServer] [nio-8888-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
configserver  | 2025-12-08T14:40:39.595Z  INFO 1 --- [ConfigServer] [nio-8888-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
configserver  | 2025-12-08T14:40:39.596Z  INFO 1 --- [ConfigServer] [nio-8888-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 1 ms
kafkaQueue    | ===> User
kafkaQueue    | uid=1000(appuser) gid=1000(appuser) groups=1000(appuser)
kafkaQueue    | ===> Setting default values of environment variables if not already set.
kafkaQueue    | CLUSTER_ID not set. Setting it to default value: "5L6g3nShT-eMCtK--X86sw"
kafkaQueue    | ===> Configuring ...
kafkaQueue    | Running in KRaft mode...
kafkaQueue    | ===> Launching ... 
kafkaQueue    | ===> Using provided cluster id 5L6g3nShT-eMCtK--X86sw ...
redis         | Starting Redis Server
redis         | 1:C 08 Dec 2025 14:40:55.854 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
redis         | 1:C 08 Dec 2025 14:40:55.854 * oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
redis         | 1:C 08 Dec 2025 14:40:55.854 * Redis version=8.4.0, bits=64, commit=00000000, modified=1, pid=1, just started
redis         | 1:C 08 Dec 2025 14:40:55.854 * Configuration loaded
redis         | 1:M 08 Dec 2025 14:40:55.854 * Increased maximum number of open files to 10032 (it was originally set to 1024).
redis         | 1:M 08 Dec 2025 14:40:55.854 * monotonic clock: POSIX clock_gettime
redis         | 1:M 08 Dec 2025 14:40:55.854 * Running mode=standalone, port=6379.
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> RedisBloom version 8.4.0 (Git=unknown)
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> Registering configuration options: [
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> 	{ bf-error-rate       :      0.01 }
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> 	{ bf-initial-size     :       100 }
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> 	{ bf-expansion-factor :         2 }
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> 	{ cf-bucket-size      :         2 }
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> 	{ cf-initial-size     :      1024 }
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> 	{ cf-max-iterations   :        20 }
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> 	{ cf-expansion-factor :         1 }
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> 	{ cf-max-expansions   :        32 }
redis         | 1:M 08 Dec 2025 14:40:55.855 * <bf> ]
redis         | 1:M 08 Dec 2025 14:40:55.855 * Module 'bf' loaded from /usr/local/lib/redis/modules//redisbloom.so
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> Redis version found by RedisSearch : 8.4.0 - oss
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> RediSearch version 8.4.2 (Git=9e2b676)
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> Low level api version 1 initialized successfully
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> gc: ON, prefix min length: 2, min word length to stem: 4, prefix max expansions: 200, query timeout (ms): 500, timeout policy: return, oom policy: return, cursor read size: 1000, cursor max idle (ms): 300000, max doctable size: 1000000, max number of search results:  1000000, default scorer: BM25STD, 
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> Initialized thread pools!
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> Disabled workers threadpool of size 0
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> Subscribe to config changes
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> Subscribe to cluster slot migration events
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> Enabled role change notification
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> Cluster configuration: AUTO partitions, type: 0, coordinator timeout: 0ms
redis         | 1:M 08 Dec 2025 14:40:55.858 * <search> Register write commands
redis         | 1:M 08 Dec 2025 14:40:55.858 * Module 'search' loaded from /usr/local/lib/redis/modules//redisearch.so
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> RedisTimeSeries version 80400, git_sha=3520a1568ad69076d60885c70711fbdc9b448749
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> Redis version found by RedisTimeSeries : 8.4.0 - oss
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> Registering configuration options: [
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> 	{ ts-compaction-policy   :              }
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> 	{ ts-num-threads         :            3 }
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> 	{ ts-retention-policy    :            0 }
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> 	{ ts-duplicate-policy    :        block }
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> 	{ ts-chunk-size-bytes    :         4096 }
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> 	{ ts-encoding            :   compressed }
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> 	{ ts-ignore-max-time-diff:            0 }
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> 	{ ts-ignore-max-val-diff :     0.000000 }
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> ]
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> Detected redis oss
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> Subscribe to ASM events
redis         | 1:M 08 Dec 2025 14:40:55.859 * <timeseries> Enabled diskless replication
redis         | 1:M 08 Dec 2025 14:40:55.859 * Module 'timeseries' loaded from /usr/local/lib/redis/modules//redistimeseries.so
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> Created new data type 'ReJSON-RL'
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> version: 80400 git sha: unknown branch: unknown
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> Exported RedisJSON_V1 API
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> Exported RedisJSON_V2 API
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> Exported RedisJSON_V3 API
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> Exported RedisJSON_V4 API
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> Exported RedisJSON_V5 API
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> Exported RedisJSON_V6 API
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> Enabled diskless replication
redis         | 1:M 08 Dec 2025 14:40:55.862 * <ReJSON> Initialized shared string cache, thread safe: true.
redis         | 1:M 08 Dec 2025 14:40:55.862 * Module 'ReJSON' loaded from /usr/local/lib/redis/modules//rejson.so
redis         | 1:M 08 Dec 2025 14:40:55.862 * <search> Acquired RedisJSON_V6 API
redis         | 1:M 08 Dec 2025 14:40:55.863 * Server initialized
redis         | 1:M 08 Dec 2025 14:40:55.863 * Ready to accept connections tcp
sql_db        | SQL Server 2022 will run as non-root by default.
sql_db        | This container is running as user mssql.
sql_db        | Your master database file is owned by mssql.
sql_db        | To learn more visit https://go.microsoft.com/fwlink/?linkid=2099216.
kafkaQueue    | [2025-12-08 14:40:58,210] INFO Registered `kafka:type=kafka.Log4jController` MBean (kafka.utils.Log4jControllerRegistration$)
kafkaQueue    | [2025-12-08 14:40:58,501] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
kafkaQueue    | [2025-12-08 14:40:58,503] INFO [ControllerServer id=1] Starting controller (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 14:40:58,762] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
kafkaQueue    | [2025-12-08 14:40:58,792] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(CONTROLLER) (kafka.network.SocketServer)
kafkaQueue    | [2025-12-08 14:40:58,795] INFO CONTROLLER: resolved wildcard host to dd07ec5c3985 (org.apache.kafka.metadata.ListenerInfo)
kafkaQueue    | [2025-12-08 14:40:58,800] INFO authorizerStart completed for endpoint CONTROLLER. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafkaQueue    | [2025-12-08 14:40:58,802] INFO [SharedServer id=1] Starting SharedServer (kafka.server.SharedServer)
kafkaQueue    | [2025-12-08 14:40:58,854] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2025-12-08 14:40:58,855] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2025-12-08 14:40:58,855] INFO [LogLoader partition=__cluster_metadata-0, dir=/tmp/kafka-logs] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue    | [2025-12-08 14:40:58,866] INFO Initialized snapshots with IDs SortedSet() from /tmp/kafka-logs/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
kafkaQueue    | [2025-12-08 14:40:58,875] INFO [raft-expiration-reaper]: Starting (org.apache.kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 14:40:58,879] INFO [RaftManager id=1] Reading KRaft snapshot and log as part of the initialization (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 14:40:58,880] INFO [RaftManager id=1] Starting voters are VoterSet(voters={1=VoterNode(voterKey=ReplicaKey(id=1, directoryId=<undefined>), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=kafkaQueue/172.20.0.4:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:0])}) (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 14:40:58,885] INFO [RaftManager id=1] Starting request manager with static voters: [kafkaQueue:9093 (id: 1 rack: null isFenced: false)] (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 14:40:58,888] INFO [RaftManager id=1] Attempting durable transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1989, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
sql_db        | 2025-12-08 14:40:58.86 Server      Setup step is FORCE copying system data file 'C:\templatedata\model_replicatedmaster.mdf' to '/var/opt/mssql/data/model_replicatedmaster.mdf'.
kafkaQueue    | [2025-12-08 14:40:58,899] INFO [RaftManager id=1] Completed transition to UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1989, highWatermark=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 14:40:58,903] INFO [RaftManager id=1] Completed transition to ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1474, highWatermark=Optional.empty) from UnattachedState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, voters=[1], electionTimeoutMs=1989, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 14:40:58,904] INFO [RaftManager id=1] Attempting durable transition to CandidateState(localId=1, localDirectoryId=8uA6wjvQ8Dwn0u2AwNEjHQ, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1895) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1474, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
sql_db        | 2025-12-08 14:40:58.90 Server      Setup step is FORCE copying system data file 'C:\templatedata\model_replicatedmaster.ldf' to '/var/opt/mssql/data/model_replicatedmaster.ldf'.
kafkaQueue    | [2025-12-08 14:40:58,909] INFO [RaftManager id=1] Completed transition to CandidateState(localId=1, localDirectoryId=8uA6wjvQ8Dwn0u2AwNEjHQ, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1895) from ProspectiveState(epoch=0, leaderId=OptionalInt.empty, votedKey=Optional.empty, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), electionTimeoutMs=1474, highWatermark=Optional.empty) (org.apache.kafka.raft.QuorumState)
sql_db        | 2025-12-08 14:40:58.90 Server      Setup step is FORCE copying system data file 'C:\templatedata\model_msdbdata.mdf' to '/var/opt/mssql/data/model_msdbdata.mdf'.
kafkaQueue    | [2025-12-08 14:40:58,913] INFO [RaftManager id=1] Attempting durable transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=8uA6wjvQ8Dwn0u2AwNEjHQ), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=dd07ec5c3985/<unresolved>:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=8uA6wjvQ8Dwn0u2AwNEjHQ, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1895) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 14:40:58,918] INFO [RaftManager id=1] Completed transition to Leader(localVoterNode=VoterNode(voterKey=ReplicaKey(id=1, directoryId=8uA6wjvQ8Dwn0u2AwNEjHQ), listeners=Endpoints(endpoints={ListenerName(CONTROLLER)=dd07ec5c3985/<unresolved>:9093}), supportedKRaftVersion=SupportedVersionRange[min_version:0, max_version:1]), epoch=1, epochStartOffset=0, highWatermark=Optional.empty, voterStates={1=ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional.empty, lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)}) from CandidateState(localId=1, localDirectoryId=8uA6wjvQ8Dwn0u2AwNEjHQ, epoch=1, epochElection=EpochElection(voterStates={1=VoterState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), state=GRANTED)}), highWatermark=Optional.empty, electionTimeoutMs=1895) (org.apache.kafka.raft.QuorumState)
kafkaQueue    | [2025-12-08 14:40:58,941] INFO [kafka-1-raft-outbound-request-thread]: Starting (org.apache.kafka.raft.KafkaNetworkChannel$SendThread)
kafkaQueue    | [2025-12-08 14:40:58,942] INFO [kafka-1-raft-io-thread]: Starting (org.apache.kafka.raft.KafkaRaftClientDriver)
sql_db        | 2025-12-08 14:40:58.93 Server      Setup step is FORCE copying system data file 'C:\templatedata\model_msdblog.ldf' to '/var/opt/mssql/data/model_msdblog.ldf'.
kafkaQueue    | [2025-12-08 14:40:58,960] INFO [MetadataLoader id=1] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:58,963] INFO [ControllerServer id=1] Waiting for controller quorum voters future (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 14:40:58,964] INFO [ControllerServer id=1] Finished waiting for controller quorum voters future (kafka.server.ControllerServer)
sql_db        | 2025-12-08 14:40:58.97 Server      Microsoft SQL Server 2022 (RTM-CU21) (KB5065865) - 16.0.4215.2 (X64) 
sql_db        | 	Aug 11 2025 13:24:21 
sql_db        | 	Copyright (C) 2022 Microsoft Corporation
sql_db        | 	Developer Edition (64-bit) on Linux (Ubuntu 22.04.5 LTS) <X64>
sql_db        | 2025-12-08 14:40:58.97 Server      UTC adjustment: 0:00
sql_db        | 2025-12-08 14:40:58.97 Server      (c) Microsoft Corporation.
sql_db        | 2025-12-08 14:40:58.97 Server      All rights reserved.
sql_db        | 2025-12-08 14:40:58.98 Server      Server process ID is 532.
sql_db        | 2025-12-08 14:40:58.98 Server      Logging SQL Server messages in file '/var/opt/mssql/log/errorlog'.
kafkaQueue    | [2025-12-08 14:40:58,988] INFO [RaftManager id=1] High watermark set to LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)]) for the first time for epoch 1 based on indexOfHw 0 and voters [ReplicaState(replicaKey=ReplicaKey(id=1, directoryId=<undefined>), endOffset=Optional[LogOffsetMetadata(offset=1, metadata=Optional[(segmentBaseOffset=0,relativePositionInSegment=91)])], lastFetchTimestamp=-1, lastCaughtUpTimestamp=-1, hasAcknowledgedLeader=true)] (org.apache.kafka.raft.LeaderState)
sql_db        | 2025-12-08 14:40:58.98 Server      Registry startup parameters: 
sql_db        | 	 -d /var/opt/mssql/data/master.mdf
sql_db        | 	 -l /var/opt/mssql/data/mastlog.ldf
sql_db        | 	 -e /var/opt/mssql/log/errorlog
sql_db        | 2025-12-08 14:40:58.98 Server      SQL Server detected 1 sockets with 8 cores per socket and 16 logical processors per socket, 16 total logical processors; using 16 logical processors based on SQL Server licensing. This is an informational message; no user action is required.
sql_db        | 2025-12-08 14:40:58.99 Server      SQL Server is starting at normal priority base (=7). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 14:40:58.99 Server      Detected 12518 MB of RAM, 5274 MB of available memory, 5274 MB of available page file. This is an informational message; no user action is required.
sql_db        | 2025-12-08 14:40:58.99 Server      Using conventional memory in the memory manager.
sql_db        | 2025-12-08 14:40:59.00 Server      Detected pause instruction latency: 55 cycles.
kafkaQueue    | [2025-12-08 14:40:59,014] INFO [controller-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 14:40:59,016] INFO [RaftManager id=1] Registered the listener org.apache.kafka.image.loader.MetadataLoader@949322668 (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 14:40:59,017] INFO [RaftManager id=1] Registered the listener org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@1819043097 (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 14:40:59,017] INFO [controller-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 14:40:59,018] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.image.loader.MetadataLoader@949322668 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 14:40:59,022] INFO [RaftManager id=1] Setting the next offset of org.apache.kafka.controller.QuorumController$QuorumMetaLogListener@1819043097 to 0 since there are no snapshots (org.apache.kafka.raft.KafkaRaftClient)
kafkaQueue    | [2025-12-08 14:40:59,024] INFO [controller-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 14:40:59,024] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
sql_db        | 2025-12-08 14:40:59.00 Server      SQL Server detected the following NUMA node configuration (NUMA Node number 0, Processor Group number 0, CPU Mask 0x000000000000ffff).
kafkaQueue    | [2025-12-08 14:40:59,029] INFO [controller-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 14:40:59,050] INFO [ExpirationReaper-1-AlterAcls]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 14:40:59,060] INFO [MetadataLoader id=1] initializeNewPublishers: The loader is still catching up because we have not loaded a controller record as of offset 0 and high water mark is 1 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,078] INFO [MetadataLoader id=1] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 8 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,082] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,133] INFO [ControllerServer id=1] Waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 14:40:59,134] INFO [ControllerServer id=1] Finished waiting for the controller metadata publishers to be installed (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 14:40:59,134] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing KRaftMetadataCachePublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,134] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing FeaturesPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,134] INFO [SocketServer listenerType=CONTROLLER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafkaQueue    | [2025-12-08 14:40:59,140] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.DataPlaneAcceptor)
kafkaQueue    | [2025-12-08 14:40:59,155] INFO [controller-1-to-controller-registration-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,156] INFO [ControllerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 14:40:59,157] INFO [ControllerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 14:40:59,157] INFO [ControllerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 14:40:59,157] INFO [ControllerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.ControllerServer)
kafkaQueue    | [2025-12-08 14:40:59,157] INFO [ControllerRegistrationManager id=1 incarnation=ClQECL76TAmj0JqFhys8-A] initialized channel manager. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 14:40:59,158] INFO [controller-1-to-controller-registration-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,159] INFO [ControllerRegistrationManager id=1 incarnation=ClQECL76TAmj0JqFhys8-A] maybeSendControllerRegistration: cannot register yet because the metadata.version is not known yet. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 14:40:59,161] INFO [BrokerServer id=1] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,164] INFO [BrokerServer id=1] Starting broker (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,172] INFO [ControllerServer id=1] Loaded new metadata FinalizedFeatures[metadataVersion=4.1-IV1, finalizedFeatures={group.version=1, transaction.version=2, eligible.leader.replicas.version=1, metadata.version=27}, finalizedFeaturesEpoch=7]. (org.apache.kafka.metadata.publisher.FeaturesPublisher)
kafkaQueue    | [2025-12-08 14:40:59,173] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationsPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,174] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerRegistrationManager with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,174] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicConfigPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
sql_db        | 2025-12-08 14:40:59.17 Server      Page exclusion bitmap is enabled.
kafkaQueue    | [2025-12-08 14:40:59,182] INFO [broker-1-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 14:40:59,183] INFO [broker-1-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 14:40:59,185] INFO [broker-1-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 14:40:59,186] INFO [broker-1-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
kafkaQueue    | [2025-12-08 14:40:59,188] INFO [DynamicConfigPublisher controller id=1] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafkaQueue    | [2025-12-08 14:40:59,204] INFO [ControllerRegistrationManager id=1 incarnation=ClQECL76TAmj0JqFhys8-A] sendControllerRegistration: attempting to send ControllerRegistrationRequestData(controllerId=1, incarnationId=ClQECL76TAmj0JqFhys8-A, zkMigrationReady=false, listeners=[Listener(name='CONTROLLER', host='dd07ec5c3985', port=9093, securityProtocol=0)], features=[Feature(name='group.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='transaction.version', minSupportedVersion=0, maxSupportedVersion=2), Feature(name='eligible.leader.replicas.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='kraft.version', minSupportedVersion=0, maxSupportedVersion=1), Feature(name='metadata.version', minSupportedVersion=7, maxSupportedVersion=27), Feature(name='share.version', minSupportedVersion=0, maxSupportedVersion=1)]) (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 14:40:59,219] INFO KafkaConfig values: 
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.ms = 20
kafkaQueue    | 	advertised.listeners = PLAINTEXT://kafkaQueue:9092
kafkaQueue    | 	alter.config.policy.class.name = null
kafkaQueue    | 	alter.log.dirs.replication.quota.window.num = 11
kafkaQueue    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafkaQueue    | 	authorizer.class.name = 
kafkaQueue    | 	auto.create.topics.enable = true
kafkaQueue    | 	auto.leader.rebalance.enable = true
kafkaQueue    | 	background.threads = 10
kafkaQueue    | 	broker.heartbeat.interval.ms = 2000
kafkaQueue    | 	broker.id = 1
kafkaQueue    | 	broker.rack = null
kafkaQueue    | 	broker.session.timeout.ms = 9000
kafkaQueue    | 	client.quota.callback.class = null
kafkaQueue    | 	compression.gzip.level = -1
kafkaQueue    | 	compression.lz4.level = 9
kafkaQueue    | 	compression.type = producer
kafkaQueue    | 	compression.zstd.level = 3
kafkaQueue    | 	connection.failed.authentication.delay.ms = 100
kafkaQueue    | 	connections.max.idle.ms = 600000
kafkaQueue    | 	connections.max.reauth.ms = 0
kafkaQueue    | 	controlled.shutdown.enable = true
kafkaQueue    | 	controller.listener.names = CONTROLLER
kafkaQueue    | 	controller.performance.always.log.threshold.ms = 2000
kafkaQueue    | 	controller.performance.sample.period.ms = 60000
kafkaQueue    | 	controller.quorum.append.linger.ms = 25
kafkaQueue    | 	controller.quorum.bootstrap.servers = []
kafkaQueue    | 	controller.quorum.election.backoff.max.ms = 1000
kafkaQueue    | 	controller.quorum.election.timeout.ms = 1000
kafkaQueue    | 	controller.quorum.fetch.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.request.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.retry.backoff.ms = 20
kafkaQueue    | 	controller.quorum.voters = [1@kafkaQueue:9093]
kafkaQueue    | 	controller.quota.window.num = 11
kafkaQueue    | 	controller.quota.window.size.seconds = 1
kafkaQueue    | 	controller.socket.timeout.ms = 30000
kafkaQueue    | 	create.topic.policy.class.name = null
kafkaQueue    | 	default.replication.factor = 1
kafkaQueue    | 	delegation.token.expiry.check.interval.ms = 3600000
kafkaQueue    | 	delegation.token.expiry.time.ms = 86400000
kafkaQueue    | 	delegation.token.max.lifetime.ms = 604800000
kafkaQueue    | 	delegation.token.secret.key = null
kafkaQueue    | 	delete.records.purgatory.purge.interval.requests = 1
kafkaQueue    | 	delete.topic.enable = true
kafkaQueue    | 	early.start.listeners = null
kafkaQueue    | 	fetch.max.bytes = 57671680
kafkaQueue    | 	fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	group.consumer.assignors = [uniform, range]
kafkaQueue    | 	group.consumer.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.consumer.max.session.timeout.ms = 60000
kafkaQueue    | 	group.consumer.max.size = 2147483647
kafkaQueue    | 	group.consumer.migration.policy = bidirectional
kafkaQueue    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.min.session.timeout.ms = 45000
kafkaQueue    | 	group.consumer.regex.refresh.interval.ms = 600000
kafkaQueue    | 	group.consumer.session.timeout.ms = 45000
kafkaQueue    | 	group.coordinator.append.linger.ms = 5
kafkaQueue    | 	group.coordinator.rebalance.protocols = [classic, consumer, streams]
kafkaQueue    | 	group.coordinator.threads = 4
kafkaQueue    | 	group.initial.rebalance.delay.ms = 3000
kafkaQueue    | 	group.max.session.timeout.ms = 1800000
kafkaQueue    | 	group.max.size = 2147483647
kafkaQueue    | 	group.min.session.timeout.ms = 6000
kafkaQueue    | 	group.share.assignors = [simple]
kafkaQueue    | 	group.share.delivery.count.limit = 5
kafkaQueue    | 	group.share.enable = false
kafkaQueue    | 	group.share.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.share.max.record.lock.duration.ms = 60000
kafkaQueue    | 	group.share.max.session.timeout.ms = 60000
kafkaQueue    | 	group.share.max.share.sessions = 2000
kafkaQueue    | 	group.share.max.size = 200
kafkaQueue    | 	group.share.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.min.record.lock.duration.ms = 15000
kafkaQueue    | 	group.share.min.session.timeout.ms = 45000
kafkaQueue    | 	group.share.partition.max.record.locks = 2000
kafkaQueue    | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafkaQueue    | 	group.share.record.lock.duration.ms = 30000
kafkaQueue    | 	group.share.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.streams.max.session.timeout.ms = 60000
kafkaQueue    | 	group.streams.max.size = 2147483647
kafkaQueue    | 	group.streams.max.standby.replicas = 2
kafkaQueue    | 	group.streams.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.min.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.num.standby.replicas = 0
kafkaQueue    | 	group.streams.session.timeout.ms = 45000
kafkaQueue    | 	initial.broker.registration.timeout.ms = 60000
kafkaQueue    | 	inter.broker.listener.name = null
kafkaQueue    | 	internal.metadata.delete.delay.millis = 60000
kafkaQueue    | 	internal.metadata.log.segment.bytes = null
kafkaQueue    | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafkaQueue    | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafkaQueue    | 	kafka.metrics.polling.interval.secs = 10
kafkaQueue    | 	kafka.metrics.reporters = []
kafkaQueue    | 	leader.imbalance.check.interval.seconds = 300
kafkaQueue    | 	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
kafkaQueue    | 	listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
kafkaQueue    | 	log.cleaner.backoff.ms = 15000
kafkaQueue    | 	log.cleaner.dedupe.buffer.size = 134217728
kafkaQueue    | 	log.cleaner.delete.retention.ms = 86400000
kafkaQueue    | 	log.cleaner.enable = true
kafkaQueue    | 	log.cleaner.io.buffer.load.factor = 0.9
kafkaQueue    | 	log.cleaner.io.buffer.size = 524288
kafkaQueue    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafkaQueue    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafkaQueue    | 	log.cleaner.min.cleanable.ratio = 0.5
kafkaQueue    | 	log.cleaner.min.compaction.lag.ms = 0
kafkaQueue    | 	log.cleaner.threads = 1
kafkaQueue    | 	log.cleanup.policy = [delete]
kafkaQueue    | 	log.dir = /tmp/kafka-logs
kafkaQueue    | 	log.dir.failure.timeout.ms = 30000
kafkaQueue    | 	log.dirs = null
kafkaQueue    | 	log.flush.interval.messages = 9223372036854775807
kafkaQueue    | 	log.flush.interval.ms = null
kafkaQueue    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafkaQueue    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.index.interval.bytes = 4096
kafkaQueue    | 	log.index.size.max.bytes = 10485760
kafkaQueue    | 	log.initial.task.delay.ms = 30000
kafkaQueue    | 	log.local.retention.bytes = -2
kafkaQueue    | 	log.local.retention.ms = -2
kafkaQueue    | 	log.message.timestamp.after.max.ms = 3600000
kafkaQueue    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafkaQueue    | 	log.message.timestamp.type = CreateTime
kafkaQueue    | 	log.preallocate = false
kafkaQueue    | 	log.retention.bytes = -1
kafkaQueue    | 	log.retention.check.interval.ms = 300000
kafkaQueue    | 	log.retention.hours = 168
kafkaQueue    | 	log.retention.minutes = null
kafkaQueue    | 	log.retention.ms = null
kafkaQueue    | 	log.roll.hours = 168
kafkaQueue    | 	log.roll.jitter.hours = 0
kafkaQueue    | 	log.roll.jitter.ms = null
kafkaQueue    | 	log.roll.ms = null
kafkaQueue    | 	log.segment.bytes = 1073741824
kafkaQueue    | 	log.segment.delete.delay.ms = 60000
kafkaQueue    | 	max.connection.creation.rate = 2147483647
kafkaQueue    | 	max.connections = 2147483647
kafkaQueue    | 	max.connections.per.ip = 2147483647
kafkaQueue    | 	max.connections.per.ip.overrides = 
kafkaQueue    | 	max.incremental.fetch.session.cache.slots = 1000
kafkaQueue    | 	max.request.partition.size.limit = 2000
kafkaQueue    | 	message.max.bytes = 1048588
kafkaQueue    | 	metadata.log.dir = null
kafkaQueue    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafkaQueue    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafkaQueue    | 	metadata.log.segment.bytes = 1073741824
kafkaQueue    | 	metadata.log.segment.ms = 604800000
kafkaQueue    | 	metadata.max.idle.interval.ms = 500
kafkaQueue    | 	metadata.max.retention.bytes = 104857600
kafkaQueue    | 	metadata.max.retention.ms = 604800000
kafkaQueue    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafkaQueue    | 	metrics.num.samples = 2
kafkaQueue    | 	metrics.recording.level = INFO
kafkaQueue    | 	metrics.sample.window.ms = 30000
kafkaQueue    | 	min.insync.replicas = 1
kafkaQueue    | 	node.id = 1
kafkaQueue    | 	num.io.threads = 8
kafkaQueue    | 	num.network.threads = 3
kafkaQueue    | 	num.partitions = 1
kafkaQueue    | 	num.recovery.threads.per.data.dir = 2
kafkaQueue    | 	num.replica.alter.log.dirs.threads = null
kafkaQueue    | 	num.replica.fetchers = 1
kafkaQueue    | 	offset.metadata.max.bytes = 4096
kafkaQueue    | 	offsets.commit.timeout.ms = 5000
kafkaQueue    | 	offsets.load.buffer.size = 5242880
kafkaQueue    | 	offsets.retention.check.interval.ms = 600000
kafkaQueue    | 	offsets.retention.minutes = 10080
kafkaQueue    | 	offsets.topic.compression.codec = 0
kafkaQueue    | 	offsets.topic.num.partitions = 50
kafkaQueue    | 	offsets.topic.replication.factor = 1
kafkaQueue    | 	offsets.topic.segment.bytes = 104857600
kafkaQueue    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafkaQueue    | 	process.roles = [broker, controller]
kafkaQueue    | 	producer.id.expiration.check.interval.ms = 600000
kafkaQueue    | 	producer.id.expiration.ms = 86400000
kafkaQueue    | 	producer.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	queued.max.request.bytes = -1
kafkaQueue    | 	queued.max.requests = 500
kafkaQueue    | 	quota.window.num = 11
kafkaQueue    | 	quota.window.size.seconds = 1
kafkaQueue    | 	remote.fetch.max.wait.ms = 500
kafkaQueue    | 	remote.list.offsets.request.timeout.ms = 30000
kafkaQueue    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafkaQueue    | 	remote.log.manager.copier.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.copy.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.expiration.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.fetch.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.task.interval.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.ms = 500
kafkaQueue    | 	remote.log.manager.task.retry.jitter = 0.2
kafkaQueue    | 	remote.log.manager.thread.pool.size = 2
kafkaQueue    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafkaQueue    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafkaQueue    | 	remote.log.metadata.manager.class.path = null
kafkaQueue    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafkaQueue    | 	remote.log.metadata.manager.listener.name = null
kafkaQueue    | 	remote.log.reader.max.pending.tasks = 100
kafkaQueue    | 	remote.log.reader.threads = 10
kafkaQueue    | 	remote.log.storage.manager.class.name = null
kafkaQueue    | 	remote.log.storage.manager.class.path = null
kafkaQueue    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafkaQueue    | 	remote.log.storage.system.enable = false
kafkaQueue    | 	replica.fetch.backoff.ms = 1000
kafkaQueue    | 	replica.fetch.max.bytes = 1048576
kafkaQueue    | 	replica.fetch.min.bytes = 1
kafkaQueue    | 	replica.fetch.response.max.bytes = 10485760
kafkaQueue    | 	replica.fetch.wait.max.ms = 500
kafkaQueue    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafkaQueue    | 	replica.lag.time.max.ms = 30000
kafkaQueue    | 	replica.selector.class = null
kafkaQueue    | 	replica.socket.receive.buffer.bytes = 65536
kafkaQueue    | 	replica.socket.timeout.ms = 30000
kafkaQueue    | 	replication.quota.window.num = 11
kafkaQueue    | 	replication.quota.window.size.seconds = 1
kafkaQueue    | 	request.timeout.ms = 30000
kafkaQueue    | 	sasl.client.callback.handler.class = null
kafkaQueue    | 	sasl.enabled.mechanisms = [GSSAPI]
kafkaQueue    | 	sasl.jaas.config = null
kafkaQueue    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafkaQueue    | 	sasl.kerberos.min.time.before.relogin = 60000
kafkaQueue    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafkaQueue    | 	sasl.kerberos.service.name = null
kafkaQueue    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafkaQueue    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafkaQueue    | 	sasl.login.callback.handler.class = null
kafkaQueue    | 	sasl.login.class = null
kafkaQueue    | 	sasl.login.connect.timeout.ms = null
kafkaQueue    | 	sasl.login.read.timeout.ms = null
kafkaQueue    | 	sasl.login.refresh.buffer.seconds = 300
kafkaQueue    | 	sasl.login.refresh.min.period.seconds = 60
kafkaQueue    | 	sasl.login.refresh.window.factor = 0.8
kafkaQueue    | 	sasl.login.refresh.window.jitter = 0.05
kafkaQueue    | 	sasl.login.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.login.retry.backoff.ms = 100
kafkaQueue    | 	sasl.mechanism.controller.protocol = GSSAPI
kafkaQueue    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafkaQueue    | 	sasl.oauthbearer.assertion.algorithm = RS256
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.aud = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.iss = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.sub = null
kafkaQueue    | 	sasl.oauthbearer.assertion.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafkaQueue    | 	sasl.oauthbearer.assertion.template.file = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.id = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.secret = null
kafkaQueue    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafkaQueue    | 	sasl.oauthbearer.expected.audience = null
kafkaQueue    | 	sasl.oauthbearer.expected.issuer = null
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafkaQueue    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafkaQueue    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafkaQueue    | 	sasl.oauthbearer.scope = null
kafkaQueue    | 	sasl.oauthbearer.scope.claim.name = scope
kafkaQueue    | 	sasl.oauthbearer.sub.claim.name = sub
kafkaQueue    | 	sasl.oauthbearer.token.endpoint.url = null
kafkaQueue    | 	sasl.server.callback.handler.class = null
kafkaQueue    | 	sasl.server.max.receive.size = 524288
kafkaQueue    | 	security.inter.broker.protocol = PLAINTEXT
kafkaQueue    | 	security.providers = null
kafkaQueue    | 	server.max.startup.time.ms = 9223372036854775807
kafkaQueue    | 	share.coordinator.append.linger.ms = 5
kafkaQueue    | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafkaQueue    | 	share.coordinator.load.buffer.size = 5242880
kafkaQueue    | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafkaQueue    | 	share.coordinator.state.topic.compression.codec = 0
kafkaQueue    | 	share.coordinator.state.topic.min.isr = 2
kafkaQueue    | 	share.coordinator.state.topic.num.partitions = 50
kafkaQueue    | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafkaQueue    | 	share.coordinator.state.topic.replication.factor = 3
kafkaQueue    | 	share.coordinator.state.topic.segment.bytes = 104857600
kafkaQueue    | 	share.coordinator.threads = 1
kafkaQueue    | 	share.coordinator.write.timeout.ms = 5000
kafkaQueue    | 	share.fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	socket.connection.setup.timeout.max.ms = 30000
kafkaQueue    | 	socket.connection.setup.timeout.ms = 10000
kafkaQueue    | 	socket.listen.backlog.size = 50
kafkaQueue    | 	socket.receive.buffer.bytes = 102400
kafkaQueue    | 	socket.request.max.bytes = 104857600
kafkaQueue    | 	socket.send.buffer.bytes = 102400
kafkaQueue    | 	ssl.allow.dn.changes = false
kafkaQueue    | 	ssl.allow.san.changes = false
kafkaQueue    | 	ssl.cipher.suites = []
kafkaQueue    | 	ssl.client.auth = none
kafkaQueue    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafkaQueue    | 	ssl.endpoint.identification.algorithm = https
kafkaQueue    | 	ssl.engine.factory.class = null
kafkaQueue    | 	ssl.key.password = null
kafkaQueue    | 	ssl.keymanager.algorithm = SunX509
kafkaQueue    | 	ssl.keystore.certificate.chain = null
kafkaQueue    | 	ssl.keystore.key = null
kafkaQueue    | 	ssl.keystore.location = null
kafkaQueue    | 	ssl.keystore.password = null
kafkaQueue    | 	ssl.keystore.type = JKS
kafkaQueue    | 	ssl.principal.mapping.rules = DEFAULT
kafkaQueue    | 	ssl.protocol = TLSv1.3
kafkaQueue    | 	ssl.provider = null
kafkaQueue    | 	ssl.secure.random.implementation = null
kafkaQueue    | 	ssl.trustmanager.algorithm = PKIX
kafkaQueue    | 	ssl.truststore.certificates = null
kafkaQueue    | 	ssl.truststore.location = null
kafkaQueue    | 	ssl.truststore.password = null
kafkaQueue    | 	ssl.truststore.type = JKS
kafkaQueue    | 	telemetry.max.bytes = 1048576
kafkaQueue    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafkaQueue    | 	transaction.max.timeout.ms = 900000
kafkaQueue    | 	transaction.partition.verification.enable = true
kafkaQueue    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafkaQueue    | 	transaction.state.log.load.buffer.size = 5242880
kafkaQueue    | 	transaction.state.log.min.isr = 1
kafkaQueue    | 	transaction.state.log.num.partitions = 50
kafkaQueue    | 	transaction.state.log.replication.factor = 1
kafkaQueue    | 	transaction.state.log.segment.bytes = 104857600
kafkaQueue    | 	transaction.two.phase.commit.enable = false
kafkaQueue    | 	transactional.id.expiration.ms = 604800000
kafkaQueue    | 	unclean.leader.election.enable = false
kafkaQueue    | 	unclean.leader.election.interval.ms = 300000
kafkaQueue    | 	unstable.api.versions.enable = false
kafkaQueue    | 	unstable.feature.versions.enable = false
kafkaQueue    |  (org.apache.kafka.common.config.AbstractConfig)
kafkaQueue    | [2025-12-08 14:40:59,230] INFO [BrokerServer id=1] Waiting for controller quorum voters future (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,230] INFO [BrokerServer id=1] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,241] INFO [broker-1-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,242] INFO [broker-1-to-controller-forwarding-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,255] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicClientQuotaPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,258] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DynamicTopicClusterQuotaPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,259] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ScramPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,262] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing DelegationTokenPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,264] INFO [client-metrics-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 14:40:59,265] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing ControllerMetadataMetricsPublisher with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,266] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing AclPublisher controller id=1 with a snapshot at offset 7 (org.apache.kafka.image.loader.MetadataLoader)
sql_db        | 2025-12-08 14:40:59.26 Server      Buffer pool extension is not supported on Linux platform.
kafkaQueue    | [2025-12-08 14:40:59,309] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
sql_db        | 2025-12-08 14:40:59.30 Server      Buffer Pool: Allocating 8388608 bytes for 867857 hashPages.
kafkaQueue    | [2025-12-08 14:40:59,316] INFO [SocketServer listenerType=BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
kafkaQueue    | [2025-12-08 14:40:59,328] INFO [broker-1-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,329] INFO [broker-1-to-controller-alter-partition-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,341] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,342] INFO [broker-1-to-controller-directory-assignments-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,345] INFO [ExpirationReaper-1-Produce]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 14:40:59,347] INFO [ExpirationReaper-1-Fetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 14:40:59,348] INFO [ExpirationReaper-1-DeleteRecords]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 14:40:59,350] INFO [ExpirationReaper-1-RemoteFetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 14:40:59,351] INFO [ExpirationReaper-1-RemoteListOffsets]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 14:40:59,353] INFO [ExpirationReaper-1-ShareFetch]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 14:40:59,368] INFO [ControllerRegistrationManager id=1 incarnation=ClQECL76TAmj0JqFhys8-A] Our registration has been persisted to the metadata log. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 14:40:59,369] INFO [ControllerRegistrationManager id=1 incarnation=ClQECL76TAmj0JqFhys8-A] RegistrationResponseHandler: controller acknowledged ControllerRegistrationRequest. (kafka.server.ControllerRegistrationManager)
kafkaQueue    | [2025-12-08 14:40:59,375] INFO [share-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 14:40:59,399] INFO [share-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 14:40:59,404] INFO [persister-state-manager-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 14:40:59,406] INFO [PersisterStateManager]: Starting (org.apache.kafka.server.share.persister.PersisterStateManager$SendThread)
kafkaQueue    | [2025-12-08 14:40:59,407] INFO [group-coordinator-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 14:40:59,417] INFO [group-coordinator-event-processor-0]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 14:40:59,421] INFO [group-coordinator-event-processor-1]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 14:40:59,421] INFO [group-coordinator-event-processor-2]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 14:40:59,423] INFO [group-coordinator-event-processor-3]: Starting (org.apache.kafka.coordinator.common.runtime.MultiThreadedEventProcessor$EventProcessorThread)
kafkaQueue    | [2025-12-08 14:40:59,454] INFO Unable to read the broker epoch in /tmp/kafka-logs. (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 14:40:59,460] INFO [broker-1-to-controller-heartbeat-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,463] INFO [broker-1-to-controller-heartbeat-channel-manager]: Recorded new KRaft controller, from now on will use node kafkaQueue:9093 (id: 1 rack: null isFenced: false) (kafka.server.NodeToControllerRequestThread)
kafkaQueue    | [2025-12-08 14:40:59,465] INFO [BrokerLifecycleManager id=1] Incarnation 41wf9A-8S_apY-KQi-vscw of broker 1 in cluster 5L6g3nShT-eMCtK--X86sw is now STARTING. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2025-12-08 14:40:59,480] INFO [share-group-lock-timeout-reaper]: Starting (org.apache.kafka.server.util.timer.SystemTimerReaper$Reaper)
kafkaQueue    | [2025-12-08 14:40:59,483] INFO [ExpirationReaper-1-AlterAcls]: Starting (org.apache.kafka.server.purgatory.DelayedOperationPurgatory$ExpiredOperationReaper)
kafkaQueue    | [2025-12-08 14:40:59,520] INFO [BrokerServer id=1] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,520] INFO [BrokerServer id=1] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,520] INFO [BrokerServer id=1] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,520] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing MetadataVersionPublisher(id=1) with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,521] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
sql_db        | 2025-12-08 14:40:59.51 Server      Buffer pool extension is already disabled. No action is necessary.
kafkaQueue    | [2025-12-08 14:40:59,530] INFO [BrokerMetadataPublisher id=1] Publishing initial metadata at offset OffsetAndEpoch[offset=8, epoch=1] with metadata.version Optional[4.1-IV1]. (kafka.server.metadata.BrokerMetadataPublisher)
kafkaQueue    | [2025-12-08 14:40:59,533] INFO Loading logs from log dirs ArrayBuffer(/tmp/kafka-logs) (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 14:40:59,534] INFO [BrokerLifecycleManager id=1] Successfully registered broker 1 with broker epoch 9 (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2025-12-08 14:40:59,540] INFO No logs found to be loaded in /tmp/kafka-logs (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 14:40:59,579] INFO Loaded 0 logs in 43ms (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 14:40:59,585] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 14:40:59,596] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafkaQueue    | [2025-12-08 14:40:59,711] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
kafkaQueue    | [2025-12-08 14:40:59,712] INFO [AddPartitionsToTxnSenderThread-1]: Starting (org.apache.kafka.server.transaction.AddPartitionsToTxnManager)
kafkaQueue    | [2025-12-08 14:40:59,713] INFO [GroupCoordinator id=1] Starting up. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
kafkaQueue    | [2025-12-08 14:40:59,714] INFO [GroupCoordinator id=1] Startup complete. (org.apache.kafka.coordinator.group.GroupCoordinatorService)
kafkaQueue    | [2025-12-08 14:40:59,717] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
kafkaQueue    | [2025-12-08 14:40:59,720] INFO [TxnMarkerSenderThread-1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
kafkaQueue    | [2025-12-08 14:40:59,720] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
kafkaQueue    | [2025-12-08 14:40:59,723] INFO [ShareCoordinator id=1] Starting up. (org.apache.kafka.coordinator.share.ShareCoordinatorService)
kafkaQueue    | [2025-12-08 14:40:59,724] INFO [ShareCoordinator id=1] Startup complete. (org.apache.kafka.coordinator.share.ShareCoordinatorService)
kafkaQueue    | [2025-12-08 14:40:59,731] INFO [DynamicConfigPublisher broker id=1] Updating cluster configuration : min.insync.replicas -> 1 (kafka.server.metadata.DynamicConfigPublisher)
kafkaQueue    | [2025-12-08 14:40:59,734] INFO KafkaConfig values: 
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.ms = 20
kafkaQueue    | 	advertised.listeners = PLAINTEXT://kafkaQueue:9092
kafkaQueue    | 	alter.config.policy.class.name = null
kafkaQueue    | 	alter.log.dirs.replication.quota.window.num = 11
kafkaQueue    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafkaQueue    | 	authorizer.class.name = 
kafkaQueue    | 	auto.create.topics.enable = true
kafkaQueue    | 	auto.leader.rebalance.enable = true
kafkaQueue    | 	background.threads = 10
kafkaQueue    | 	broker.heartbeat.interval.ms = 2000
kafkaQueue    | 	broker.id = 1
kafkaQueue    | 	broker.rack = null
kafkaQueue    | 	broker.session.timeout.ms = 9000
kafkaQueue    | 	client.quota.callback.class = null
kafkaQueue    | 	compression.gzip.level = -1
kafkaQueue    | 	compression.lz4.level = 9
kafkaQueue    | 	compression.type = producer
kafkaQueue    | 	compression.zstd.level = 3
kafkaQueue    | 	connection.failed.authentication.delay.ms = 100
kafkaQueue    | 	connections.max.idle.ms = 600000
kafkaQueue    | 	connections.max.reauth.ms = 0
kafkaQueue    | 	controlled.shutdown.enable = true
kafkaQueue    | 	controller.listener.names = CONTROLLER
kafkaQueue    | 	controller.performance.always.log.threshold.ms = 2000
kafkaQueue    | 	controller.performance.sample.period.ms = 60000
kafkaQueue    | 	controller.quorum.append.linger.ms = 25
kafkaQueue    | 	controller.quorum.bootstrap.servers = []
kafkaQueue    | 	controller.quorum.election.backoff.max.ms = 1000
kafkaQueue    | 	controller.quorum.election.timeout.ms = 1000
kafkaQueue    | 	controller.quorum.fetch.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.request.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.retry.backoff.ms = 20
kafkaQueue    | 	controller.quorum.voters = [1@kafkaQueue:9093]
kafkaQueue    | 	controller.quota.window.num = 11
kafkaQueue    | 	controller.quota.window.size.seconds = 1
kafkaQueue    | 	controller.socket.timeout.ms = 30000
kafkaQueue    | 	create.topic.policy.class.name = null
kafkaQueue    | 	default.replication.factor = 1
kafkaQueue    | 	delegation.token.expiry.check.interval.ms = 3600000
kafkaQueue    | 	delegation.token.expiry.time.ms = 86400000
kafkaQueue    | 	delegation.token.max.lifetime.ms = 604800000
kafkaQueue    | 	delegation.token.secret.key = null
kafkaQueue    | 	delete.records.purgatory.purge.interval.requests = 1
kafkaQueue    | 	delete.topic.enable = true
kafkaQueue    | 	early.start.listeners = null
kafkaQueue    | 	fetch.max.bytes = 57671680
kafkaQueue    | 	fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	group.consumer.assignors = [uniform, range]
kafkaQueue    | 	group.consumer.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.consumer.max.session.timeout.ms = 60000
kafkaQueue    | 	group.consumer.max.size = 2147483647
kafkaQueue    | 	group.consumer.migration.policy = bidirectional
kafkaQueue    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.min.session.timeout.ms = 45000
kafkaQueue    | 	group.consumer.regex.refresh.interval.ms = 600000
kafkaQueue    | 	group.consumer.session.timeout.ms = 45000
kafkaQueue    | 	group.coordinator.append.linger.ms = 5
kafkaQueue    | 	group.coordinator.rebalance.protocols = [classic, consumer, streams]
kafkaQueue    | 	group.coordinator.threads = 4
kafkaQueue    | 	group.initial.rebalance.delay.ms = 3000
kafkaQueue    | 	group.max.session.timeout.ms = 1800000
kafkaQueue    | 	group.max.size = 2147483647
kafkaQueue    | 	group.min.session.timeout.ms = 6000
kafkaQueue    | 	group.share.assignors = [simple]
kafkaQueue    | 	group.share.delivery.count.limit = 5
kafkaQueue    | 	group.share.enable = false
kafkaQueue    | 	group.share.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.share.max.record.lock.duration.ms = 60000
kafkaQueue    | 	group.share.max.session.timeout.ms = 60000
kafkaQueue    | 	group.share.max.share.sessions = 2000
kafkaQueue    | 	group.share.max.size = 200
kafkaQueue    | 	group.share.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.min.record.lock.duration.ms = 15000
kafkaQueue    | 	group.share.min.session.timeout.ms = 45000
kafkaQueue    | 	group.share.partition.max.record.locks = 2000
kafkaQueue    | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafkaQueue    | 	group.share.record.lock.duration.ms = 30000
kafkaQueue    | 	group.share.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.streams.max.session.timeout.ms = 60000
kafkaQueue    | 	group.streams.max.size = 2147483647
kafkaQueue    | 	group.streams.max.standby.replicas = 2
kafkaQueue    | 	group.streams.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.min.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.num.standby.replicas = 0
kafkaQueue    | 	group.streams.session.timeout.ms = 45000
kafkaQueue    | 	initial.broker.registration.timeout.ms = 60000
kafkaQueue    | 	inter.broker.listener.name = null
kafkaQueue    | 	internal.metadata.delete.delay.millis = 60000
kafkaQueue    | 	internal.metadata.log.segment.bytes = null
kafkaQueue    | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafkaQueue    | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafkaQueue    | 	kafka.metrics.polling.interval.secs = 10
kafkaQueue    | 	kafka.metrics.reporters = []
kafkaQueue    | 	leader.imbalance.check.interval.seconds = 300
kafkaQueue    | 	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
kafkaQueue    | 	listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
kafkaQueue    | 	log.cleaner.backoff.ms = 15000
kafkaQueue    | 	log.cleaner.dedupe.buffer.size = 134217728
kafkaQueue    | 	log.cleaner.delete.retention.ms = 86400000
kafkaQueue    | 	log.cleaner.enable = true
kafkaQueue    | 	log.cleaner.io.buffer.load.factor = 0.9
kafkaQueue    | 	log.cleaner.io.buffer.size = 524288
kafkaQueue    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafkaQueue    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafkaQueue    | 	log.cleaner.min.cleanable.ratio = 0.5
kafkaQueue    | 	log.cleaner.min.compaction.lag.ms = 0
kafkaQueue    | 	log.cleaner.threads = 1
kafkaQueue    | 	log.cleanup.policy = [delete]
kafkaQueue    | 	log.dir = /tmp/kafka-logs
kafkaQueue    | 	log.dir.failure.timeout.ms = 30000
kafkaQueue    | 	log.dirs = null
kafkaQueue    | 	log.flush.interval.messages = 9223372036854775807
kafkaQueue    | 	log.flush.interval.ms = null
kafkaQueue    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafkaQueue    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.index.interval.bytes = 4096
kafkaQueue    | 	log.index.size.max.bytes = 10485760
kafkaQueue    | 	log.initial.task.delay.ms = 30000
kafkaQueue    | 	log.local.retention.bytes = -2
kafkaQueue    | 	log.local.retention.ms = -2
kafkaQueue    | 	log.message.timestamp.after.max.ms = 3600000
kafkaQueue    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafkaQueue    | 	log.message.timestamp.type = CreateTime
kafkaQueue    | 	log.preallocate = false
kafkaQueue    | 	log.retention.bytes = -1
kafkaQueue    | 	log.retention.check.interval.ms = 300000
kafkaQueue    | 	log.retention.hours = 168
kafkaQueue    | 	log.retention.minutes = null
kafkaQueue    | 	log.retention.ms = null
kafkaQueue    | 	log.roll.hours = 168
kafkaQueue    | 	log.roll.jitter.hours = 0
kafkaQueue    | 	log.roll.jitter.ms = null
kafkaQueue    | 	log.roll.ms = null
kafkaQueue    | 	log.segment.bytes = 1073741824
kafkaQueue    | 	log.segment.delete.delay.ms = 60000
kafkaQueue    | 	max.connection.creation.rate = 2147483647
kafkaQueue    | 	max.connections = 2147483647
kafkaQueue    | 	max.connections.per.ip = 2147483647
kafkaQueue    | 	max.connections.per.ip.overrides = 
kafkaQueue    | 	max.incremental.fetch.session.cache.slots = 1000
kafkaQueue    | 	max.request.partition.size.limit = 2000
kafkaQueue    | 	message.max.bytes = 1048588
kafkaQueue    | 	metadata.log.dir = null
kafkaQueue    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafkaQueue    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafkaQueue    | 	metadata.log.segment.bytes = 1073741824
kafkaQueue    | 	metadata.log.segment.ms = 604800000
kafkaQueue    | 	metadata.max.idle.interval.ms = 500
kafkaQueue    | 	metadata.max.retention.bytes = 104857600
kafkaQueue    | 	metadata.max.retention.ms = 604800000
kafkaQueue    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafkaQueue    | 	metrics.num.samples = 2
kafkaQueue    | 	metrics.recording.level = INFO
kafkaQueue    | 	metrics.sample.window.ms = 30000
kafkaQueue    | 	min.insync.replicas = 1
kafkaQueue    | 	node.id = 1
kafkaQueue    | 	num.io.threads = 8
kafkaQueue    | 	num.network.threads = 3
kafkaQueue    | 	num.partitions = 1
kafkaQueue    | 	num.recovery.threads.per.data.dir = 2
kafkaQueue    | 	num.replica.alter.log.dirs.threads = null
kafkaQueue    | 	num.replica.fetchers = 1
kafkaQueue    | 	offset.metadata.max.bytes = 4096
kafkaQueue    | 	offsets.commit.timeout.ms = 5000
kafkaQueue    | 	offsets.load.buffer.size = 5242880
kafkaQueue    | 	offsets.retention.check.interval.ms = 600000
kafkaQueue    | 	offsets.retention.minutes = 10080
kafkaQueue    | 	offsets.topic.compression.codec = 0
kafkaQueue    | 	offsets.topic.num.partitions = 50
kafkaQueue    | 	offsets.topic.replication.factor = 1
kafkaQueue    | 	offsets.topic.segment.bytes = 104857600
kafkaQueue    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafkaQueue    | 	process.roles = [broker, controller]
kafkaQueue    | 	producer.id.expiration.check.interval.ms = 600000
kafkaQueue    | 	producer.id.expiration.ms = 86400000
kafkaQueue    | 	producer.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	queued.max.request.bytes = -1
kafkaQueue    | 	queued.max.requests = 500
kafkaQueue    | 	quota.window.num = 11
kafkaQueue    | 	quota.window.size.seconds = 1
kafkaQueue    | 	remote.fetch.max.wait.ms = 500
kafkaQueue    | 	remote.list.offsets.request.timeout.ms = 30000
kafkaQueue    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafkaQueue    | 	remote.log.manager.copier.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.copy.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.expiration.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.fetch.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.task.interval.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.ms = 500
kafkaQueue    | 	remote.log.manager.task.retry.jitter = 0.2
kafkaQueue    | 	remote.log.manager.thread.pool.size = 2
kafkaQueue    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafkaQueue    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafkaQueue    | 	remote.log.metadata.manager.class.path = null
kafkaQueue    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafkaQueue    | 	remote.log.metadata.manager.listener.name = null
kafkaQueue    | 	remote.log.reader.max.pending.tasks = 100
kafkaQueue    | 	remote.log.reader.threads = 10
kafkaQueue    | 	remote.log.storage.manager.class.name = null
kafkaQueue    | 	remote.log.storage.manager.class.path = null
kafkaQueue    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafkaQueue    | 	remote.log.storage.system.enable = false
kafkaQueue    | 	replica.fetch.backoff.ms = 1000
kafkaQueue    | 	replica.fetch.max.bytes = 1048576
kafkaQueue    | 	replica.fetch.min.bytes = 1
kafkaQueue    | 	replica.fetch.response.max.bytes = 10485760
kafkaQueue    | 	replica.fetch.wait.max.ms = 500
kafkaQueue    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafkaQueue    | 	replica.lag.time.max.ms = 30000
kafkaQueue    | 	replica.selector.class = null
kafkaQueue    | 	replica.socket.receive.buffer.bytes = 65536
kafkaQueue    | 	replica.socket.timeout.ms = 30000
kafkaQueue    | 	replication.quota.window.num = 11
kafkaQueue    | 	replication.quota.window.size.seconds = 1
kafkaQueue    | 	request.timeout.ms = 30000
kafkaQueue    | 	sasl.client.callback.handler.class = null
kafkaQueue    | 	sasl.enabled.mechanisms = [GSSAPI]
kafkaQueue    | 	sasl.jaas.config = null
kafkaQueue    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafkaQueue    | 	sasl.kerberos.min.time.before.relogin = 60000
kafkaQueue    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafkaQueue    | 	sasl.kerberos.service.name = null
kafkaQueue    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafkaQueue    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafkaQueue    | 	sasl.login.callback.handler.class = null
kafkaQueue    | 	sasl.login.class = null
kafkaQueue    | 	sasl.login.connect.timeout.ms = null
kafkaQueue    | 	sasl.login.read.timeout.ms = null
kafkaQueue    | 	sasl.login.refresh.buffer.seconds = 300
kafkaQueue    | 	sasl.login.refresh.min.period.seconds = 60
kafkaQueue    | 	sasl.login.refresh.window.factor = 0.8
kafkaQueue    | 	sasl.login.refresh.window.jitter = 0.05
kafkaQueue    | 	sasl.login.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.login.retry.backoff.ms = 100
kafkaQueue    | 	sasl.mechanism.controller.protocol = GSSAPI
kafkaQueue    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafkaQueue    | 	sasl.oauthbearer.assertion.algorithm = RS256
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.aud = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.iss = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.sub = null
kafkaQueue    | 	sasl.oauthbearer.assertion.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafkaQueue    | 	sasl.oauthbearer.assertion.template.file = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.id = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.secret = null
kafkaQueue    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafkaQueue    | 	sasl.oauthbearer.expected.audience = null
kafkaQueue    | 	sasl.oauthbearer.expected.issuer = null
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafkaQueue    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafkaQueue    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafkaQueue    | 	sasl.oauthbearer.scope = null
kafkaQueue    | 	sasl.oauthbearer.scope.claim.name = scope
kafkaQueue    | 	sasl.oauthbearer.sub.claim.name = sub
kafkaQueue    | 	sasl.oauthbearer.token.endpoint.url = null
kafkaQueue    | 	sasl.server.callback.handler.class = null
kafkaQueue    | 	sasl.server.max.receive.size = 524288
kafkaQueue    | 	security.inter.broker.protocol = PLAINTEXT
kafkaQueue    | 	security.providers = null
kafkaQueue    | 	server.max.startup.time.ms = 9223372036854775807
kafkaQueue    | 	share.coordinator.append.linger.ms = 5
kafkaQueue    | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafkaQueue    | 	share.coordinator.load.buffer.size = 5242880
kafkaQueue    | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafkaQueue    | 	share.coordinator.state.topic.compression.codec = 0
kafkaQueue    | 	share.coordinator.state.topic.min.isr = 2
kafkaQueue    | 	share.coordinator.state.topic.num.partitions = 50
kafkaQueue    | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafkaQueue    | 	share.coordinator.state.topic.replication.factor = 3
kafkaQueue    | 	share.coordinator.state.topic.segment.bytes = 104857600
kafkaQueue    | 	share.coordinator.threads = 1
kafkaQueue    | 	share.coordinator.write.timeout.ms = 5000
kafkaQueue    | 	share.fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	socket.connection.setup.timeout.max.ms = 30000
kafkaQueue    | 	socket.connection.setup.timeout.ms = 10000
kafkaQueue    | 	socket.listen.backlog.size = 50
kafkaQueue    | 	socket.receive.buffer.bytes = 102400
kafkaQueue    | 	socket.request.max.bytes = 104857600
kafkaQueue    | 	socket.send.buffer.bytes = 102400
kafkaQueue    | 	ssl.allow.dn.changes = false
kafkaQueue    | 	ssl.allow.san.changes = false
kafkaQueue    | 	ssl.cipher.suites = []
kafkaQueue    | 	ssl.client.auth = none
kafkaQueue    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafkaQueue    | 	ssl.endpoint.identification.algorithm = https
kafkaQueue    | 	ssl.engine.factory.class = null
kafkaQueue    | 	ssl.key.password = null
kafkaQueue    | 	ssl.keymanager.algorithm = SunX509
kafkaQueue    | 	ssl.keystore.certificate.chain = null
kafkaQueue    | 	ssl.keystore.key = null
kafkaQueue    | 	ssl.keystore.location = null
kafkaQueue    | 	ssl.keystore.password = null
kafkaQueue    | 	ssl.keystore.type = JKS
kafkaQueue    | 	ssl.principal.mapping.rules = DEFAULT
kafkaQueue    | 	ssl.protocol = TLSv1.3
kafkaQueue    | 	ssl.provider = null
kafkaQueue    | 	ssl.secure.random.implementation = null
kafkaQueue    | 	ssl.trustmanager.algorithm = PKIX
kafkaQueue    | 	ssl.truststore.certificates = null
kafkaQueue    | 	ssl.truststore.location = null
kafkaQueue    | 	ssl.truststore.password = null
kafkaQueue    | 	ssl.truststore.type = JKS
kafkaQueue    | 	telemetry.max.bytes = 1048576
kafkaQueue    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafkaQueue    | 	transaction.max.timeout.ms = 900000
kafkaQueue    | 	transaction.partition.verification.enable = true
kafkaQueue    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafkaQueue    | 	transaction.state.log.load.buffer.size = 5242880
kafkaQueue    | 	transaction.state.log.min.isr = 1
kafkaQueue    | 	transaction.state.log.num.partitions = 50
kafkaQueue    | 	transaction.state.log.replication.factor = 1
kafkaQueue    | 	transaction.state.log.segment.bytes = 104857600
kafkaQueue    | 	transaction.two.phase.commit.enable = false
kafkaQueue    | 	transactional.id.expiration.ms = 604800000
kafkaQueue    | 	unclean.leader.election.enable = false
kafkaQueue    | 	unclean.leader.election.interval.ms = 300000
kafkaQueue    | 	unstable.api.versions.enable = false
kafkaQueue    | 	unstable.feature.versions.enable = false
kafkaQueue    |  (org.apache.kafka.common.config.AbstractConfig)
kafkaQueue    | [2025-12-08 14:40:59,752] INFO [MetadataLoader id=1] InitializeNewPublishers: initializing BrokerRegistrationTracker(id=1) with a snapshot at offset 8 (org.apache.kafka.image.loader.MetadataLoader)
kafkaQueue    | [2025-12-08 14:40:59,760] INFO [BrokerLifecycleManager id=1] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2025-12-08 14:40:59,760] INFO [BrokerServer id=1] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,760] INFO [BrokerServer id=1] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,761] INFO [BrokerServer id=1] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,762] INFO KafkaConfig values: 
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.max.ms = 100
kafkaQueue    | 	add.partitions.to.txn.retry.backoff.ms = 20
kafkaQueue    | 	advertised.listeners = PLAINTEXT://kafkaQueue:9092
kafkaQueue    | 	alter.config.policy.class.name = null
kafkaQueue    | 	alter.log.dirs.replication.quota.window.num = 11
kafkaQueue    | 	alter.log.dirs.replication.quota.window.size.seconds = 1
kafkaQueue    | 	authorizer.class.name = 
kafkaQueue    | 	auto.create.topics.enable = true
kafkaQueue    | 	auto.leader.rebalance.enable = true
kafkaQueue    | 	background.threads = 10
kafkaQueue    | 	broker.heartbeat.interval.ms = 2000
kafkaQueue    | 	broker.id = 1
kafkaQueue    | 	broker.rack = null
kafkaQueue    | 	broker.session.timeout.ms = 9000
kafkaQueue    | 	client.quota.callback.class = null
kafkaQueue    | 	compression.gzip.level = -1
kafkaQueue    | 	compression.lz4.level = 9
kafkaQueue    | 	compression.type = producer
kafkaQueue    | 	compression.zstd.level = 3
kafkaQueue    | 	connection.failed.authentication.delay.ms = 100
kafkaQueue    | 	connections.max.idle.ms = 600000
kafkaQueue    | 	connections.max.reauth.ms = 0
kafkaQueue    | 	controlled.shutdown.enable = true
kafkaQueue    | 	controller.listener.names = CONTROLLER
kafkaQueue    | 	controller.performance.always.log.threshold.ms = 2000
kafkaQueue    | 	controller.performance.sample.period.ms = 60000
kafkaQueue    | 	controller.quorum.append.linger.ms = 25
kafkaQueue    | 	controller.quorum.bootstrap.servers = []
kafkaQueue    | 	controller.quorum.election.backoff.max.ms = 1000
kafkaQueue    | 	controller.quorum.election.timeout.ms = 1000
kafkaQueue    | 	controller.quorum.fetch.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.request.timeout.ms = 2000
kafkaQueue    | 	controller.quorum.retry.backoff.ms = 20
kafkaQueue    | 	controller.quorum.voters = [1@kafkaQueue:9093]
kafkaQueue    | 	controller.quota.window.num = 11
kafkaQueue    | 	controller.quota.window.size.seconds = 1
kafkaQueue    | 	controller.socket.timeout.ms = 30000
kafkaQueue    | 	create.topic.policy.class.name = null
kafkaQueue    | 	default.replication.factor = 1
kafkaQueue    | 	delegation.token.expiry.check.interval.ms = 3600000
kafkaQueue    | 	delegation.token.expiry.time.ms = 86400000
kafkaQueue    | 	delegation.token.max.lifetime.ms = 604800000
kafkaQueue    | 	delegation.token.secret.key = null
kafkaQueue    | 	delete.records.purgatory.purge.interval.requests = 1
kafkaQueue    | 	delete.topic.enable = true
kafkaQueue    | 	early.start.listeners = null
kafkaQueue    | 	fetch.max.bytes = 57671680
kafkaQueue    | 	fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	group.consumer.assignors = [uniform, range]
kafkaQueue    | 	group.consumer.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.consumer.max.session.timeout.ms = 60000
kafkaQueue    | 	group.consumer.max.size = 2147483647
kafkaQueue    | 	group.consumer.migration.policy = bidirectional
kafkaQueue    | 	group.consumer.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.consumer.min.session.timeout.ms = 45000
kafkaQueue    | 	group.consumer.regex.refresh.interval.ms = 600000
kafkaQueue    | 	group.consumer.session.timeout.ms = 45000
kafkaQueue    | 	group.coordinator.append.linger.ms = 5
kafkaQueue    | 	group.coordinator.rebalance.protocols = [classic, consumer, streams]
kafkaQueue    | 	group.coordinator.threads = 4
kafkaQueue    | 	group.initial.rebalance.delay.ms = 3000
kafkaQueue    | 	group.max.session.timeout.ms = 1800000
kafkaQueue    | 	group.max.size = 2147483647
kafkaQueue    | 	group.min.session.timeout.ms = 6000
kafkaQueue    | 	group.share.assignors = [simple]
kafkaQueue    | 	group.share.delivery.count.limit = 5
kafkaQueue    | 	group.share.enable = false
kafkaQueue    | 	group.share.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.share.max.record.lock.duration.ms = 60000
kafkaQueue    | 	group.share.max.session.timeout.ms = 60000
kafkaQueue    | 	group.share.max.share.sessions = 2000
kafkaQueue    | 	group.share.max.size = 200
kafkaQueue    | 	group.share.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.share.min.record.lock.duration.ms = 15000
kafkaQueue    | 	group.share.min.session.timeout.ms = 45000
kafkaQueue    | 	group.share.partition.max.record.locks = 2000
kafkaQueue    | 	group.share.persister.class.name = org.apache.kafka.server.share.persister.DefaultStatePersister
kafkaQueue    | 	group.share.record.lock.duration.ms = 30000
kafkaQueue    | 	group.share.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.max.heartbeat.interval.ms = 15000
kafkaQueue    | 	group.streams.max.session.timeout.ms = 60000
kafkaQueue    | 	group.streams.max.size = 2147483647
kafkaQueue    | 	group.streams.max.standby.replicas = 2
kafkaQueue    | 	group.streams.min.heartbeat.interval.ms = 5000
kafkaQueue    | 	group.streams.min.session.timeout.ms = 45000
kafkaQueue    | 	group.streams.num.standby.replicas = 0
kafkaQueue    | 	group.streams.session.timeout.ms = 45000
kafkaQueue    | 	initial.broker.registration.timeout.ms = 60000
kafkaQueue    | 	inter.broker.listener.name = null
kafkaQueue    | 	internal.metadata.delete.delay.millis = 60000
kafkaQueue    | 	internal.metadata.log.segment.bytes = null
kafkaQueue    | 	internal.metadata.max.batch.size.in.bytes = 8388608
kafkaQueue    | 	internal.metadata.max.fetch.size.in.bytes = 8388608
kafkaQueue    | 	kafka.metrics.polling.interval.secs = 10
kafkaQueue    | 	kafka.metrics.reporters = []
kafkaQueue    | 	leader.imbalance.check.interval.seconds = 300
kafkaQueue    | 	listener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT
kafkaQueue    | 	listeners = PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
kafkaQueue    | 	log.cleaner.backoff.ms = 15000
kafkaQueue    | 	log.cleaner.dedupe.buffer.size = 134217728
kafkaQueue    | 	log.cleaner.delete.retention.ms = 86400000
kafkaQueue    | 	log.cleaner.enable = true
kafkaQueue    | 	log.cleaner.io.buffer.load.factor = 0.9
kafkaQueue    | 	log.cleaner.io.buffer.size = 524288
kafkaQueue    | 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafkaQueue    | 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
kafkaQueue    | 	log.cleaner.min.cleanable.ratio = 0.5
kafkaQueue    | 	log.cleaner.min.compaction.lag.ms = 0
kafkaQueue    | 	log.cleaner.threads = 1
kafkaQueue    | 	log.cleanup.policy = [delete]
kafkaQueue    | 	log.dir = /tmp/kafka-logs
kafkaQueue    | 	log.dir.failure.timeout.ms = 30000
kafkaQueue    | 	log.dirs = null
kafkaQueue    | 	log.flush.interval.messages = 9223372036854775807
kafkaQueue    | 	log.flush.interval.ms = null
kafkaQueue    | 	log.flush.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.flush.scheduler.interval.ms = 9223372036854775807
kafkaQueue    | 	log.flush.start.offset.checkpoint.interval.ms = 60000
kafkaQueue    | 	log.index.interval.bytes = 4096
kafkaQueue    | 	log.index.size.max.bytes = 10485760
kafkaQueue    | 	log.initial.task.delay.ms = 30000
kafkaQueue    | 	log.local.retention.bytes = -2
kafkaQueue    | 	log.local.retention.ms = -2
kafkaQueue    | 	log.message.timestamp.after.max.ms = 3600000
kafkaQueue    | 	log.message.timestamp.before.max.ms = 9223372036854775807
kafkaQueue    | 	log.message.timestamp.type = CreateTime
kafkaQueue    | 	log.preallocate = false
kafkaQueue    | 	log.retention.bytes = -1
kafkaQueue    | 	log.retention.check.interval.ms = 300000
kafkaQueue    | 	log.retention.hours = 168
kafkaQueue    | 	log.retention.minutes = null
kafkaQueue    | 	log.retention.ms = null
kafkaQueue    | 	log.roll.hours = 168
kafkaQueue    | 	log.roll.jitter.hours = 0
kafkaQueue    | 	log.roll.jitter.ms = null
kafkaQueue    | 	log.roll.ms = null
kafkaQueue    | 	log.segment.bytes = 1073741824
kafkaQueue    | 	log.segment.delete.delay.ms = 60000
kafkaQueue    | 	max.connection.creation.rate = 2147483647
kafkaQueue    | 	max.connections = 2147483647
kafkaQueue    | 	max.connections.per.ip = 2147483647
kafkaQueue    | 	max.connections.per.ip.overrides = 
kafkaQueue    | 	max.incremental.fetch.session.cache.slots = 1000
kafkaQueue    | 	max.request.partition.size.limit = 2000
kafkaQueue    | 	message.max.bytes = 1048588
kafkaQueue    | 	metadata.log.dir = null
kafkaQueue    | 	metadata.log.max.record.bytes.between.snapshots = 20971520
kafkaQueue    | 	metadata.log.max.snapshot.interval.ms = 3600000
kafkaQueue    | 	metadata.log.segment.bytes = 1073741824
kafkaQueue    | 	metadata.log.segment.ms = 604800000
kafkaQueue    | 	metadata.max.idle.interval.ms = 500
kafkaQueue    | 	metadata.max.retention.bytes = 104857600
kafkaQueue    | 	metadata.max.retention.ms = 604800000
kafkaQueue    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
kafkaQueue    | 	metrics.num.samples = 2
kafkaQueue    | 	metrics.recording.level = INFO
kafkaQueue    | 	metrics.sample.window.ms = 30000
kafkaQueue    | 	min.insync.replicas = 1
kafkaQueue    | 	node.id = 1
kafkaQueue    | 	num.io.threads = 8
kafkaQueue    | 	num.network.threads = 3
kafkaQueue    | 	num.partitions = 1
kafkaQueue    | 	num.recovery.threads.per.data.dir = 2
kafkaQueue    | 	num.replica.alter.log.dirs.threads = null
kafkaQueue    | 	num.replica.fetchers = 1
kafkaQueue    | 	offset.metadata.max.bytes = 4096
kafkaQueue    | 	offsets.commit.timeout.ms = 5000
kafkaQueue    | 	offsets.load.buffer.size = 5242880
kafkaQueue    | 	offsets.retention.check.interval.ms = 600000
kafkaQueue    | 	offsets.retention.minutes = 10080
kafkaQueue    | 	offsets.topic.compression.codec = 0
kafkaQueue    | 	offsets.topic.num.partitions = 50
kafkaQueue    | 	offsets.topic.replication.factor = 1
kafkaQueue    | 	offsets.topic.segment.bytes = 104857600
kafkaQueue    | 	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
kafkaQueue    | 	process.roles = [broker, controller]
kafkaQueue    | 	producer.id.expiration.check.interval.ms = 600000
kafkaQueue    | 	producer.id.expiration.ms = 86400000
kafkaQueue    | 	producer.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	queued.max.request.bytes = -1
kafkaQueue    | 	queued.max.requests = 500
kafkaQueue    | 	quota.window.num = 11
kafkaQueue    | 	quota.window.size.seconds = 1
kafkaQueue    | 	remote.fetch.max.wait.ms = 500
kafkaQueue    | 	remote.list.offsets.request.timeout.ms = 30000
kafkaQueue    | 	remote.log.index.file.cache.total.size.bytes = 1073741824
kafkaQueue    | 	remote.log.manager.copier.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.copy.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.copy.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.copy.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.expiration.thread.pool.size = 10
kafkaQueue    | 	remote.log.manager.fetch.max.bytes.per.second = 9223372036854775807
kafkaQueue    | 	remote.log.manager.fetch.quota.window.num = 11
kafkaQueue    | 	remote.log.manager.fetch.quota.window.size.seconds = 1
kafkaQueue    | 	remote.log.manager.task.interval.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.max.ms = 30000
kafkaQueue    | 	remote.log.manager.task.retry.backoff.ms = 500
kafkaQueue    | 	remote.log.manager.task.retry.jitter = 0.2
kafkaQueue    | 	remote.log.manager.thread.pool.size = 2
kafkaQueue    | 	remote.log.metadata.custom.metadata.max.bytes = 128
kafkaQueue    | 	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
kafkaQueue    | 	remote.log.metadata.manager.class.path = null
kafkaQueue    | 	remote.log.metadata.manager.impl.prefix = rlmm.config.
kafkaQueue    | 	remote.log.metadata.manager.listener.name = null
kafkaQueue    | 	remote.log.reader.max.pending.tasks = 100
kafkaQueue    | 	remote.log.reader.threads = 10
kafkaQueue    | 	remote.log.storage.manager.class.name = null
kafkaQueue    | 	remote.log.storage.manager.class.path = null
kafkaQueue    | 	remote.log.storage.manager.impl.prefix = rsm.config.
kafkaQueue    | 	remote.log.storage.system.enable = false
kafkaQueue    | 	replica.fetch.backoff.ms = 1000
kafkaQueue    | 	replica.fetch.max.bytes = 1048576
kafkaQueue    | 	replica.fetch.min.bytes = 1
kafkaQueue    | 	replica.fetch.response.max.bytes = 10485760
kafkaQueue    | 	replica.fetch.wait.max.ms = 500
kafkaQueue    | 	replica.high.watermark.checkpoint.interval.ms = 5000
kafkaQueue    | 	replica.lag.time.max.ms = 30000
kafkaQueue    | 	replica.selector.class = null
kafkaQueue    | 	replica.socket.receive.buffer.bytes = 65536
kafkaQueue    | 	replica.socket.timeout.ms = 30000
kafkaQueue    | 	replication.quota.window.num = 11
kafkaQueue    | 	replication.quota.window.size.seconds = 1
kafkaQueue    | 	request.timeout.ms = 30000
kafkaQueue    | 	sasl.client.callback.handler.class = null
kafkaQueue    | 	sasl.enabled.mechanisms = [GSSAPI]
kafkaQueue    | 	sasl.jaas.config = null
kafkaQueue    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafkaQueue    | 	sasl.kerberos.min.time.before.relogin = 60000
kafkaQueue    | 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafkaQueue    | 	sasl.kerberos.service.name = null
kafkaQueue    | 	sasl.kerberos.ticket.renew.jitter = 0.05
kafkaQueue    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
kafkaQueue    | 	sasl.login.callback.handler.class = null
kafkaQueue    | 	sasl.login.class = null
kafkaQueue    | 	sasl.login.connect.timeout.ms = null
kafkaQueue    | 	sasl.login.read.timeout.ms = null
kafkaQueue    | 	sasl.login.refresh.buffer.seconds = 300
kafkaQueue    | 	sasl.login.refresh.min.period.seconds = 60
kafkaQueue    | 	sasl.login.refresh.window.factor = 0.8
kafkaQueue    | 	sasl.login.refresh.window.jitter = 0.05
kafkaQueue    | 	sasl.login.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.login.retry.backoff.ms = 100
kafkaQueue    | 	sasl.mechanism.controller.protocol = GSSAPI
kafkaQueue    | 	sasl.mechanism.inter.broker.protocol = GSSAPI
kafkaQueue    | 	sasl.oauthbearer.assertion.algorithm = RS256
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.aud = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.iss = null
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.jti.include = false
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
kafkaQueue    | 	sasl.oauthbearer.assertion.claim.sub = null
kafkaQueue    | 	sasl.oauthbearer.assertion.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.file = null
kafkaQueue    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
kafkaQueue    | 	sasl.oauthbearer.assertion.template.file = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.id = null
kafkaQueue    | 	sasl.oauthbearer.client.credentials.client.secret = null
kafkaQueue    | 	sasl.oauthbearer.clock.skew.seconds = 30
kafkaQueue    | 	sasl.oauthbearer.expected.audience = null
kafkaQueue    | 	sasl.oauthbearer.expected.issuer = null
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
kafkaQueue    | 	sasl.oauthbearer.jwks.endpoint.url = null
kafkaQueue    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
kafkaQueue    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
kafkaQueue    | 	sasl.oauthbearer.scope = null
kafkaQueue    | 	sasl.oauthbearer.scope.claim.name = scope
kafkaQueue    | 	sasl.oauthbearer.sub.claim.name = sub
kafkaQueue    | 	sasl.oauthbearer.token.endpoint.url = null
kafkaQueue    | 	sasl.server.callback.handler.class = null
kafkaQueue    | 	sasl.server.max.receive.size = 524288
kafkaQueue    | 	security.inter.broker.protocol = PLAINTEXT
kafkaQueue    | 	security.providers = null
kafkaQueue    | 	server.max.startup.time.ms = 9223372036854775807
kafkaQueue    | 	share.coordinator.append.linger.ms = 5
kafkaQueue    | 	share.coordinator.cold.partition.snapshot.interval.ms = 300000
kafkaQueue    | 	share.coordinator.load.buffer.size = 5242880
kafkaQueue    | 	share.coordinator.snapshot.update.records.per.snapshot = 500
kafkaQueue    | 	share.coordinator.state.topic.compression.codec = 0
kafkaQueue    | 	share.coordinator.state.topic.min.isr = 2
kafkaQueue    | 	share.coordinator.state.topic.num.partitions = 50
kafkaQueue    | 	share.coordinator.state.topic.prune.interval.ms = 300000
kafkaQueue    | 	share.coordinator.state.topic.replication.factor = 3
kafkaQueue    | 	share.coordinator.state.topic.segment.bytes = 104857600
kafkaQueue    | 	share.coordinator.threads = 1
kafkaQueue    | 	share.coordinator.write.timeout.ms = 5000
kafkaQueue    | 	share.fetch.purgatory.purge.interval.requests = 1000
kafkaQueue    | 	socket.connection.setup.timeout.max.ms = 30000
kafkaQueue    | 	socket.connection.setup.timeout.ms = 10000
kafkaQueue    | 	socket.listen.backlog.size = 50
kafkaQueue    | 	socket.receive.buffer.bytes = 102400
kafkaQueue    | 	socket.request.max.bytes = 104857600
kafkaQueue    | 	socket.send.buffer.bytes = 102400
kafkaQueue    | 	ssl.allow.dn.changes = false
kafkaQueue    | 	ssl.allow.san.changes = false
kafkaQueue    | 	ssl.cipher.suites = []
kafkaQueue    | 	ssl.client.auth = none
kafkaQueue    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
kafkaQueue    | 	ssl.endpoint.identification.algorithm = https
kafkaQueue    | 	ssl.engine.factory.class = null
kafkaQueue    | 	ssl.key.password = null
kafkaQueue    | 	ssl.keymanager.algorithm = SunX509
kafkaQueue    | 	ssl.keystore.certificate.chain = null
kafkaQueue    | 	ssl.keystore.key = null
kafkaQueue    | 	ssl.keystore.location = null
kafkaQueue    | 	ssl.keystore.password = null
kafkaQueue    | 	ssl.keystore.type = JKS
kafkaQueue    | 	ssl.principal.mapping.rules = DEFAULT
kafkaQueue    | 	ssl.protocol = TLSv1.3
kafkaQueue    | 	ssl.provider = null
kafkaQueue    | 	ssl.secure.random.implementation = null
kafkaQueue    | 	ssl.trustmanager.algorithm = PKIX
kafkaQueue    | 	ssl.truststore.certificates = null
kafkaQueue    | 	ssl.truststore.location = null
kafkaQueue    | 	ssl.truststore.password = null
kafkaQueue    | 	ssl.truststore.type = JKS
kafkaQueue    | 	telemetry.max.bytes = 1048576
kafkaQueue    | 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
kafkaQueue    | 	transaction.max.timeout.ms = 900000
kafkaQueue    | 	transaction.partition.verification.enable = true
kafkaQueue    | 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
kafkaQueue    | 	transaction.state.log.load.buffer.size = 5242880
kafkaQueue    | 	transaction.state.log.min.isr = 1
kafkaQueue    | 	transaction.state.log.num.partitions = 50
kafkaQueue    | 	transaction.state.log.replication.factor = 1
kafkaQueue    | 	transaction.state.log.segment.bytes = 104857600
kafkaQueue    | 	transaction.two.phase.commit.enable = false
kafkaQueue    | 	transactional.id.expiration.ms = 604800000
kafkaQueue    | 	unclean.leader.election.enable = false
kafkaQueue    | 	unclean.leader.election.interval.ms = 300000
kafkaQueue    | 	unstable.api.versions.enable = false
kafkaQueue    | 	unstable.feature.versions.enable = false
kafkaQueue    |  (org.apache.kafka.common.config.AbstractConfig)
kafkaQueue    | [2025-12-08 14:40:59,765] INFO [BrokerServer id=1] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,797] INFO [BrokerLifecycleManager id=1] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
kafkaQueue    | [2025-12-08 14:40:59,798] INFO [BrokerServer id=1] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,799] INFO authorizerStart completed for endpoint PLAINTEXT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
kafkaQueue    | [2025-12-08 14:40:59,799] INFO [SocketServer listenerType=BROKER, nodeId=1] Enabling request processing. (kafka.network.SocketServer)
kafkaQueue    | [2025-12-08 14:40:59,800] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
kafkaQueue    | [2025-12-08 14:40:59,800] INFO [BrokerServer id=1] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,801] INFO [BrokerServer id=1] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,801] INFO [BrokerServer id=1] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,801] INFO [BrokerServer id=1] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,801] INFO [BrokerServer id=1] Transition from STARTING to STARTED (kafka.server.BrokerServer)
kafkaQueue    | [2025-12-08 14:40:59,802] INFO Kafka version: 4.1.1 (org.apache.kafka.common.utils.AppInfoParser)
kafkaQueue    | [2025-12-08 14:40:59,802] INFO Kafka commitId: be816b82d25370ce (org.apache.kafka.common.utils.AppInfoParser)
kafkaQueue    | [2025-12-08 14:40:59,802] INFO Kafka startTimeMs: 1765204859801 (org.apache.kafka.common.utils.AppInfoParser)
kafkaQueue    | [2025-12-08 14:40:59,803] INFO [KafkaRaftServer nodeId=1] Kafka Server started (kafka.server.KafkaRaftServer)
configserver  | 2025-12-08T14:40:59.975Z  INFO 1 --- [ConfigServer] [nio-8888-exec-4] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-4219905010480086910/AuthService.properties]' via location 'file:/tmp/config-repo-4219905010480086910/'
sql_db        | 2025-12-08 14:41:00.01 Server      Installing Client TLS certificates to the store.
sql_db        | 2025-12-08 14:41:00.02 Server      CPU vectorization level(s) detected:  SSE SSE2 SSE3 SSSE3 SSE41 SSE42 AVX AVX2 POPCNT BMI1 BMI2
sql_db        | 2025-12-08 14:41:00.08 Server      Successfully initialized the TLS configuration. Allowed TLS protocol versions are ['1.0 1.1 1.2']. Allowed TLS ciphers are ['ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-ECDSA-AES128-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:!DHE-RSA-AES256-GCM-SHA384:!DHE-RSA-AES128-GCM-SHA256:!DHE-RSA-AES256-SHA:!DHE-RSA-AES128-SHA'].
sql_db        | 2025-12-08 14:41:00.11 Server      Query Store settings initialized with enabled = 1, 
sql_db        | 2025-12-08 14:41:00.12 Server      The maximum number of dedicated administrator connections for this instance is '1'
sql_db        | 2025-12-08 14:41:00.13 Server      Node configuration: node 0: CPU mask: 0x000000000000ffff:0 Active CPU mask: 0x000000000000ffff:0. This message provides a description of the NUMA configuration for this computer. This is an informational message only. No user action is required.
sql_db        | 2025-12-08 14:41:00.17 Server      Using dynamic lock allocation.  Initial allocation of 2500 Lock blocks and 5000 Lock Owner blocks per node.  This is an informational message only.  No user action is required.
sql_db        | 2025-12-08 14:41:00.17 Server      Lock partitioning is enabled.  This is an informational message only. No user action is required.
sql_db        | 2025-12-08 14:41:00.21 Server      In-Memory OLTP initialized on lowend machine.
sql_db        | 2025-12-08 14:41:00.24 Server      [INFO] Created Extended Events session 'hkenginexesession'
authservice   | 
authservice   |   .   ____          _            __ _ _
authservice   |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
authservice   | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
authservice   |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
authservice   |   '  |____| .__|_| |_|_| |_\__, | / / / /
authservice   |  =========|_|==============|___/=/_/_/_/
authservice   | 
sql_db        | 2025-12-08 14:41:00.24 Server      Database Instant File Initialization: enabled. For security and performance considerations see the topic 'Database Instant File Initialization' in SQL Server Books Online. This is an informational message only. No user action is required.
authservice   |  :: Spring Boot ::                (v4.0.0)
authservice   | 
sql_db        | ForceFlush is enabled for this instance. 
sql_db        | 2025-12-08 14:41:00.25 Server      Total Log Writer threads: 2. This is an informational message; no user action is required.
sql_db        | 2025-12-08 14:41:00.26 Server      CLR version v4.0.30319 loaded.
sql_db        | 2025-12-08 14:41:00.26 Server      clwb is selected for pmem flush operation.
sql_db        | 2025-12-08 14:41:00.27 Server      Software Usage Metrics is disabled.
sql_db        | 2025-12-08 14:41:00.28 spid44s     [1]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 14:41:00.29 spid44s     Starting up database 'master'.
sql_db        | ForceFlush feature is enabled for log durability.
sql_db        | 2025-12-08 14:41:00.34 spid44s     25 transactions rolled forward in database 'master' (1:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 14:41:00.35 spid44s     0 transactions rolled back in database 'master' (1:0). This is an informational message only. No user action is required.
sql_db        | 2025-12-08 14:41:00.35 spid44s     Recovery is writing a checkpoint in database 'master' (1). This is an informational message only. No user action is required.
authservice   | 2025-12-08T14:41:00.390Z  INFO 1 --- [AuthService] [           main] o.e.authservice.AuthServiceApplication   : Starting AuthServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/AuthService-0.0.1-SNAPSHOT.jar started by root in /app)
authservice   | 2025-12-08T14:41:00.395Z  INFO 1 --- [AuthService] [           main] o.e.authservice.AuthServiceApplication   : No active profile set, falling back to 1 default profile: "default"
sql_db        | 2025-12-08 14:41:00.44 spid44s     [32762]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 14:41:00.45 spid46s     [32767]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 14:41:00.45 spid44s     Starting up database 'model_replicatedmaster'.
sql_db        | 2025-12-08 14:41:00.45 spid46s     Starting up database 'mssqlsystemresource'.
sql_db        | 2025-12-08 14:41:00.46 spid46s     The resource database build version is 16.00.4215. This is an informational message only. No user action is required.
authservice   | 2025-12-08T14:41:00.474Z  INFO 1 --- [AuthService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
authservice   | 2025-12-08T14:41:00.474Z  INFO 1 --- [AuthService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=AuthService, profiles=[default], label=null, version=87cb91717b3f85aeb151ff96b7043491fdd99f6d, state=
sql_db        | 2025-12-08 14:41:00.49 spid46s     [3]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 14:41:00.49 spid46s     Starting up database 'model'.
sql_db        | 2025-12-08 14:41:00.50 spid44s     Converting database 'model_replicatedmaster' from version 927 to the current version 957.
sql_db        | 2025-12-08 14:41:00.50 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 927 to version 928.
sql_db        | 2025-12-08 14:41:00.51 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 928 to version 929.
sql_db        | 2025-12-08 14:41:00.55 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 929 to version 930.
sql_db        | 2025-12-08 14:41:00.56 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 930 to version 931.
sql_db        | 2025-12-08 14:41:00.57 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 931 to version 932.
sql_db        | 2025-12-08 14:41:00.58 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 932 to version 933.
sql_db        | 2025-12-08 14:41:00.59 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 933 to version 934.
sql_db        | 2025-12-08 14:41:00.59 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 934 to version 935.
sql_db        | 2025-12-08 14:41:00.60 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 935 to version 936.
sql_db        | 2025-12-08 14:41:00.61 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 936 to version 937.
sql_db        | 2025-12-08 14:41:00.62 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 937 to version 938.
sql_db        | 2025-12-08 14:41:00.62 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 938 to version 939.
sql_db        | 2025-12-08 14:41:00.63 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 939 to version 940.
sql_db        | 2025-12-08 14:41:00.64 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 940 to version 941.
sql_db        | 2025-12-08 14:41:00.65 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 941 to version 942.
sql_db        | 2025-12-08 14:41:00.65 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 942 to version 943.
sql_db        | 2025-12-08 14:41:00.66 Server      Common language runtime (CLR) functionality initialized.
sql_db        | 2025-12-08 14:41:00.68 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 943 to version 944.
sql_db        | 2025-12-08 14:41:00.68 Server      External governance manager initialized
sql_db        | 2025-12-08 14:41:00.69 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 944 to version 945.
sql_db        | 2025-12-08 14:41:00.70 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 945 to version 946.
sql_db        | 2025-12-08 14:41:00.71 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 946 to version 947.
sql_db        | 2025-12-08 14:41:00.72 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 947 to version 948.
sql_db        | 2025-12-08 14:41:00.73 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 948 to version 949.
sql_db        | 2025-12-08 14:41:00.74 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 949 to version 950.
sql_db        | 2025-12-08 14:41:00.74 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 950 to version 951.
sql_db        | 2025-12-08 14:41:00.76 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 951 to version 952.
sql_db        | 2025-12-08 14:41:00.77 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 952 to version 953.
sql_db        | 2025-12-08 14:41:00.78 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 953 to version 954.
sql_db        | 2025-12-08 14:41:00.79 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 954 to version 955.
sql_db        | 2025-12-08 14:41:00.80 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 955 to version 956.
sql_db        | 2025-12-08 14:41:00.82 spid44s     Database 'model_replicatedmaster' running the upgrade step from version 956 to version 957.
sql_db        | 2025-12-08 14:41:00.86 spid44s     [32761]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db        | 2025-12-08 14:41:00.86 spid44s     Starting up database 'model_msdb'.
sql_db        | 2025-12-08 14:41:00.89 spid44s     Converting database 'model_msdb' from version 927 to the current version 957.
sql_db        | 2025-12-08 14:41:00.89 spid44s     Database 'model_msdb' running the upgrade step from version 927 to version 928.
sql_db        | 2025-12-08 14:41:00.90 spid44s     Database 'model_msdb' running the upgrade step from version 928 to version 929.
sql_db        | 2025-12-08 14:41:00.92 spid44s     Database 'model_msdb' running the upgrade step from version 929 to version 930.
configserver  | 2025-12-08T14:41:00.937Z  INFO 1 --- [ConfigServer] [nio-8888-exec-6] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-4219905010480086910/FlightService.properties]' via location 'file:/tmp/config-repo-4219905010480086910/'
sql_db        | 2025-12-08 14:41:00.93 spid44s     Database 'model_msdb' running the upgrade step from version 930 to version 931.
sql_db        | 2025-12-08 14:41:00.95 spid44s     Database 'model_msdb' running the upgrade step from version 931 to version 932.
sql_db        | 2025-12-08 14:41:00.96 spid44s     Database 'model_msdb' running the upgrade step from version 932 to version 933.
sql_db        | 2025-12-08 14:41:00.97 spid44s     Database 'model_msdb' running the upgrade step from version 933 to version 934.
sql_db        | 2025-12-08 14:41:00.98 spid44s     Database 'model_msdb' running the upgrade step from version 934 to version 935.
sql_db        | 2025-12-08 14:41:00.98 spid44s     Database 'model_msdb' running the upgrade step from version 935 to version 936.
sql_db        | 2025-12-08 14:41:01.00 spid44s     Database 'model_msdb' running the upgrade step from version 936 to version 937.
sql_db        | 2025-12-08 14:41:01.00 spid44s     Database 'model_msdb' running the upgrade step from version 937 to version 938.
sql_db        | 2025-12-08 14:41:01.01 spid44s     Database 'model_msdb' running the upgrade step from version 938 to version 939.
sql_db        | 2025-12-08 14:41:01.02 spid44s     Database 'model_msdb' running the upgrade step from version 939 to version 940.
sql_db        | 2025-12-08 14:41:01.03 spid44s     Database 'model_msdb' running the upgrade step from version 940 to version 941.
sql_db        | 2025-12-08 14:41:01.03 spid44s     Database 'model_msdb' running the upgrade step from version 941 to version 942.
sql_db        | 2025-12-08 14:41:01.04 spid44s     Database 'model_msdb' running the upgrade step from version 942 to version 943.
sql_db        | 2025-12-08 14:41:01.07 spid44s     Database 'model_msdb' running the upgrade step from version 943 to version 944.
sql_db        | 2025-12-08 14:41:01.08 spid44s     Database 'model_msdb' running the upgrade step from version 944 to version 945.
sql_db        | 2025-12-08 14:41:01.10 spid44s     Database 'model_msdb' running the upgrade step from version 945 to version 946.
sql_db        | 2025-12-08 14:41:01.11 spid44s     Database 'model_msdb' running the upgrade step from version 946 to version 947.
sql_db        | 2025-12-08 14:41:01.11 spid44s     Database 'model_msdb' running the upgrade step from version 947 to version 948.
sql_db        | 2025-12-08 14:41:01.12 spid44s     Database 'model_msdb' running the upgrade step from version 948 to version 949.
sql_db        | 2025-12-08 14:41:01.13 spid44s     Database 'model_msdb' running the upgrade step from version 949 to version 950.
sql_db        | 2025-12-08 14:41:01.14 spid44s     Database 'model_msdb' running the upgrade step from version 950 to version 951.
sql_db        | 2025-12-08 14:41:01.16 spid44s     Database 'model_msdb' running the upgrade step from version 951 to version 952.
sql_db        | 2025-12-08 14:41:01.16 spid44s     Database 'model_msdb' running the upgrade step from version 952 to version 953.
sql_db        | 2025-12-08 14:41:01.17 spid44s     Database 'model_msdb' running the upgrade step from version 953 to version 954.
sql_db        | 2025-12-08 14:41:01.18 spid44s     Database 'model_msdb' running the upgrade step from version 954 to version 955.
sql_db        | 2025-12-08 14:41:01.19 spid44s     Database 'model_msdb' running the upgrade step from version 955 to version 956.
sql_db        | 2025-12-08 14:41:01.22 spid44s     Database 'model_msdb' running the upgrade step from version 956 to version 957.
flightservice  | 
flightservice  |   .   ____          _            __ _ _
flightservice  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
flightservice  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
flightservice  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
flightservice  |   '  |____| .__|_| |_|_| |_\__, | / / / /
flightservice  |  =========|_|==============|___/=/_/_/_/
flightservice  | 
flightservice  |  :: Spring Boot ::                (v4.0.0)
flightservice  | 
sql_db         | 2025-12-08 14:41:01.27 spid44s     Resource governor reconfiguration succeeded.
sql_db         | 2025-12-08 14:41:01.27 spid55s     Attribute synchronization initialized
sql_db         | 2025-12-08 14:41:01.27 spid44s     SQL Server Audit is starting the audits. This is an informational message. No user action is required.
sql_db         | 2025-12-08 14:41:01.27 spid55s     Attribute synchronization manager initialized
sql_db         | 2025-12-08 14:41:01.27 spid44s     SQL Server Audit has started the audits. This is an informational message. No user action is required.
sql_db         | 2025-12-08 14:41:01.31 spid44s     SQL Trace ID 1 was started by login "sa".
sql_db         | 2025-12-08 14:41:01.32 spid44s     Server name is '5d03cb505ff1'. This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.34 spid46s     Clearing tempdb database.
sql_db         | 2025-12-08 14:41:01.34 spid62s     Always On: The availability replica manager is starting. This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.34 spid68s     [6]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db         | 2025-12-08 14:41:01.34 spid65s     [4]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db         | 2025-12-08 14:41:01.34 spid67s     [5]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db         | 2025-12-08 14:41:01.34 spid66s     [7]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db         | 2025-12-08 14:41:01.34 spid69s     [8]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db         | 2025-12-08 14:41:01.34 spid62s     Always On: The availability replica manager is waiting for the instance of SQL Server to allow client connections. This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.35 spid68s     Starting up database 'springtest'.
sql_db         | 2025-12-08 14:41:01.35 spid65s     Starting up database 'msdb'.
sql_db         | 2025-12-08 14:41:01.35 spid67s     Starting up database 'FlightBooking'.
sql_db         | 2025-12-08 14:41:01.35 spid66s     Starting up database 'TicketDB'.
sql_db         | 2025-12-08 14:41:01.35 spid69s     Starting up database 'UserDB'.
sql_db         | 2025-12-08 14:41:01.36 spid68s     RemoveStaleDbEntries: Cleanup of stale DB entries called for database ID: [6]
sql_db         | 2025-12-08 14:41:01.36 spid67s     RemoveStaleDbEntries: Cleanup of stale DB entries called for database ID: [5]
sql_db         | 2025-12-08 14:41:01.36 spid66s     RemoveStaleDbEntries: Cleanup of stale DB entries called for database ID: [7]
sql_db         | 2025-12-08 14:41:01.36 spid69s     RemoveStaleDbEntries: Cleanup of stale DB entries called for database ID: [8]
sql_db         | 2025-12-08 14:41:01.36 spid68s     RemoveStaleDbEntries: Cleanup of stale DB entries skipped because master db is not memory optimized. DbId: 6.
sql_db         | 2025-12-08 14:41:01.36 spid67s     RemoveStaleDbEntries: Cleanup of stale DB entries skipped because master db is not memory optimized. DbId: 5.
sql_db         | 2025-12-08 14:41:01.36 spid66s     RemoveStaleDbEntries: Cleanup of stale DB entries skipped because master db is not memory optimized. DbId: 7.
sql_db         | 2025-12-08 14:41:01.37 spid69s     RemoveStaleDbEntries: Cleanup of stale DB entries skipped because master db is not memory optimized. DbId: 8.
flightservice  | 2025-12-08T14:41:01.379Z  INFO 1 --- [FlightService] [           main] o.e.f.FlightServiceApplication           : Starting FlightServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/FlightService-0.0.1-SNAPSHOT.jar started by root in /app)
flightservice  | 2025-12-08T14:41:01.387Z  INFO 1 --- [FlightService] [           main] o.e.f.FlightServiceApplication           : No active profile set, falling back to 1 default profile: "default"
sql_db         | 2025-12-08 14:41:01.40 spid68s     Parallel redo is started for database 'springtest' with worker pool size [8].
sql_db         | 2025-12-08 14:41:01.40 spid66s     Parallel redo is started for database 'TicketDB' with worker pool size [8].
sql_db         | 2025-12-08 14:41:01.41 spid67s     Parallel redo is started for database 'FlightBooking' with worker pool size [8].
sql_db         | 2025-12-08 14:41:01.41 spid69s     Parallel redo is started for database 'UserDB' with worker pool size [8].
authservice    | 2025-12-08T14:41:01.445Z  INFO 1 --- [AuthService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
sql_db         | 2025-12-08 14:41:01.45 spid66s     112 transactions rolled forward in database 'TicketDB' (7:0). This is an informational message only. No user action is required.
flightservice  | 2025-12-08T14:41:01.465Z  INFO 1 --- [FlightService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
flightservice  | 2025-12-08T14:41:01.465Z  INFO 1 --- [FlightService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=FlightService, profiles=[default], label=null, version=87cb91717b3f85aeb151ff96b7043491fdd99f6d, state=
sql_db         | 2025-12-08 14:41:01.46 spid46s     [2]. Feature Status: PVS: 0. CTR: 0. ConcurrentPFSUpdate: 1. ConcurrentGAMUpdate: 1. ConcurrentSGAMUpdate: 1, CleanupUnderUserTransaction: 0. TranLevelPVS: 0
sql_db         | 2025-12-08 14:41:01.46 spid46s     Starting up database 'tempdb'.
sql_db         | 2025-12-08 14:41:01.46 spid68s     96 transactions rolled forward in database 'springtest' (6:0). This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.47 spid69s     11 transactions rolled forward in database 'UserDB' (8:0). This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.49 spid68s     0 transactions rolled back in database 'springtest' (6:0). This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.49 spid68s     Parallel redo is shutdown for database 'springtest' with worker pool size [8].
sql_db         | 2025-12-08 14:41:01.49 spid68s     0 transactions rolled back in database 'UserDB' (8:0). This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.49 spid69s     0 transactions rolled back in database 'TicketDB' (7:0). This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.49 spid68s     Parallel redo is shutdown for database 'UserDB' with worker pool size [8].
sql_db         | 2025-12-08 14:41:01.49 spid69s     Parallel redo is shutdown for database 'TicketDB' with worker pool size [8].
sql_db         | 2025-12-08 14:41:01.58 spid67s     Recovery of database 'FlightBooking' (5) is 0% complete (approximately 36 seconds remain). Phase 2 of 3. This is an informational message only. No user action is required.
authservice    | 2025-12-08T14:41:01.659Z  INFO 1 --- [AuthService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 197 ms. Found 2 JPA repository interfaces.
configserver   | 2025-12-08T14:41:01.725Z  INFO 1 --- [ConfigServer] [nio-8888-exec-5] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-4219905010480086910/BookingService.properties]' via location 'file:/tmp/config-repo-4219905010480086910/'
sql_db         | 2025-12-08 14:41:01.72 spid67s     96 transactions rolled forward in database 'FlightBooking' (5:0). This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.74 spid46s     The tempdb database has 8 data file(s).
sql_db         | 2025-12-08 14:41:01.75 spid65s     The Service Broker endpoint is in disabled or stopped state.
sql_db         | 2025-12-08 14:41:01.75 spid65s     The Database Mirroring endpoint is in disabled or stopped state.
sql_db         | 2025-12-08 14:41:01.76 spid65s     Service Broker manager has started.
sql_db         | 2025-12-08 14:41:01.77 spid67s     0 transactions rolled back in database 'FlightBooking' (5:0). This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.78 spid67s     Parallel redo is shutdown for database 'FlightBooking' with worker pool size [8].
sql_db         | 2025-12-08 14:41:01.80 spid53s     A self-generated certificate was successfully loaded for encryption.
sql_db         | 2025-12-08 14:41:01.80 spid53s     Server is listening on [ 'any' <ipv6> 1433] accept sockets 1.
sql_db         | 2025-12-08 14:41:01.80 spid53s     Server is listening on [ 'any' <ipv4> 1433] accept sockets 1.
sql_db         | 2025-12-08 14:41:01.81 Server      Server is listening on [ ::1 <ipv6> 1434] accept sockets 1.
sql_db         | 2025-12-08 14:41:01.81 Server      Server is listening on [ 127.0.0.1 <ipv4> 1434] accept sockets 1.
sql_db         | 2025-12-08 14:41:01.82 Server      Dedicated admin connection support was established for listening locally on port 1434.
sql_db         | 2025-12-08 14:41:01.82 spid53s     Server is listening on [ ::1 <ipv6> 1431] accept sockets 1.
sql_db         | 2025-12-08 14:41:01.82 spid53s     Server is listening on [ 127.0.0.1 <ipv4> 1431] accept sockets 1.
sql_db         | 2025-12-08 14:41:01.82 spid53s     Recovery is complete. This is an informational message only. No user action is required.
sql_db         | 2025-12-08 14:41:01.82 spid53s     SQL Server is now ready for client connections. This is an informational message; no user action is required.
bookingservice  | 
bookingservice  |   .   ____          _            __ _ _
bookingservice  |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
bookingservice  | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
bookingservice  |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
bookingservice  |   '  |____| .__|_| |_|_| |_\__, | / / / /
bookingservice  |  =========|_|==============|___/=/_/_/_/
bookingservice  | 
bookingservice  |  :: Spring Boot ::                (v4.0.0)
bookingservice  | 
authservice     | 2025-12-08T14:41:02.163Z  INFO 1 --- [AuthService] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=faa00cb5-5d72-3e77-9798-bd8143851520
bookingservice  | 2025-12-08T14:41:02.175Z  INFO 1 --- [BookingService] [           main] o.e.b.BookingServiceApplication          : Starting BookingServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/BookingService-0.0.1-SNAPSHOT.jar started by root in /app)
bookingservice  | 2025-12-08T14:41:02.196Z  INFO 1 --- [BookingService] [           main] o.e.b.BookingServiceApplication          : No active profile set, falling back to 1 default profile: "default"
bookingservice  | 2025-12-08T14:41:02.314Z  INFO 1 --- [BookingService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
bookingservice  | 2025-12-08T14:41:02.314Z  INFO 1 --- [BookingService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=BookingService, profiles=[default], label=null, version=87cb91717b3f85aeb151ff96b7043491fdd99f6d, state=
configserver    | 2025-12-08T14:41:02.532Z  INFO 1 --- [ConfigServer] [nio-8888-exec-8] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-4219905010480086910/ApiGateway.properties]' via location 'file:/tmp/config-repo-4219905010480086910/'
apigateway      | 
apigateway      |   .   ____          _            __ _ _
apigateway      |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
apigateway      | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
apigateway      |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
apigateway      |   '  |____| .__|_| |_|_| |_\__, | / / / /
apigateway      |  =========|_|==============|___/=/_/_/_/
apigateway      | 
apigateway      |  :: Spring Boot ::                (v3.4.0)
apigateway      | 
authservice     | 2025-12-08T14:41:02.812Z  INFO 1 --- [AuthService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 9091 (http)
authservice     | 2025-12-08T14:41:02.832Z  INFO 1 --- [AuthService] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
authservice     | 2025-12-08T14:41:02.832Z  INFO 1 --- [AuthService] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
authservice     | 2025-12-08T14:41:02.867Z  INFO 1 --- [AuthService] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 2388 ms
apigateway      | 2025-12-08T14:41:02.960Z  INFO 1 --- [ApiGateway] [           main] o.e.apigateway.ApiGatewayApplication     : Starting ApiGatewayApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/ApiGateway-0.0.1-SNAPSHOT.jar started by root in /app)
apigateway      | 2025-12-08T14:41:02.964Z  INFO 1 --- [ApiGateway] [           main] o.e.apigateway.ApiGatewayApplication     : No active profile set, falling back to 1 default profile: "default"
apigateway      | 2025-12-08T14:41:03.084Z  INFO 1 --- [ApiGateway] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
apigateway      | 2025-12-08T14:41:03.084Z  INFO 1 --- [ApiGateway] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=ApiGateway, profiles=[default], label=null, version=87cb91717b3f85aeb151ff96b7043491fdd99f6d, state=
flightservice   | 2025-12-08T14:41:03.110Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
flightservice   | 2025-12-08T14:41:03.113Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
authservice     | 2025-12-08T14:41:03.150Z  INFO 1 --- [AuthService] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
authservice     | 2025-12-08T14:41:03.247Z  INFO 1 --- [AuthService] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 7.1.8.Final
configserver    | 2025-12-08T14:41:03.404Z  INFO 1 --- [ConfigServer] [nio-8888-exec-7] o.s.c.c.s.e.NativeEnvironmentRepository  : Adding property source: Config resource 'file [/tmp/config-repo-4219905010480086910/EmailService.properties]' via location 'file:/tmp/config-repo-4219905010480086910/'
flightservice   | 2025-12-08T14:41:03.647Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 512 ms. Found 5 JPA repository interfaces.
flightservice   | 2025-12-08T14:41:03.687Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
flightservice   | 2025-12-08T14:41:03.690Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
flightservice   | 2025-12-08T14:41:03.722Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.AirLineRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T14:41:03.722Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.BookedSeatsRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T14:41:03.722Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.CityRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T14:41:03.723Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.FlightRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T14:41:03.723Z  INFO 1 --- [FlightService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.flightservice.repository.ScheduleRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
flightservice   | 2025-12-08T14:41:03.723Z  INFO 1 --- [FlightService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 6 ms. Found 0 Redis repository interfaces.
emailservice    | 
emailservice    |   .   ____          _            __ _ _
emailservice    |  /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \
emailservice    | ( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \
emailservice    |  \\/  ___)| |_)| | | | | || (_| |  ) ) ) )
emailservice    |   '  |____| .__|_| |_|_| |_\__, | / / / /
emailservice    |  =========|_|==============|___/=/_/_/_/
emailservice    | 
emailservice    |  :: Spring Boot ::                (v4.0.0)
emailservice    | 
emailservice    | 2025-12-08T14:41:03.965Z  INFO 1 --- [EmailService] [           main] o.e.e.EmailServiceApplication            : Starting EmailServiceApplication v0.0.1-SNAPSHOT using Java 21.0.9 with PID 1 (/app/EmailService-0.0.1-SNAPSHOT.jar started by root in /app)
emailservice    | 2025-12-08T14:41:03.970Z  INFO 1 --- [EmailService] [           main] o.e.e.EmailServiceApplication            : No active profile set, falling back to 1 default profile: "default"
emailservice    | 2025-12-08T14:41:04.043Z  INFO 1 --- [EmailService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Fetching config from server at : http://configserver:8888
emailservice    | 2025-12-08T14:41:04.043Z  INFO 1 --- [EmailService] [           main] o.s.c.c.c.ConfigServerConfigDataLoader   : Located environment: name=EmailService, profiles=[default], label=null, version=87cb91717b3f85aeb151ff96b7043491fdd99f6d, state=
bookingservice  | 2025-12-08T14:41:04.050Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
bookingservice  | 2025-12-08T14:41:04.055Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data JPA repositories in DEFAULT mode.
authservice     | 2025-12-08T14:41:04.155Z  INFO 1 --- [AuthService] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
authservice     | 2025-12-08T14:41:04.215Z  INFO 1 --- [AuthService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
bookingservice  | 2025-12-08T14:41:04.359Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 286 ms. Found 3 JPA repository interfaces.
flightservice   | 2025-12-08T14:41:04.409Z  INFO 1 --- [FlightService] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=0a6497e2-90da-31d3-a8d7-36470356a157
bookingservice  | 2025-12-08T14:41:04.422Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode
bookingservice  | 2025-12-08T14:41:04.424Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
bookingservice  | 2025-12-08T14:41:04.453Z  INFO 1 --- [BookingService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.bookingservice.repository.PassengerRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
bookingservice  | 2025-12-08T14:41:04.453Z  INFO 1 --- [BookingService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.bookingservice.repository.TicketRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
bookingservice  | 2025-12-08T14:41:04.454Z  INFO 1 --- [BookingService] [           main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface org.example.bookingservice.repository.UsersRepository; If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository
bookingservice  | 2025-12-08T14:41:04.454Z  INFO 1 --- [BookingService] [           main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 7 ms. Found 0 Redis repository interfaces.
authservice     | 2025-12-08T14:41:04.729Z  INFO 1 --- [AuthService] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection ConnectionID:1 ClientConnectionId: 00becf5d-b3ae-47eb-9599-b7c0b05bc208
authservice     | 2025-12-08T14:41:04.732Z  INFO 1 --- [AuthService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
apigateway      | 2025-12-08T14:41:04.754Z  INFO 1 --- [ApiGateway] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=f06187ee-b48a-3178-9607-c0316c1fe5a5
authservice     | 2025-12-08T14:41:04.843Z  WARN 1 --- [AuthService] [           main] org.hibernate.orm.deprecation            : HHH90000025: SQLServerDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
authservice     | 2025-12-08T14:41:04.872Z  INFO 1 --- [AuthService] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
authservice     | 	Database JDBC URL [jdbc:sqlserver://sql_db:1433;concatNullYieldsNull=ON;quotedIdentifier=ON;connectRetryInterval=10;connectRetryCount=1;maxResultBuffer=-1;sendTemporalDataTypesAsStringForBulkCopy=true;delayLoadingLobs=true;useFmtOnly=false;vectorTypeSupport=v1;cacheBulkCopyMetadata=false;bulkCopyForBatchInsertAllowEncryptedValueModifications=false;bulkCopyForBatchInsertTableLock=false;bulkCopyForBatchInsertKeepNulls=false;bulkCopyForBatchInsertKeepIdentity=false;bulkCopyForBatchInsertFireTriggers=false;bulkCopyForBatchInsertCheckConstraints=false;bulkCopyForBatchInsertBatchSize=0;useBulkCopyForBatchInsert=false;cancelQueryTimeout=-1;sslProtocol=TLS;calcBigDecimalPrecision=false;useDefaultJaasConfig=false;jaasConfigurationName=SQLJDBCDriver;statementPoolingCacheSize=0;serverPreparedStatementDiscardThreshold=10;enablePrepareOnFirstPreparedStatementCall=false;fips=false;socketTimeout=0;authentication=NotSpecified;authenticationScheme=nativeAuthentication;xopenStates=false;datetimeParameterType=datetime2;sendTimeAsDatetime=true;replication=false;trustStoreType=JKS;trustServerCertificate=true;TransparentNetworkIPResolution=true;iPAddressPreference=IPv4First;serverNameAsACE=false;sendStringParametersAsUnicode=true;selectMethod=direct;responseBuffering=adaptive;queryTimeout=-1;packetSize=8000;multiSubnetFailover=false;loginTimeout=30;lockTimeout=-1;lastUpdateCount=true;useDefaultGSSCredential=false;prepareMethod=prepexec;encrypt=true;disableStatementPooling=true;databaseName=UserDB;columnEncryptionSetting=Disabled;applicationName=Microsoft JDBC Driver for SQL Server;applicationIntent=readwrite;]
authservice     | 	Database driver: Microsoft JDBC Driver 13.2 for SQL Server
authservice     | 	Database dialect: SQLServerDialect
authservice     | 	Database version: 16.0
authservice     | 	Default catalog/schema: UserDB/dbo
authservice     | 	Autocommit mode: undefined/unknown
authservice     | 	Isolation level: READ_COMMITTED [default READ_COMMITTED]
authservice     | 	JDBC fetch size: 128
authservice     | 	Pool: DatasourceConnectionProviderImpl
authservice     | 	Minimum pool size: undefined/unknown
authservice     | 	Maximum pool size: undefined/unknown
bookingservice  | 2025-12-08T14:41:05.290Z  INFO 1 --- [BookingService] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=8922e5d5-be11-3bd2-8ac6-6f5dc10dcc0d
emailservice    | 2025-12-08T14:41:05.518Z  INFO 1 --- [EmailService] [           main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=53d4c282-6f6e-32c3-8e94-119279e67d6a
flightservice   | 2025-12-08T14:41:06.021Z  INFO 1 --- [FlightService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8080 (http)
flightservice   | 2025-12-08T14:41:06.052Z  INFO 1 --- [FlightService] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
flightservice   | 2025-12-08T14:41:06.053Z  INFO 1 --- [FlightService] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
flightservice   | 2025-12-08T14:41:06.105Z  INFO 1 --- [FlightService] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 4635 ms
emailservice    | 2025-12-08T14:41:06.142Z  INFO 1 --- [EmailService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8082 (http)
emailservice    | 2025-12-08T14:41:06.175Z  INFO 1 --- [EmailService] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
emailservice    | 2025-12-08T14:41:06.176Z  INFO 1 --- [EmailService] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
emailservice    | 2025-12-08T14:41:06.240Z  INFO 1 --- [EmailService] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 2189 ms
apigateway      | 2025-12-08T14:41:06.655Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [After]
apigateway      | 2025-12-08T14:41:06.655Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Before]
apigateway      | 2025-12-08T14:41:06.656Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Between]
apigateway      | 2025-12-08T14:41:06.656Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Cookie]
apigateway      | 2025-12-08T14:41:06.657Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Header]
apigateway      | 2025-12-08T14:41:06.657Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Host]
apigateway      | 2025-12-08T14:41:06.657Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Method]
apigateway      | 2025-12-08T14:41:06.658Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Path]
apigateway      | 2025-12-08T14:41:06.658Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Query]
apigateway      | 2025-12-08T14:41:06.658Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [ReadBody]
apigateway      | 2025-12-08T14:41:06.659Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [RemoteAddr]
apigateway      | 2025-12-08T14:41:06.660Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [XForwardedRemoteAddr]
apigateway      | 2025-12-08T14:41:06.661Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [Weight]
apigateway      | 2025-12-08T14:41:06.662Z  INFO 1 --- [ApiGateway] [           main] o.s.c.g.r.RouteDefinitionRouteLocator    : Loaded RoutePredicateFactory [CloudFoundryRouteService]
authservice     | 2025-12-08T14:41:06.905Z  INFO 1 --- [AuthService] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
bookingservice  | 2025-12-08T14:41:07.138Z  INFO 1 --- [BookingService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat initialized with port 8081 (http)
flightservice   | 2025-12-08T14:41:07.154Z  INFO 1 --- [FlightService] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
bookingservice  | 2025-12-08T14:41:07.209Z  INFO 1 --- [BookingService] [           main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
bookingservice  | 2025-12-08T14:41:07.210Z  INFO 1 --- [BookingService] [           main] o.apache.catalina.core.StandardEngine    : Starting Servlet engine: [Apache Tomcat/11.0.14]
bookingservice  | 2025-12-08T14:41:07.412Z  INFO 1 --- [BookingService] [           main] b.w.c.s.WebApplicationContextInitializer : Root WebApplicationContext: initialization completed in 5089 ms
flightservice   | 2025-12-08T14:41:07.461Z  INFO 1 --- [FlightService] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 7.1.8.Final
apigateway      | 2025-12-08T14:41:07.783Z  INFO 1 --- [ApiGateway] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestTemplate.
apigateway      | 2025-12-08T14:41:07.961Z  WARN 1 --- [ApiGateway] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
apigateway      | 2025-12-08T14:41:08.154Z  INFO 1 --- [ApiGateway] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
apigateway      | 2025-12-08T14:41:08.273Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
apigateway      | 2025-12-08T14:41:08.296Z  INFO 1 --- [ApiGateway] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
apigateway      | 2025-12-08T14:41:08.331Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
apigateway      | 2025-12-08T14:41:08.332Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
apigateway      | 2025-12-08T14:41:08.332Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
apigateway      | 2025-12-08T14:41:08.332Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
apigateway      | 2025-12-08T14:41:08.332Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
apigateway      | 2025-12-08T14:41:08.333Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
apigateway      | 2025-12-08T14:41:08.333Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-08T14:41:08.616Z  INFO 1 --- [BookingService] [           main] o.hibernate.jpa.internal.util.LogHelper  : HHH000204: Processing PersistenceUnitInfo [name: default]
bookingservice  | 2025-12-08T14:41:08.717Z  INFO 1 --- [BookingService] [           main] org.hibernate.Version                    : HHH000412: Hibernate ORM core version 7.1.8.Final
authservice     | 2025-12-08T14:41:08.856Z  INFO 1 --- [AuthService] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
authservice     | 2025-12-08T14:41:09.100Z  INFO 1 --- [AuthService] [           main] o.s.d.j.r.query.QueryEnhancerFactories   : Hibernate is in classpath; If applicable, HQL parser will be used.
emailservice    | 2025-12-08T14:41:09.198Z  INFO 1 --- [EmailService] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
emailservice    | 2025-12-08T14:41:09.462Z  WARN 1 --- [EmailService] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
apigateway      | 2025-12-08T14:41:09.499Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
apigateway      | 2025-12-08T14:41:09.504Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
apigateway      | 2025-12-08T14:41:09.513Z  INFO 1 --- [ApiGateway] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
apigateway      | 2025-12-08T14:41:09.519Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765204869518 with initial instances count: 0
apigateway      | 2025-12-08T14:41:09.536Z  INFO 1 --- [ApiGateway] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application APIGATEWAY with eureka with status UP
apigateway      | 2025-12-08T14:41:09.540Z  INFO 1 --- [ApiGateway] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765204869540, current=UP, previous=STARTING]
apigateway      | 2025-12-08T14:41:09.550Z  INFO 1 --- [ApiGateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b1d5ae2d07e0:ApiGateway:9000: registering service...
flightservice   | 2025-12-08T14:41:09.616Z  INFO 1 --- [FlightService] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
emailservice    | 2025-12-08T14:41:09.775Z  INFO 1 --- [EmailService] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
flightservice   | 2025-12-08T14:41:09.797Z  INFO 1 --- [FlightService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
emailservice    | 2025-12-08T14:41:09.917Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
emailservice    | 2025-12-08T14:41:09.929Z  INFO 1 --- [EmailService] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
emailservice    | 2025-12-08T14:41:09.948Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
emailservice    | 2025-12-08T14:41:09.949Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
emailservice    | 2025-12-08T14:41:09.949Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
emailservice    | 2025-12-08T14:41:09.949Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
emailservice    | 2025-12-08T14:41:09.949Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
emailservice    | 2025-12-08T14:41:09.949Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
emailservice    | 2025-12-08T14:41:09.949Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
eureka          | 2025-12-08T14:41:10.130Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-9] c.n.e.registry.AbstractInstanceRegistry  : Registered instance APIGATEWAY/b1d5ae2d07e0:ApiGateway:9000 with status UP (replication=false)
apigateway      | 2025-12-08T14:41:10.137Z  INFO 1 --- [ApiGateway] [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 9000 (http)
apigateway      | 2025-12-08T14:41:10.142Z  INFO 1 --- [ApiGateway] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 9000
apigateway      | 2025-12-08T14:41:10.155Z  INFO 1 --- [ApiGateway] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_APIGATEWAY/b1d5ae2d07e0:ApiGateway:9000 - registration status: 204
apigateway      | 2025-12-08T14:41:10.200Z  INFO 1 --- [ApiGateway] [           main] o.e.apigateway.ApiGatewayApplication     : Started ApiGatewayApplication in 10.383 seconds (process running for 11.812)
authservice     | 2025-12-08T14:41:10.265Z  INFO 1 --- [AuthService] [           main] eAuthenticationProviderManagerConfigurer : Global AuthenticationManager configured with AuthenticationProvider bean with name authenticationProvider
authservice     | 2025-12-08T14:41:10.266Z  WARN 1 --- [AuthService] [           main] r$InitializeUserDetailsManagerConfigurer : Global AuthenticationManager configured with an AuthenticationProvider bean. UserDetailsService beans will not be used by Spring Security for automatically configuring username/password login. Consider removing the AuthenticationProvider bean. Alternatively, consider using the UserDetailsService in a manually instantiated DaoAuthenticationProvider. If the current configuration is intentional, to turn off this warning, increase the logging level of 'org.springframework.security.config.annotation.authentication.configuration.InitializeUserDetailsBeanManagerConfigurer' to ERROR
authservice     | 2025-12-08T14:41:10.404Z  WARN 1 --- [AuthService] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
flightservice   | 2025-12-08T14:41:10.424Z  INFO 1 --- [FlightService] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection ConnectionID:1 ClientConnectionId: 07237891-d5c7-43ee-b464-ae19bd353fcd
flightservice   | 2025-12-08T14:41:10.427Z  INFO 1 --- [FlightService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
bookingservice  | 2025-12-08T14:41:10.431Z  INFO 1 --- [BookingService] [           main] o.s.o.j.p.SpringPersistenceUnitInfo      : No LoadTimeWeaver setup: ignoring JPA class transformer
bookingservice  | 2025-12-08T14:41:10.485Z  INFO 1 --- [BookingService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Starting...
flightservice   | 2025-12-08T14:41:10.518Z  WARN 1 --- [FlightService] [           main] org.hibernate.orm.deprecation            : HHH90000025: SQLServerDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
flightservice   | 2025-12-08T14:41:10.562Z  INFO 1 --- [FlightService] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
flightservice   | 	Database JDBC URL [jdbc:sqlserver://sql_db:1433;concatNullYieldsNull=ON;quotedIdentifier=ON;connectRetryInterval=10;connectRetryCount=1;maxResultBuffer=-1;sendTemporalDataTypesAsStringForBulkCopy=true;delayLoadingLobs=true;useFmtOnly=false;vectorTypeSupport=v1;cacheBulkCopyMetadata=false;bulkCopyForBatchInsertAllowEncryptedValueModifications=false;bulkCopyForBatchInsertTableLock=false;bulkCopyForBatchInsertKeepNulls=false;bulkCopyForBatchInsertKeepIdentity=false;bulkCopyForBatchInsertFireTriggers=false;bulkCopyForBatchInsertCheckConstraints=false;bulkCopyForBatchInsertBatchSize=0;useBulkCopyForBatchInsert=false;cancelQueryTimeout=-1;sslProtocol=TLS;calcBigDecimalPrecision=false;useDefaultJaasConfig=false;jaasConfigurationName=SQLJDBCDriver;statementPoolingCacheSize=0;serverPreparedStatementDiscardThreshold=10;enablePrepareOnFirstPreparedStatementCall=false;fips=false;socketTimeout=0;authentication=NotSpecified;authenticationScheme=nativeAuthentication;xopenStates=false;datetimeParameterType=datetime2;sendTimeAsDatetime=true;replication=false;trustStoreType=JKS;trustServerCertificate=true;TransparentNetworkIPResolution=true;iPAddressPreference=IPv4First;serverNameAsACE=false;sendStringParametersAsUnicode=true;selectMethod=direct;responseBuffering=adaptive;queryTimeout=-1;packetSize=8000;multiSubnetFailover=false;loginTimeout=30;lockTimeout=-1;lastUpdateCount=true;useDefaultGSSCredential=false;prepareMethod=prepexec;encrypt=true;disableStatementPooling=true;databaseName=FlightBooking;columnEncryptionSetting=Disabled;applicationName=Microsoft JDBC Driver for SQL Server;applicationIntent=readwrite;]
flightservice   | 	Database driver: Microsoft JDBC Driver 13.2 for SQL Server
flightservice   | 	Database dialect: SQLServerDialect
flightservice   | 	Database version: 16.0
flightservice   | 	Default catalog/schema: FlightBooking/dbo
flightservice   | 	Autocommit mode: undefined/unknown
flightservice   | 	Isolation level: READ_COMMITTED [default READ_COMMITTED]
flightservice   | 	JDBC fetch size: 128
flightservice   | 	Pool: DatasourceConnectionProviderImpl
flightservice   | 	Minimum pool size: undefined/unknown
flightservice   | 	Maximum pool size: undefined/unknown
emailservice    | 2025-12-08T14:41:10.689Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
emailservice    | 2025-12-08T14:41:10.691Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
emailservice    | 2025-12-08T14:41:10.693Z  INFO 1 --- [EmailService] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
emailservice    | 2025-12-08T14:41:10.695Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765204870694 with initial instances count: 0
emailservice    | 2025-12-08T14:41:10.699Z  INFO 1 --- [EmailService] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application EMAILSERVICE with eureka with status UP
emailservice    | 2025-12-08T14:41:10.700Z  INFO 1 --- [EmailService] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765204870700, current=UP, previous=STARTING]
emailservice    | 2025-12-08T14:41:10.702Z  INFO 1 --- [EmailService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_EMAILSERVICE/fe5a43e4e71e:EmailService:8082: registering service...
emailservice    | 2025-12-08T14:41:10.725Z  INFO 1 --- [EmailService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8082 (http) with context path '/'
emailservice    | 2025-12-08T14:41:10.727Z  INFO 1 --- [EmailService] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8082
eureka          | 2025-12-08T14:41:10.772Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] c.n.e.registry.AbstractInstanceRegistry  : Registered instance EMAILSERVICE/fe5a43e4e71e:EmailService:8082 with status UP (replication=false)
emailservice    | 2025-12-08T14:41:10.774Z  INFO 1 --- [EmailService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_EMAILSERVICE/fe5a43e4e71e:EmailService:8082 - registration status: 204
emailservice    | 2025-12-08T14:41:10.815Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice    | 	allow.auto.create.topics = true
emailservice    | 	auto.commit.interval.ms = 5000
emailservice    | 	auto.offset.reset = latest
emailservice    | 	bootstrap.servers = [kafkaQueue:9092]
emailservice    | 	check.crcs = true
emailservice    | 	client.dns.lookup = use_all_dns_ips
emailservice    | 	client.id = consumer-email-service-group-1
emailservice    | 	client.rack = 
emailservice    | 	connections.max.idle.ms = 540000
emailservice    | 	default.api.timeout.ms = 60000
emailservice    | 	enable.auto.commit = false
emailservice    | 	enable.metrics.push = true
emailservice    | 	exclude.internal.topics = true
emailservice    | 	fetch.max.bytes = 52428800
emailservice    | 	fetch.max.wait.ms = 500
emailservice    | 	fetch.min.bytes = 1
emailservice    | 	group.id = email-service-group
emailservice    | 	group.instance.id = null
emailservice    | 	group.protocol = classic
emailservice    | 	group.remote.assignor = null
emailservice    | 	heartbeat.interval.ms = 3000
emailservice    | 	interceptor.classes = []
emailservice    | 	internal.leave.group.on.close = true
emailservice    | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice    | 	isolation.level = read_uncommitted
emailservice    | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice    | 	max.partition.fetch.bytes = 1048576
emailservice    | 	max.poll.interval.ms = 300000
emailservice    | 	max.poll.records = 500
emailservice    | 	metadata.max.age.ms = 300000
emailservice    | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice    | 	metadata.recovery.strategy = rebootstrap
emailservice    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice    | 	metrics.num.samples = 2
emailservice    | 	metrics.recording.level = INFO
emailservice    | 	metrics.sample.window.ms = 30000
emailservice    | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice    | 	receive.buffer.bytes = 65536
emailservice    | 	reconnect.backoff.max.ms = 1000
emailservice    | 	reconnect.backoff.ms = 50
emailservice    | 	request.timeout.ms = 30000
emailservice    | 	retry.backoff.max.ms = 1000
emailservice    | 	retry.backoff.ms = 100
emailservice    | 	sasl.client.callback.handler.class = null
emailservice    | 	sasl.jaas.config = null
emailservice    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice    | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice    | 	sasl.kerberos.service.name = null
emailservice    | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice    | 	sasl.login.callback.handler.class = null
emailservice    | 	sasl.login.class = null
emailservice    | 	sasl.login.connect.timeout.ms = null
emailservice    | 	sasl.login.read.timeout.ms = null
emailservice    | 	sasl.login.refresh.buffer.seconds = 300
emailservice    | 	sasl.login.refresh.min.period.seconds = 60
emailservice    | 	sasl.login.refresh.window.factor = 0.8
emailservice    | 	sasl.login.refresh.window.jitter = 0.05
emailservice    | 	sasl.login.retry.backoff.max.ms = 10000
emailservice    | 	sasl.login.retry.backoff.ms = 100
emailservice    | 	sasl.mechanism = GSSAPI
emailservice    | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice    | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice    | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice    | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice    | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice    | 	sasl.oauthbearer.assertion.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice    | 	sasl.oauthbearer.assertion.template.file = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice    | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice    | 	sasl.oauthbearer.expected.audience = null
emailservice    | 	sasl.oauthbearer.expected.issuer = null
emailservice    | 	sasl.oauthbearer.header.urlencode = false
emailservice    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice    | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice    | 	sasl.oauthbearer.scope = null
emailservice    | 	sasl.oauthbearer.scope.claim.name = scope
emailservice    | 	sasl.oauthbearer.sub.claim.name = sub
emailservice    | 	sasl.oauthbearer.token.endpoint.url = null
emailservice    | 	security.protocol = PLAINTEXT
emailservice    | 	security.providers = null
emailservice    | 	send.buffer.bytes = 131072
emailservice    | 	session.timeout.ms = 45000
emailservice    | 	share.acknowledgement.mode = implicit
emailservice    | 	socket.connection.setup.timeout.max.ms = 30000
emailservice    | 	socket.connection.setup.timeout.ms = 10000
emailservice    | 	ssl.cipher.suites = null
emailservice    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice    | 	ssl.endpoint.identification.algorithm = https
emailservice    | 	ssl.engine.factory.class = null
emailservice    | 	ssl.key.password = null
emailservice    | 	ssl.keymanager.algorithm = SunX509
emailservice    | 	ssl.keystore.certificate.chain = null
emailservice    | 	ssl.keystore.key = null
emailservice    | 	ssl.keystore.location = null
emailservice    | 	ssl.keystore.password = null
emailservice    | 	ssl.keystore.type = JKS
emailservice    | 	ssl.protocol = TLSv1.3
emailservice    | 	ssl.provider = null
emailservice    | 	ssl.secure.random.implementation = null
emailservice    | 	ssl.trustmanager.algorithm = PKIX
emailservice    | 	ssl.truststore.certificates = null
emailservice    | 	ssl.truststore.location = null
emailservice    | 	ssl.truststore.password = null
emailservice    | 	ssl.truststore.type = JKS
emailservice    | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice    | 
emailservice    | 2025-12-08T14:41:10.907Z  INFO 1 --- [EmailService] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
eureka          | 2025-12-08T14:41:11.014Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance APIGATEWAY/b1d5ae2d07e0:ApiGateway:9000 with status UP (replication=true)
bookingservice  | 2025-12-08T14:41:11.048Z  INFO 1 --- [BookingService] [           main] com.zaxxer.hikari.pool.HikariPool        : HikariPool-1 - Added connection ConnectionID:1 ClientConnectionId: 1e64b2e5-4b93-4b9f-a100-6234db71f87b
bookingservice  | 2025-12-08T14:41:11.056Z  INFO 1 --- [BookingService] [           main] com.zaxxer.hikari.HikariDataSource       : HikariPool-1 - Start completed.
bookingservice  | 2025-12-08T14:41:11.265Z  WARN 1 --- [BookingService] [           main] org.hibernate.orm.deprecation            : HHH90000025: SQLServerDialect does not need to be specified explicitly using 'hibernate.dialect' (remove the property setting and it will be selected by default)
eureka          | 2025-12-08T14:41:11.293Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-3] c.n.e.registry.AbstractInstanceRegistry  : Registered instance EMAILSERVICE/fe5a43e4e71e:EmailService:8082 with status UP (replication=true)
bookingservice  | 2025-12-08T14:41:11.364Z  INFO 1 --- [BookingService] [           main] org.hibernate.orm.connections.pooling    : HHH10001005: Database info:
bookingservice  | 	Database JDBC URL [jdbc:sqlserver://sql_db:1433;concatNullYieldsNull=ON;quotedIdentifier=ON;connectRetryInterval=10;connectRetryCount=1;maxResultBuffer=-1;sendTemporalDataTypesAsStringForBulkCopy=true;delayLoadingLobs=true;useFmtOnly=false;vectorTypeSupport=v1;cacheBulkCopyMetadata=false;bulkCopyForBatchInsertAllowEncryptedValueModifications=false;bulkCopyForBatchInsertTableLock=false;bulkCopyForBatchInsertKeepNulls=false;bulkCopyForBatchInsertKeepIdentity=false;bulkCopyForBatchInsertFireTriggers=false;bulkCopyForBatchInsertCheckConstraints=false;bulkCopyForBatchInsertBatchSize=0;useBulkCopyForBatchInsert=false;cancelQueryTimeout=-1;sslProtocol=TLS;calcBigDecimalPrecision=false;useDefaultJaasConfig=false;jaasConfigurationName=SQLJDBCDriver;statementPoolingCacheSize=0;serverPreparedStatementDiscardThreshold=10;enablePrepareOnFirstPreparedStatementCall=false;fips=false;socketTimeout=0;authentication=NotSpecified;authenticationScheme=nativeAuthentication;xopenStates=false;datetimeParameterType=datetime2;sendTimeAsDatetime=true;replication=false;trustStoreType=JKS;trustServerCertificate=true;TransparentNetworkIPResolution=true;iPAddressPreference=IPv4First;serverNameAsACE=false;sendStringParametersAsUnicode=true;selectMethod=direct;responseBuffering=adaptive;queryTimeout=-1;packetSize=8000;multiSubnetFailover=false;loginTimeout=30;lockTimeout=-1;lastUpdateCount=true;useDefaultGSSCredential=false;prepareMethod=prepexec;encrypt=true;disableStatementPooling=true;databaseName=TicketDB;columnEncryptionSetting=Disabled;applicationName=Microsoft JDBC Driver for SQL Server;applicationIntent=readwrite;]
bookingservice  | 	Database driver: Microsoft JDBC Driver 13.2 for SQL Server
bookingservice  | 	Database dialect: SQLServerDialect
bookingservice  | 	Database version: 16.0
bookingservice  | 	Default catalog/schema: TicketDB/dbo
bookingservice  | 	Autocommit mode: undefined/unknown
bookingservice  | 	Isolation level: READ_COMMITTED [default READ_COMMITTED]
bookingservice  | 	JDBC fetch size: 128
bookingservice  | 	Pool: DatasourceConnectionProviderImpl
bookingservice  | 	Minimum pool size: undefined/unknown
bookingservice  | 	Maximum pool size: undefined/unknown
emailservice    | 2025-12-08T14:41:11.542Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice    | 2025-12-08T14:41:11.544Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice    | 2025-12-08T14:41:11.545Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1765204871538
emailservice    | 2025-12-08T14:41:11.557Z  INFO 1 --- [EmailService] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Subscribed to topic(s): ticket.cancelled
emailservice    | 2025-12-08T14:41:11.583Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice    | 	allow.auto.create.topics = true
emailservice    | 	auto.commit.interval.ms = 5000
emailservice    | 	auto.offset.reset = latest
emailservice    | 	bootstrap.servers = [kafkaQueue:9092]
emailservice    | 	check.crcs = true
emailservice    | 	client.dns.lookup = use_all_dns_ips
emailservice    | 	client.id = consumer-email-service-group-2
emailservice    | 	client.rack = 
emailservice    | 	connections.max.idle.ms = 540000
emailservice    | 	default.api.timeout.ms = 60000
emailservice    | 	enable.auto.commit = false
emailservice    | 	enable.metrics.push = true
emailservice    | 	exclude.internal.topics = true
emailservice    | 	fetch.max.bytes = 52428800
emailservice    | 	fetch.max.wait.ms = 500
emailservice    | 	fetch.min.bytes = 1
emailservice    | 	group.id = email-service-group
emailservice    | 	group.instance.id = null
emailservice    | 	group.protocol = classic
emailservice    | 	group.remote.assignor = null
emailservice    | 	heartbeat.interval.ms = 3000
emailservice    | 	interceptor.classes = []
emailservice    | 	internal.leave.group.on.close = true
emailservice    | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice    | 	isolation.level = read_uncommitted
emailservice    | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice    | 	max.partition.fetch.bytes = 1048576
emailservice    | 	max.poll.interval.ms = 300000
emailservice    | 	max.poll.records = 500
emailservice    | 	metadata.max.age.ms = 300000
emailservice    | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice    | 	metadata.recovery.strategy = rebootstrap
emailservice    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice    | 	metrics.num.samples = 2
emailservice    | 	metrics.recording.level = INFO
emailservice    | 	metrics.sample.window.ms = 30000
emailservice    | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice    | 	receive.buffer.bytes = 65536
emailservice    | 	reconnect.backoff.max.ms = 1000
emailservice    | 	reconnect.backoff.ms = 50
emailservice    | 	request.timeout.ms = 30000
emailservice    | 	retry.backoff.max.ms = 1000
emailservice    | 	retry.backoff.ms = 100
emailservice    | 	sasl.client.callback.handler.class = null
emailservice    | 	sasl.jaas.config = null
emailservice    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice    | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice    | 	sasl.kerberos.service.name = null
emailservice    | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice    | 	sasl.login.callback.handler.class = null
emailservice    | 	sasl.login.class = null
emailservice    | 	sasl.login.connect.timeout.ms = null
emailservice    | 	sasl.login.read.timeout.ms = null
emailservice    | 	sasl.login.refresh.buffer.seconds = 300
emailservice    | 	sasl.login.refresh.min.period.seconds = 60
emailservice    | 	sasl.login.refresh.window.factor = 0.8
emailservice    | 	sasl.login.refresh.window.jitter = 0.05
emailservice    | 	sasl.login.retry.backoff.max.ms = 10000
emailservice    | 	sasl.login.retry.backoff.ms = 100
emailservice    | 	sasl.mechanism = GSSAPI
emailservice    | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice    | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice    | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice    | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice    | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice    | 	sasl.oauthbearer.assertion.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice    | 	sasl.oauthbearer.assertion.template.file = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice    | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice    | 	sasl.oauthbearer.expected.audience = null
emailservice    | 	sasl.oauthbearer.expected.issuer = null
emailservice    | 	sasl.oauthbearer.header.urlencode = false
emailservice    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice    | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice    | 	sasl.oauthbearer.scope = null
emailservice    | 	sasl.oauthbearer.scope.claim.name = scope
emailservice    | 	sasl.oauthbearer.sub.claim.name = sub
emailservice    | 	sasl.oauthbearer.token.endpoint.url = null
emailservice    | 	security.protocol = PLAINTEXT
emailservice    | 	security.providers = null
emailservice    | 	send.buffer.bytes = 131072
emailservice    | 	session.timeout.ms = 45000
emailservice    | 	share.acknowledgement.mode = implicit
emailservice    | 	socket.connection.setup.timeout.max.ms = 30000
emailservice    | 	socket.connection.setup.timeout.ms = 10000
emailservice    | 	ssl.cipher.suites = null
emailservice    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice    | 	ssl.endpoint.identification.algorithm = https
emailservice    | 	ssl.engine.factory.class = null
emailservice    | 	ssl.key.password = null
emailservice    | 	ssl.keymanager.algorithm = SunX509
emailservice    | 	ssl.keystore.certificate.chain = null
emailservice    | 	ssl.keystore.key = null
emailservice    | 	ssl.keystore.location = null
emailservice    | 	ssl.keystore.password = null
emailservice    | 	ssl.keystore.type = JKS
emailservice    | 	ssl.protocol = TLSv1.3
emailservice    | 	ssl.provider = null
emailservice    | 	ssl.secure.random.implementation = null
emailservice    | 	ssl.trustmanager.algorithm = PKIX
emailservice    | 	ssl.truststore.certificates = null
emailservice    | 	ssl.truststore.location = null
emailservice    | 	ssl.truststore.password = null
emailservice    | 	ssl.truststore.type = JKS
emailservice    | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice    | 
emailservice    | 2025-12-08T14:41:11.584Z  INFO 1 --- [EmailService] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice    | 2025-12-08T14:41:11.671Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice    | 2025-12-08T14:41:11.671Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice    | 2025-12-08T14:41:11.672Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1765204871670
emailservice    | 2025-12-08T14:41:11.675Z  INFO 1 --- [EmailService] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Subscribed to topic(s): schedule.added
emailservice    | 2025-12-08T14:41:11.683Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.config.AbstractConfig   : ConsumerConfig values: 
emailservice    | 	allow.auto.create.topics = true
emailservice    | 	auto.commit.interval.ms = 5000
emailservice    | 	auto.offset.reset = latest
emailservice    | 	bootstrap.servers = [kafkaQueue:9092]
emailservice    | 	check.crcs = true
emailservice    | 	client.dns.lookup = use_all_dns_ips
emailservice    | 	client.id = consumer-email-service-group-3
emailservice    | 	client.rack = 
emailservice    | 	connections.max.idle.ms = 540000
emailservice    | 	default.api.timeout.ms = 60000
emailservice    | 	enable.auto.commit = false
emailservice    | 	enable.metrics.push = true
emailservice    | 	exclude.internal.topics = true
emailservice    | 	fetch.max.bytes = 52428800
emailservice    | 	fetch.max.wait.ms = 500
emailservice    | 	fetch.min.bytes = 1
emailservice    | 	group.id = email-service-group
emailservice    | 	group.instance.id = null
emailservice    | 	group.protocol = classic
emailservice    | 	group.remote.assignor = null
emailservice    | 	heartbeat.interval.ms = 3000
emailservice    | 	interceptor.classes = []
emailservice    | 	internal.leave.group.on.close = true
emailservice    | 	internal.throw.on.fetch.stable.offset.unsupported = false
emailservice    | 	isolation.level = read_uncommitted
emailservice    | 	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
emailservice    | 	max.partition.fetch.bytes = 1048576
emailservice    | 	max.poll.interval.ms = 300000
emailservice    | 	max.poll.records = 500
emailservice    | 	metadata.max.age.ms = 300000
emailservice    | 	metadata.recovery.rebootstrap.trigger.ms = 300000
emailservice    | 	metadata.recovery.strategy = rebootstrap
emailservice    | 	metric.reporters = [org.apache.kafka.common.metrics.JmxReporter]
emailservice    | 	metrics.num.samples = 2
emailservice    | 	metrics.recording.level = INFO
emailservice    | 	metrics.sample.window.ms = 30000
emailservice    | 	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
emailservice    | 	receive.buffer.bytes = 65536
emailservice    | 	reconnect.backoff.max.ms = 1000
emailservice    | 	reconnect.backoff.ms = 50
emailservice    | 	request.timeout.ms = 30000
emailservice    | 	retry.backoff.max.ms = 1000
emailservice    | 	retry.backoff.ms = 100
emailservice    | 	sasl.client.callback.handler.class = null
emailservice    | 	sasl.jaas.config = null
emailservice    | 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
emailservice    | 	sasl.kerberos.min.time.before.relogin = 60000
emailservice    | 	sasl.kerberos.service.name = null
emailservice    | 	sasl.kerberos.ticket.renew.jitter = 0.05
emailservice    | 	sasl.kerberos.ticket.renew.window.factor = 0.8
emailservice    | 	sasl.login.callback.handler.class = null
emailservice    | 	sasl.login.class = null
emailservice    | 	sasl.login.connect.timeout.ms = null
emailservice    | 	sasl.login.read.timeout.ms = null
emailservice    | 	sasl.login.refresh.buffer.seconds = 300
emailservice    | 	sasl.login.refresh.min.period.seconds = 60
emailservice    | 	sasl.login.refresh.window.factor = 0.8
emailservice    | 	sasl.login.refresh.window.jitter = 0.05
emailservice    | 	sasl.login.retry.backoff.max.ms = 10000
emailservice    | 	sasl.login.retry.backoff.ms = 100
emailservice    | 	sasl.mechanism = GSSAPI
emailservice    | 	sasl.oauthbearer.assertion.algorithm = RS256
emailservice    | 	sasl.oauthbearer.assertion.claim.aud = null
emailservice    | 	sasl.oauthbearer.assertion.claim.exp.seconds = 300
emailservice    | 	sasl.oauthbearer.assertion.claim.iss = null
emailservice    | 	sasl.oauthbearer.assertion.claim.jti.include = false
emailservice    | 	sasl.oauthbearer.assertion.claim.nbf.seconds = 60
emailservice    | 	sasl.oauthbearer.assertion.claim.sub = null
emailservice    | 	sasl.oauthbearer.assertion.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.file = null
emailservice    | 	sasl.oauthbearer.assertion.private.key.passphrase = null
emailservice    | 	sasl.oauthbearer.assertion.template.file = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.id = null
emailservice    | 	sasl.oauthbearer.client.credentials.client.secret = null
emailservice    | 	sasl.oauthbearer.clock.skew.seconds = 30
emailservice    | 	sasl.oauthbearer.expected.audience = null
emailservice    | 	sasl.oauthbearer.expected.issuer = null
emailservice    | 	sasl.oauthbearer.header.urlencode = false
emailservice    | 	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
emailservice    | 	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
emailservice    | 	sasl.oauthbearer.jwks.endpoint.url = null
emailservice    | 	sasl.oauthbearer.jwt.retriever.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtRetriever
emailservice    | 	sasl.oauthbearer.jwt.validator.class = class org.apache.kafka.common.security.oauthbearer.DefaultJwtValidator
emailservice    | 	sasl.oauthbearer.scope = null
emailservice    | 	sasl.oauthbearer.scope.claim.name = scope
emailservice    | 	sasl.oauthbearer.sub.claim.name = sub
emailservice    | 	sasl.oauthbearer.token.endpoint.url = null
emailservice    | 	security.protocol = PLAINTEXT
emailservice    | 	security.providers = null
emailservice    | 	send.buffer.bytes = 131072
emailservice    | 	session.timeout.ms = 45000
emailservice    | 	share.acknowledgement.mode = implicit
emailservice    | 	socket.connection.setup.timeout.max.ms = 30000
emailservice    | 	socket.connection.setup.timeout.ms = 10000
emailservice    | 	ssl.cipher.suites = null
emailservice    | 	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
emailservice    | 	ssl.endpoint.identification.algorithm = https
emailservice    | 	ssl.engine.factory.class = null
emailservice    | 	ssl.key.password = null
emailservice    | 	ssl.keymanager.algorithm = SunX509
emailservice    | 	ssl.keystore.certificate.chain = null
emailservice    | 	ssl.keystore.key = null
emailservice    | 	ssl.keystore.location = null
emailservice    | 	ssl.keystore.password = null
emailservice    | 	ssl.keystore.type = JKS
emailservice    | 	ssl.protocol = TLSv1.3
emailservice    | 	ssl.provider = null
emailservice    | 	ssl.secure.random.implementation = null
emailservice    | 	ssl.trustmanager.algorithm = PKIX
emailservice    | 	ssl.truststore.certificates = null
emailservice    | 	ssl.truststore.location = null
emailservice    | 	ssl.truststore.password = null
emailservice    | 	ssl.truststore.type = JKS
emailservice    | 	value.deserializer = class org.springframework.kafka.support.serializer.JsonDeserializer
emailservice    | 
emailservice    | 2025-12-08T14:41:11.685Z  INFO 1 --- [EmailService] [           main] o.a.k.c.t.i.KafkaMetricsCollector        : initializing Kafka metrics collector
emailservice    | 2025-12-08T14:41:11.728Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 4.1.1
emailservice    | 2025-12-08T14:41:11.728Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: be816b82d25370ce
emailservice    | 2025-12-08T14:41:11.728Z  INFO 1 --- [EmailService] [           main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1765204871727
emailservice    | 2025-12-08T14:41:11.730Z  INFO 1 --- [EmailService] [           main] o.a.k.c.c.i.ClassicKafkaConsumer         : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Subscribed to topic(s): ticket.booked
emailservice    | 2025-12-08T14:41:11.772Z  INFO 1 --- [EmailService] [           main] o.e.e.EmailServiceApplication            : Started EmailServiceApplication in 12.999 seconds (process running for 14.182)
authservice     | 2025-12-08T14:41:12.428Z  INFO 1 --- [AuthService] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
authservice     | 2025-12-08T14:41:12.575Z  WARN 1 --- [AuthService] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
authservice     | 2025-12-08T14:41:12.654Z  INFO 1 --- [AuthService] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
authservice     | 2025-12-08T14:41:12.755Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
authservice     | 2025-12-08T14:41:12.769Z  INFO 1 --- [AuthService] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
authservice     | 2025-12-08T14:41:12.797Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
authservice     | 2025-12-08T14:41:12.798Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
authservice     | 2025-12-08T14:41:12.798Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
authservice     | 2025-12-08T14:41:12.798Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
authservice     | 2025-12-08T14:41:12.798Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
authservice     | 2025-12-08T14:41:12.798Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
authservice     | 2025-12-08T14:41:12.799Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
kafkaQueue      | [2025-12-08 14:41:12,853] INFO Sent auto-creation request for Set(schedule.added) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
kafkaQueue      | [2025-12-08 14:41:12,853] INFO Sent auto-creation request for Set(ticket.cancelled) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
kafkaQueue      | [2025-12-08 14:41:12,853] INFO Sent auto-creation request for Set(ticket.booked) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
kafkaQueue      | [2025-12-08 14:41:12,872] INFO Sent auto-creation request for Set(__consumer_offsets) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
emailservice    | 2025-12-08T14:41:12.884Z  WARN 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {ticket.cancelled=UNKNOWN_TOPIC_OR_PARTITION}
emailservice    | 2025-12-08T14:41:12.885Z  WARN 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {schedule.added=UNKNOWN_TOPIC_OR_PARTITION}
emailservice    | 2025-12-08T14:41:12.890Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice    | 2025-12-08T14:41:12.891Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
emailservice    | 2025-12-08T14:41:12.886Z  WARN 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] The metadata response from the cluster reported a recoverable issue with correlation id 2 : {ticket.booked=UNKNOWN_TOPIC_OR_PARTITION}
emailservice    | 2025-12-08T14:41:12.892Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Cluster ID: 5L6g3nShT-eMCtK--X86sw
kafkaQueue      | [2025-12-08 14:41:12,944] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(schedule.added-0) (kafka.server.ReplicaFetcherManager)
kafkaQueue      | [2025-12-08 14:41:12,999] INFO Sent auto-creation request for Set(ticket.cancelled) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
kafkaQueue      | [2025-12-08 14:41:13,006] INFO [LogLoader partition=schedule.added-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T14:41:13.003Z  WARN 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {ticket.cancelled=UNKNOWN_TOPIC_OR_PARTITION}
kafkaQueue      | [2025-12-08 14:41:13,018] INFO Created log for partition schedule.added-0 in /tmp/kafka-logs/schedule.added-0 with properties {} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,028] INFO [Partition schedule.added-0 broker=1] No checkpointed highwatermark is found for partition schedule.added-0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,032] INFO Sent auto-creation request for Set(ticket.booked) to the active controller. (kafka.server.DefaultAutoTopicCreationManager)
emailservice    | 2025-12-08T14:41:13.034Z  WARN 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] The metadata response from the cluster reported a recoverable issue with correlation id 5 : {ticket.booked=UNKNOWN_TOPIC_OR_PARTITION}
kafkaQueue      | [2025-12-08 14:41:13,041] INFO [Partition schedule.added-0 broker=1] Log loaded for partition schedule.added-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,097] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ticket.cancelled-0) (kafka.server.ReplicaFetcherManager)
kafkaQueue      | [2025-12-08 14:41:13,107] INFO [LogLoader partition=ticket.cancelled-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,110] INFO Created log for partition ticket.cancelled-0 in /tmp/kafka-logs/ticket.cancelled-0 with properties {} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,111] INFO [Partition ticket.cancelled-0 broker=1] No checkpointed highwatermark is found for partition ticket.cancelled-0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,111] INFO [Partition ticket.cancelled-0 broker=1] Log loaded for partition ticket.cancelled-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,117] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(ticket.booked-0) (kafka.server.ReplicaFetcherManager)
kafkaQueue      | [2025-12-08 14:41:13,124] INFO [LogLoader partition=ticket.booked-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,126] INFO Created log for partition ticket.booked-0 in /tmp/kafka-logs/ticket.booked-0 with properties {} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,127] INFO [Partition ticket.booked-0 broker=1] No checkpointed highwatermark is found for partition ticket.booked-0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,127] INFO [Partition ticket.booked-0 broker=1] Log loaded for partition ticket.booked-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,135] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(__consumer_offsets-13, __consumer_offsets-46, __consumer_offsets-9, __consumer_offsets-42, __consumer_offsets-21, __consumer_offsets-17, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-5, __consumer_offsets-38, __consumer_offsets-1, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-45, __consumer_offsets-12, __consumer_offsets-41, __consumer_offsets-24, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-0, __consumer_offsets-29, __consumer_offsets-25, __consumer_offsets-8, __consumer_offsets-37, __consumer_offsets-4, __consumer_offsets-33, __consumer_offsets-15, __consumer_offsets-48, __consumer_offsets-11, __consumer_offsets-44, __consumer_offsets-23, __consumer_offsets-19, __consumer_offsets-32, __consumer_offsets-28, __consumer_offsets-7, __consumer_offsets-40, __consumer_offsets-3, __consumer_offsets-36, __consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-43, __consumer_offsets-10, __consumer_offsets-22, __consumer_offsets-18, __consumer_offsets-31, __consumer_offsets-27, __consumer_offsets-39, __consumer_offsets-6, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
kafkaQueue      | [2025-12-08 14:41:13,141] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,143] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,144] INFO [Partition __consumer_offsets-13 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,145] INFO [Partition __consumer_offsets-13 broker=1] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,158] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,160] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,160] INFO [Partition __consumer_offsets-46 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,161] INFO [Partition __consumer_offsets-46 broker=1] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,171] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,173] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,173] INFO [Partition __consumer_offsets-9 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,174] INFO [Partition __consumer_offsets-9 broker=1] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,185] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,187] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,188] INFO [Partition __consumer_offsets-42 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,188] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,199] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,201] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,202] INFO [Partition __consumer_offsets-21 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,202] INFO [Partition __consumer_offsets-21 broker=1] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,218] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,220] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,221] INFO [Partition __consumer_offsets-17 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,221] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,235] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,237] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,238] INFO [Partition __consumer_offsets-30 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,239] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,252] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,253] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,254] INFO [Partition __consumer_offsets-26 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,254] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.267Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.267Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 14:41:13,268] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,270] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,270] INFO [Partition __consumer_offsets-5 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,271] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.271Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T14:41:13.271Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,282] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,283] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,284] INFO [Partition __consumer_offsets-38 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,284] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.287Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.290Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,294] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,295] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,296] INFO [Partition __consumer_offsets-1 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,296] INFO [Partition __consumer_offsets-1 broker=1] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.296Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.297Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.297Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.297Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.299Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.300Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.302Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.302Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.303Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T14:41:13.304Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T14:41:13.306Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
kafkaQueue      | [2025-12-08 14:41:13,308] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T14:41:13.308Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Client requested disconnect from node 2147483646
kafkaQueue      | [2025-12-08 14:41:13,310] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,310] INFO [Partition __consumer_offsets-34 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,311] INFO [Partition __consumer_offsets-34 broker=1] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.316Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.317Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.317Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.317Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.317Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.317Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.317Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.317Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.317Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
flightservice   | 2025-12-08T14:41:13.318Z  INFO 1 --- [FlightService] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
kafkaQueue      | [2025-12-08 14:41:13,319] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,320] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,320] INFO [Partition __consumer_offsets-16 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,320] INFO [Partition __consumer_offsets-16 broker=1] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,329] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,330] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,330] INFO [Partition __consumer_offsets-45 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,330] INFO [Partition __consumer_offsets-45 broker=1] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,338] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,339] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,339] INFO [Partition __consumer_offsets-12 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,339] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,348] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,348] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,349] INFO [Partition __consumer_offsets-41 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,349] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,356] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,357] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,358] INFO [Partition __consumer_offsets-24 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,358] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,369] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,371] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,372] INFO [Partition __consumer_offsets-20 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,372] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,381] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,382] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,382] INFO [Partition __consumer_offsets-49 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,382] INFO [Partition __consumer_offsets-49 broker=1] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,391] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,391] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,392] INFO [Partition __consumer_offsets-0 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,392] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,400] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,400] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,401] INFO [Partition __consumer_offsets-29 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,401] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.403Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.405Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T14:41:13.406Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,409] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,410] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,410] INFO [Partition __consumer_offsets-25 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,410] INFO [Partition __consumer_offsets-25 broker=1] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.410Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.410Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.410Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.410Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T14:41:13.414Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.414Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.414Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 14:41:13,417] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,418] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,418] INFO [Partition __consumer_offsets-8 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,418] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,427] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T14:41:13.427Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.428Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T14:41:13.429Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,428] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,429] INFO [Partition __consumer_offsets-37 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,429] INFO [Partition __consumer_offsets-37 broker=1] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.430Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.432Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T14:41:13.433Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T14:41:13.433Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.434Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.434Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.434Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T14:41:13.437Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.437Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.437Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.437Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.437Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.438Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.438Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Client requested disconnect from node 2147483646
kafkaQueue      | [2025-12-08 14:41:13,440] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,441] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,442] INFO [Partition __consumer_offsets-4 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,442] INFO [Partition __consumer_offsets-4 broker=1] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.441Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.441Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.442Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 14:41:13,452] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,454] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,454] INFO [Partition __consumer_offsets-33 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,455] INFO [Partition __consumer_offsets-33 broker=1] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,463] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,463] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,464] INFO [Partition __consumer_offsets-15 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,464] INFO [Partition __consumer_offsets-15 broker=1] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,474] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,475] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,475] INFO [Partition __consumer_offsets-48 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,475] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,483] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,483] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,483] INFO [Partition __consumer_offsets-11 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,484] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,492] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,493] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,493] INFO [Partition __consumer_offsets-44 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,494] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,502] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,504] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,504] INFO [Partition __consumer_offsets-23 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,504] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,513] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,515] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,515] INFO [Partition __consumer_offsets-19 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,515] INFO [Partition __consumer_offsets-19 broker=1] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.521Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.523Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T14:41:13.524Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,526] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T14:41:13.529Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 14:41:13,528] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,529] INFO [Partition __consumer_offsets-32 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,529] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.530Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.530Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.530Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.532Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T14:41:13.533Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T14:41:13.536Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T14:41:13.536Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.536Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.536Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.538Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.540Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T14:41:13.542Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,543] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T14:41:13.544Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.544Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.545Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
kafkaQueue      | [2025-12-08 14:41:13,544] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
emailservice    | 2025-12-08T14:41:13.545Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Client requested disconnect from node 2147483646
kafkaQueue      | [2025-12-08 14:41:13,547] INFO [Partition __consumer_offsets-28 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.548Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.548Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.548Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.549Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Client requested disconnect from node 2147483646
kafkaQueue      | [2025-12-08 14:41:13,549] INFO [Partition __consumer_offsets-28 broker=1] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.551Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.552Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.552Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.556Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.556Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.556Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 14:41:13,558] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,559] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,559] INFO [Partition __consumer_offsets-7 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,560] INFO [Partition __consumer_offsets-7 broker=1] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,569] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,571] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,571] INFO [Partition __consumer_offsets-40 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,572] INFO [Partition __consumer_offsets-40 broker=1] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,581] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,582] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,583] INFO [Partition __consumer_offsets-3 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,583] INFO [Partition __consumer_offsets-3 broker=1] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,591] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,592] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,592] INFO [Partition __consumer_offsets-36 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,592] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,600] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,601] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,601] INFO [Partition __consumer_offsets-47 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,601] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,610] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,611] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,611] INFO [Partition __consumer_offsets-14 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,612] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,623] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,624] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,624] INFO [Partition __consumer_offsets-43 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,624] INFO [Partition __consumer_offsets-43 broker=1] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
authservice     | 2025-12-08T14:41:13.631Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
authservice     | 2025-12-08T14:41:13.634Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
authservice     | 2025-12-08T14:41:13.639Z  INFO 1 --- [AuthService] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
emailservice    | 2025-12-08T14:41:13.642Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
authservice     | 2025-12-08T14:41:13.642Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765204873642 with initial instances count: 0
kafkaQueue      | [2025-12-08 14:41:13,644] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T14:41:13.644Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
kafkaQueue      | [2025-12-08 14:41:13,646] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,646] INFO [Partition __consumer_offsets-10 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,646] INFO [Partition __consumer_offsets-10 broker=1] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.646Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T14:41:13.650Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.650Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.650Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.651Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Client requested disconnect from node 2147483646
authservice     | 2025-12-08T14:41:13.651Z  INFO 1 --- [AuthService] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application AUTHSERVICE with eureka with status UP
authservice     | 2025-12-08T14:41:13.653Z  INFO 1 --- [AuthService] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765204873653, current=UP, previous=STARTING]
emailservice    | 2025-12-08T14:41:13.654Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.654Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.654Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.654Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.655Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
kafkaQueue      | [2025-12-08 14:41:13,655] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
emailservice    | 2025-12-08T14:41:13.656Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.656Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
authservice     | 2025-12-08T14:41:13.656Z  INFO 1 --- [AuthService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/b23d61510aaa:AuthService:9091: registering service...
emailservice    | 2025-12-08T14:41:13.657Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
kafkaQueue      | [2025-12-08 14:41:13,656] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,657] INFO [Partition __consumer_offsets-22 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,657] INFO [Partition __consumer_offsets-22 broker=1] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
emailservice    | 2025-12-08T14:41:13.658Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T14:41:13.661Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.661Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.661Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.661Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T14:41:13.663Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: error response NOT_COORDINATOR. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.663Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.663Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] JoinGroup failed: This is not the correct coordinator. Marking coordinator unknown. Sent generation was Generation{generationId=-1, memberId='', protocol='null'}
emailservice    | 2025-12-08T14:41:13.663Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Client requested disconnect from node 2147483646
emailservice    | 2025-12-08T14:41:13.664Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.664Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.665Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.666Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.667Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false) is unavailable or invalid due to cause: coordinator unavailable. isDisconnected: false. Rediscovery will be attempted.
emailservice    | 2025-12-08T14:41:13.667Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Requesting disconnect from last known coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 14:41:13,668] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,669] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,669] INFO [Partition __consumer_offsets-18 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,670] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,679] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
authservice     | 2025-12-08T14:41:13.679Z  INFO 1 --- [AuthService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 9091 (http) with context path '/'
kafkaQueue      | [2025-12-08 14:41:13,680] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,680] INFO [Partition __consumer_offsets-31 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,680] INFO [Partition __consumer_offsets-31 broker=1] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
authservice     | 2025-12-08T14:41:13.681Z  INFO 1 --- [AuthService] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 9091
kafkaQueue      | [2025-12-08 14:41:13,691] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,693] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,693] INFO [Partition __consumer_offsets-27 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,693] INFO [Partition __consumer_offsets-27 broker=1] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
authservice     | 2025-12-08T14:41:13.699Z  INFO 1 --- [AuthService] [           main] o.e.authservice.AuthServiceApplication   : Started AuthServiceApplication in 16.029 seconds (process running for 17.01)
kafkaQueue      | [2025-12-08 14:41:13,703] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,704] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,704] INFO [Partition __consumer_offsets-39 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,705] INFO [Partition __consumer_offsets-39 broker=1] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,714] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,715] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,715] INFO [Partition __consumer_offsets-6 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,716] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
eureka          | 2025-12-08T14:41:13.718Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-5] c.n.e.registry.AbstractInstanceRegistry  : Registered instance AUTHSERVICE/b23d61510aaa:AuthService:9091 with status UP (replication=false)
authservice     | 2025-12-08T14:41:13.720Z  INFO 1 --- [AuthService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_AUTHSERVICE/b23d61510aaa:AuthService:9091 - registration status: 204
kafkaQueue      | [2025-12-08 14:41:13,725] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,726] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,726] INFO [Partition __consumer_offsets-35 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,726] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,735] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 (org.apache.kafka.storage.internals.log.UnifiedLog)
kafkaQueue      | [2025-12-08 14:41:13,737] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type="producer", segment.bytes=104857600} (kafka.log.LogManager)
kafkaQueue      | [2025-12-08 14:41:13,737] INFO [Partition __consumer_offsets-2 broker=1] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,737] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
kafkaQueue      | [2025-12-08 14:41:13,745] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-13 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,747] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-46 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,748] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-9 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,748] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-42 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,748] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-21 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,749] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-17 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,749] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-30 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,749] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-26 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,749] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-5 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,750] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-38 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,750] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-1 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,750] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-34 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,750] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-16 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,751] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-45 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,752] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-12 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,752] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-41 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,753] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-24 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,754] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-13 with epoch 0 in 3ms where 3ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,754] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-17 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,754] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-46 with epoch 0 in 2ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,754] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-34 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,754] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-20 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-9 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-49 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-30 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-26 with epoch 0 in 2ms where 2ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-16 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-0 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-12 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-29 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-5 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,756] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-25 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,756] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-8 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,756] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-37 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,756] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-21 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,757] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-0 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,757] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-4 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,757] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-33 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,757] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-15 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,755] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-42 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,758] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-1 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,758] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-38 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,758] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-45 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,758] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-24 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,758] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-49 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,759] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-33 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,759] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-8 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,759] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-20 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,759] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-29 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T14:41:13.758Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 14:41:13,759] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-41 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,759] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-37 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,759] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-4 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,759] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-25 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,759] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-48 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,760] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-11 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,761] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-15 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,761] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-44 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T14:41:13.760Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T14:41:13.761Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,762] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-23 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,761] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-48 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,764] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-11 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,764] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-23 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,764] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-19 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,764] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-32 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,764] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-44 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,765] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-28 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,765] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-7 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,765] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-40 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T14:41:13.765Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
kafkaQueue      | [2025-12-08 14:41:13,766] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-3 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,766] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-36 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,766] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-47 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,767] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-14 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,767] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-43 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,767] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-10 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T14:41:13.766Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Discovered group coordinator kafkaQueue:9092 (id: 2147483646 rack: null isFenced: false)
emailservice    | 2025-12-08T14:41:13.767Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
emailservice    | 2025-12-08T14:41:13.767Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: rebalance failed due to 'This is not the correct coordinator.' (NotCoordinatorException)
kafkaQueue      | [2025-12-08 14:41:13,768] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-28 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T14:41:13.768Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T14:41:13.768Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,769] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-22 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,770] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-18 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,770] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Empty state. Created a new member id consumer-email-service-group-3-fac08d3c-8e9f-4812-9bf4-3c31069d5272 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue      | [2025-12-08 14:41:13,770] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-31 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,770] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-27 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,770] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-10 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,771] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-47 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,771] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-39 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,771] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-40 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,771] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-6 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,771] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-35 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,771] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-22 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T14:41:13.772Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-3-fac08d3c-8e9f-4812-9bf4-3c31069d5272
kafkaQueue      | [2025-12-08 14:41:13,772] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-19 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T14:41:13.773Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,774] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-14 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,774] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-32 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,774] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-3 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,774] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-27 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,774] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-7 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,772] INFO [GroupCoordinator id=1] Scheduling loading of metadata from __consumer_offsets-2 with epoch 0 (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,776] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-43 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,776] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-6 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,776] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Empty state. Created a new member id consumer-email-service-group-1-3635d652-e0bf-44bf-96a1-b74d4c9631fd and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue      | [2025-12-08 14:41:13,776] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-36 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,776] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-31 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,777] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-39 with epoch 0 in 0ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,777] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Dynamic member with unknown member id joins group email-service-group in Empty state. Created a new member id consumer-email-service-group-2-3058da23-c3d1-468f-a71b-17dc5763ffc6 and requesting the member to rejoin with this id. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue      | [2025-12-08 14:41:13,777] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-35 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,777] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-3-fac08d3c-8e9f-4812-9bf4-3c31069d5272 joins group email-service-group in Empty state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice    | 2025-12-08T14:41:13.778Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-2-3058da23-c3d1-468f-a71b-17dc5763ffc6
kafkaQueue      | [2025-12-08 14:41:13,778] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-18 with epoch 0 in 1ms where 0ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
emailservice    | 2025-12-08T14:41:13.779Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] (Re-)joining group
emailservice    | 2025-12-08T14:41:13.779Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Request joining group due to: need to re-join with the given member-id: consumer-email-service-group-1-3635d652-e0bf-44bf-96a1-b74d4c9631fd
emailservice    | 2025-12-08T14:41:13.779Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] (Re-)joining group
kafkaQueue      | [2025-12-08 14:41:13,779] INFO [DynamicConfigPublisher broker id=1] Updating topic __consumer_offsets with new configuration : compression.type -> producer,cleanup.policy -> compact,segment.bytes -> 104857600 (kafka.server.metadata.DynamicConfigPublisher)
kafkaQueue      | [2025-12-08 14:41:13,780] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Preparing to rebalance group email-service-group in state PreparingRebalance with old generation 0 (reason: Adding new member consumer-email-service-group-3-fac08d3c-8e9f-4812-9bf4-3c31069d5272 with group instance id null; client reason: need to re-join with the given member-id: consumer-email-service-group-3-fac08d3c-8e9f-4812-9bf4-3c31069d5272). (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue      | [2025-12-08 14:41:13,779] INFO [GroupCoordinator id=1] Finished loading of metadata from __consumer_offsets-2 with epoch 0 in 1ms where 1ms was spent in the scheduler. Loaded 0 records which total to 0 bytes. (org.apache.kafka.coordinator.common.runtime.CoordinatorRuntime)
kafkaQueue      | [2025-12-08 14:41:13,791] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-2-3058da23-c3d1-468f-a71b-17dc5763ffc6 joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
kafkaQueue      | [2025-12-08 14:41:13,792] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Pending dynamic member with id consumer-email-service-group-1-3635d652-e0bf-44bf-96a1-b74d4c9631fd joins group email-service-group in PreparingRebalance state. Adding to the group now. (org.apache.kafka.coordinator.group.GroupMetadataManager)
bookingservice  | 2025-12-08T14:41:13.831Z  INFO 1 --- [BookingService] [           main] o.h.e.t.j.p.i.JtaPlatformInitiator       : HHH000489: No JTA platform available (set 'hibernate.transaction.jta.platform' to enable JTA platform integration)
flightservice   | 2025-12-08T14:41:13.919Z  INFO 1 --- [FlightService] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
flightservice   | 2025-12-08T14:41:14.092Z  INFO 1 --- [FlightService] [           main] o.s.d.j.r.query.QueryEnhancerFactories   : Hibernate is in classpath; If applicable, HQL parser will be used.
bookingservice  | 2025-12-08T14:41:14.168Z  INFO 1 --- [BookingService] [           main] j.LocalContainerEntityManagerFactoryBean : Initialized JPA EntityManagerFactory for persistence unit 'default'
eureka          | 2025-12-08T14:41:14.231Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-6] c.n.e.registry.AbstractInstanceRegistry  : Registered instance AUTHSERVICE/b23d61510aaa:AuthService:9091 with status UP (replication=true)
bookingservice  | 2025-12-08T14:41:14.348Z  INFO 1 --- [BookingService] [           main] o.s.d.j.r.query.QueryEnhancerFactories   : Hibernate is in classpath; If applicable, HQL parser will be used.
flightservice   | 2025-12-08T14:41:14.522Z  INFO 1 --- [FlightService] [           main] org.redisson.Version                     : Redisson 3.45.0
bookingservice  | 2025-12-08T14:41:14.642Z  WARN 1 --- [BookingService] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
bookingservice  | 2025-12-08T14:41:14.799Z  INFO 1 --- [BookingService] [           main] o.s.c.openfeign.FeignClientFactoryBean   : For 'FlightService' URL not provided. Will try picking an instance via load-balancing.
flightservice   | 2025-12-08T14:41:15.006Z  INFO 1 --- [FlightService] [isson-netty-1-5] o.redisson.connection.ConnectionsHolder  : 1 connections initialized for redis/172.20.0.5:6379
flightservice   | 2025-12-08T14:41:15.066Z  INFO 1 --- [FlightService] [sson-netty-1-20] o.redisson.connection.ConnectionsHolder  : 24 connections initialized for redis/172.20.0.5:6379
flightservice   | 2025-12-08T14:41:15.481Z  WARN 1 --- [FlightService] [           main] JpaBaseConfiguration$JpaWebConfiguration : spring.jpa.open-in-view is enabled by default. Therefore, database queries may be performed during view rendering. Explicitly configure spring.jpa.open-in-view to disable this warning
bookingservice  | 2025-12-08T14:41:16.680Z  INFO 1 --- [BookingService] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
bookingservice  | 2025-12-08T14:41:16.779Z  WARN 1 --- [BookingService] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
flightservice   | 2025-12-08T14:41:16.833Z  INFO 1 --- [FlightService] [           main] DiscoveryClientOptionalArgsConfiguration : Eureka HTTP Client uses RestClient.
bookingservice  | 2025-12-08T14:41:16.838Z  INFO 1 --- [BookingService] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
bookingservice  | 2025-12-08T14:41:16.879Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
bookingservice  | 2025-12-08T14:41:16.888Z  INFO 1 --- [BookingService] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
bookingservice  | 2025-12-08T14:41:16.899Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
bookingservice  | 2025-12-08T14:41:16.899Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
bookingservice  | 2025-12-08T14:41:16.899Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
bookingservice  | 2025-12-08T14:41:16.899Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
bookingservice  | 2025-12-08T14:41:16.899Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
bookingservice  | 2025-12-08T14:41:16.899Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
bookingservice  | 2025-12-08T14:41:16.899Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
flightservice   | 2025-12-08T14:41:16.933Z  WARN 1 --- [FlightService] [           main] iguration$LoadBalancerCaffeineWarnLogger : Spring Cloud LoadBalancer is currently working with the default cache. While this cache implementation is useful for development and tests, it's recommended to use Caffeine cache in production.You can switch to using Caffeine cache, by adding it and org.springframework.cache.caffeine.CaffeineCacheManager to the classpath.
flightservice   | 2025-12-08T14:41:16.969Z  INFO 1 --- [FlightService] [           main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
flightservice   | 2025-12-08T14:41:17.012Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
flightservice   | 2025-12-08T14:41:17.019Z  INFO 1 --- [FlightService] [           main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
flightservice   | 2025-12-08T14:41:17.029Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
flightservice   | 2025-12-08T14:41:17.030Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
flightservice   | 2025-12-08T14:41:17.030Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
flightservice   | 2025-12-08T14:41:17.030Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Application is null : false
flightservice   | 2025-12-08T14:41:17.030Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
flightservice   | 2025-12-08T14:41:17.030Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
flightservice   | 2025-12-08T14:41:17.031Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-08T14:41:17.209Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
bookingservice  | 2025-12-08T14:41:17.210Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
bookingservice  | 2025-12-08T14:41:17.211Z  INFO 1 --- [BookingService] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
bookingservice  | 2025-12-08T14:41:17.213Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765204877212 with initial instances count: 0
bookingservice  | 2025-12-08T14:41:17.223Z  INFO 1 --- [BookingService] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application BOOKINGSERVICE with eureka with status UP
bookingservice  | 2025-12-08T14:41:17.223Z  INFO 1 --- [BookingService] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765204877223, current=UP, previous=STARTING]
bookingservice  | 2025-12-08T14:41:17.225Z  INFO 1 --- [BookingService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/ab1d217cfe84:BookingService:8081: registering service...
bookingservice  | 2025-12-08T14:41:17.242Z  INFO 1 --- [BookingService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8081 (http) with context path '/'
bookingservice  | 2025-12-08T14:41:17.243Z  INFO 1 --- [BookingService] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8081
flightservice   | 2025-12-08T14:41:17.244Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : The response status is 200
flightservice   | 2025-12-08T14:41:17.246Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
flightservice   | 2025-12-08T14:41:17.247Z  INFO 1 --- [FlightService] [           main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
flightservice   | 2025-12-08T14:41:17.249Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1765204877248 with initial instances count: 0
bookingservice  | 2025-12-08T14:41:17.257Z  INFO 1 --- [BookingService] [           main] o.e.b.BookingServiceApplication          : Started BookingServiceApplication in 19.236 seconds (process running for 20.516)
flightservice   | 2025-12-08T14:41:17.265Z  INFO 1 --- [FlightService] [           main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application FLIGHTSERVICE with eureka with status UP
flightservice   | 2025-12-08T14:41:17.266Z  INFO 1 --- [FlightService] [           main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1765204877266, current=UP, previous=STARTING]
flightservice   | 2025-12-08T14:41:17.268Z  INFO 1 --- [FlightService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/3d2705fda27c:FlightService:8080: registering service...
eureka          | 2025-12-08T14:41:17.268Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-1] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BOOKINGSERVICE/ab1d217cfe84:BookingService:8081 with status UP (replication=false)
bookingservice  | 2025-12-08T14:41:17.270Z  INFO 1 --- [BookingService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_BOOKINGSERVICE/ab1d217cfe84:BookingService:8081 - registration status: 204
flightservice   | 2025-12-08T14:41:17.280Z  INFO 1 --- [FlightService] [           main] o.s.boot.tomcat.TomcatWebServer          : Tomcat started on port 8080 (http) with context path '/'
flightservice   | 2025-12-08T14:41:17.281Z  INFO 1 --- [FlightService] [           main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 8080
flightservice   | 2025-12-08T14:41:17.298Z  INFO 1 --- [FlightService] [           main] o.e.f.FlightServiceApplication           : Started FlightServiceApplication in 19.448 seconds (process running for 20.586)
eureka          | 2025-12-08T14:41:17.310Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-2] c.n.e.registry.AbstractInstanceRegistry  : Registered instance FLIGHTSERVICE/3d2705fda27c:FlightService:8080 with status UP (replication=false)
flightservice   | 2025-12-08T14:41:17.312Z  INFO 1 --- [FlightService] [foReplicator-%d] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_FLIGHTSERVICE/3d2705fda27c:FlightService:8080 - registration status: 204
eureka          | 2025-12-08T14:41:17.774Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-3] c.n.e.registry.AbstractInstanceRegistry  : Registered instance BOOKINGSERVICE/ab1d217cfe84:BookingService:8081 with status UP (replication=true)
eureka          | 2025-12-08T14:41:17.774Z  INFO 1 --- [ServiceRegistry] [nio-8761-exec-3] c.n.e.registry.AbstractInstanceRegistry  : Registered instance FLIGHTSERVICE/3d2705fda27c:FlightService:8080 with status UP (replication=true)
kafkaQueue      | [2025-12-08 14:41:19,784] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Stabilized group email-service-group generation 1 with 3 members. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice    | 2025-12-08T14:41:19.785Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-email-service-group-1-3635d652-e0bf-44bf-96a1-b74d4c9631fd', protocol='range'}
emailservice    | 2025-12-08T14:41:19.785Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-email-service-group-3-fac08d3c-8e9f-4812-9bf4-3c31069d5272', protocol='range'}
emailservice    | 2025-12-08T14:41:19.785Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Successfully joined group with generation Generation{generationId=1, memberId='consumer-email-service-group-2-3058da23-c3d1-468f-a71b-17dc5763ffc6', protocol='range'}
emailservice    | 2025-12-08T14:41:19.794Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Finished assignment for group at generation 1: {consumer-email-service-group-1-3635d652-e0bf-44bf-96a1-b74d4c9631fd=Assignment(partitions=[ticket.cancelled-0]), consumer-email-service-group-3-fac08d3c-8e9f-4812-9bf4-3c31069d5272=Assignment(partitions=[ticket.booked-0]), consumer-email-service-group-2-3058da23-c3d1-468f-a71b-17dc5763ffc6=Assignment(partitions=[schedule.added-0])}
kafkaQueue      | [2025-12-08 14:41:19,797] INFO [GroupCoordinator id=1 topic=__consumer_offsets partition=46] Assignment received from leader consumer-email-service-group-3-fac08d3c-8e9f-4812-9bf4-3c31069d5272 for group email-service-group for generation 1. The group has 3 members, 0 of which are static. (org.apache.kafka.coordinator.group.GroupMetadataManager)
emailservice    | 2025-12-08T14:41:19.805Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-email-service-group-1-3635d652-e0bf-44bf-96a1-b74d4c9631fd', protocol='range'}
emailservice    | 2025-12-08T14:41:19.805Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-email-service-group-2-3058da23-c3d1-468f-a71b-17dc5763ffc6', protocol='range'}
emailservice    | 2025-12-08T14:41:19.805Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Successfully synced group in generation Generation{generationId=1, memberId='consumer-email-service-group-3-fac08d3c-8e9f-4812-9bf4-3c31069d5272', protocol='range'}
emailservice    | 2025-12-08T14:41:19.805Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[ticket.cancelled-0])
emailservice    | 2025-12-08T14:41:19.805Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[schedule.added-0])
emailservice    | 2025-12-08T14:41:19.805Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Notifying assignor about the new Assignment(partitions=[ticket.booked-0])
emailservice    | 2025-12-08T14:41:19.807Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Adding newly assigned partitions: [ticket.cancelled-0]
emailservice    | 2025-12-08T14:41:19.807Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Adding newly assigned partitions: [schedule.added-0]
emailservice    | 2025-12-08T14:41:19.807Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] k.c.c.i.ConsumerRebalanceListenerInvoker : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Adding newly assigned partitions: [ticket.booked-0]
emailservice    | 2025-12-08T14:41:19.814Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Found no committed offset for partition ticket.cancelled-0
emailservice    | 2025-12-08T14:41:19.814Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Found no committed offset for partition schedule.added-0
emailservice    | 2025-12-08T14:41:19.814Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Found no committed offset for partition ticket.booked-0
emailservice    | 2025-12-08T14:41:19.817Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Found no committed offset for partition ticket.cancelled-0
emailservice    | 2025-12-08T14:41:19.817Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Found no committed offset for partition ticket.booked-0
emailservice    | 2025-12-08T14:41:19.817Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Found no committed offset for partition schedule.added-0
emailservice    | 2025-12-08T14:41:19.827Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-email-service-group-2, groupId=email-service-group] Resetting offset for partition schedule.added-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=0}}.
emailservice    | 2025-12-08T14:41:19.827Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-email-service-group-3, groupId=email-service-group] Resetting offset for partition ticket.booked-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=0}}.
emailservice    | 2025-12-08T14:41:19.827Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.a.k.c.c.internals.SubscriptionState    : [Consumer clientId=consumer-email-service-group-1, groupId=email-service-group] Resetting offset for partition ticket.cancelled-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[kafkaQueue:9092 (id: 1 rack: null isFenced: false)], epoch=0}}.
emailservice    | 2025-12-08T14:41:19.849Z  INFO 1 --- [EmailService] [ntainer#2-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [ticket.cancelled-0]
emailservice    | 2025-12-08T14:41:19.849Z  INFO 1 --- [EmailService] [ntainer#1-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [ticket.booked-0]
emailservice    | 2025-12-08T14:41:19.849Z  INFO 1 --- [EmailService] [ntainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : email-service-group: partitions assigned: [schedule.added-0]
eureka          | 2025-12-08T14:41:33.179Z  INFO 1 --- [ServiceRegistry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
apigateway      | 2025-12-08T14:41:39.504Z  INFO 1 --- [ApiGateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
apigateway      | 2025-12-08T14:41:39.504Z  INFO 1 --- [ApiGateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
apigateway      | 2025-12-08T14:41:39.504Z  INFO 1 --- [ApiGateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
apigateway      | 2025-12-08T14:41:39.504Z  INFO 1 --- [ApiGateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
apigateway      | 2025-12-08T14:41:39.504Z  INFO 1 --- [ApiGateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
apigateway      | 2025-12-08T14:41:39.504Z  INFO 1 --- [ApiGateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
apigateway      | 2025-12-08T14:41:39.504Z  INFO 1 --- [ApiGateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
apigateway      | 2025-12-08T14:41:39.524Z  INFO 1 --- [ApiGateway] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
emailservice    | 2025-12-08T14:41:40.691Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
emailservice    | 2025-12-08T14:41:40.691Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
emailservice    | 2025-12-08T14:41:40.692Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
emailservice    | 2025-12-08T14:41:40.692Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
emailservice    | 2025-12-08T14:41:40.692Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
emailservice    | 2025-12-08T14:41:40.692Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
emailservice    | 2025-12-08T14:41:40.692Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
emailservice    | 2025-12-08T14:41:40.707Z  INFO 1 --- [EmailService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
authservice     | 2025-12-08T14:41:43.634Z  INFO 1 --- [AuthService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
authservice     | 2025-12-08T14:41:43.634Z  INFO 1 --- [AuthService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
authservice     | 2025-12-08T14:41:43.634Z  INFO 1 --- [AuthService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
authservice     | 2025-12-08T14:41:43.634Z  INFO 1 --- [AuthService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
authservice     | 2025-12-08T14:41:43.634Z  INFO 1 --- [AuthService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
authservice     | 2025-12-08T14:41:43.634Z  INFO 1 --- [AuthService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
authservice     | 2025-12-08T14:41:43.634Z  INFO 1 --- [AuthService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
authservice     | 2025-12-08T14:41:43.652Z  INFO 1 --- [AuthService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
bookingservice  | 2025-12-08T14:41:47.211Z  INFO 1 --- [BookingService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
bookingservice  | 2025-12-08T14:41:47.211Z  INFO 1 --- [BookingService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
bookingservice  | 2025-12-08T14:41:47.211Z  INFO 1 --- [BookingService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
bookingservice  | 2025-12-08T14:41:47.211Z  INFO 1 --- [BookingService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
bookingservice  | 2025-12-08T14:41:47.211Z  INFO 1 --- [BookingService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
bookingservice  | 2025-12-08T14:41:47.211Z  INFO 1 --- [BookingService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
bookingservice  | 2025-12-08T14:41:47.211Z  INFO 1 --- [BookingService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
bookingservice  | 2025-12-08T14:41:47.230Z  INFO 1 --- [BookingService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
flightservice   | 2025-12-08T14:41:47.246Z  INFO 1 --- [FlightService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
flightservice   | 2025-12-08T14:41:47.246Z  INFO 1 --- [FlightService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
flightservice   | 2025-12-08T14:41:47.246Z  INFO 1 --- [FlightService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
flightservice   | 2025-12-08T14:41:47.246Z  INFO 1 --- [FlightService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application is null : false
flightservice   | 2025-12-08T14:41:47.246Z  INFO 1 --- [FlightService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
flightservice   | 2025-12-08T14:41:47.246Z  INFO 1 --- [FlightService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
flightservice   | 2025-12-08T14:41:47.246Z  INFO 1 --- [FlightService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
flightservice   | 2025-12-08T14:41:47.263Z  INFO 1 --- [FlightService] [reshExecutor-%d] com.netflix.discovery.DiscoveryClient    : The response status is 200
flightservice   | 2025-12-08T14:42:00.040Z  INFO 1 --- [FlightService] [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
flightservice   | 2025-12-08T14:42:00.040Z  INFO 1 --- [FlightService] [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
flightservice   | 2025-12-08T14:42:00.042Z  INFO 1 --- [FlightService] [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 2 ms
bookingservice  | 2025-12-08T14:42:08.426Z  INFO 1 --- [BookingService] [nio-8081-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
bookingservice  | 2025-12-08T14:42:08.427Z  INFO 1 --- [BookingService] [nio-8081-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
bookingservice  | 2025-12-08T14:42:08.429Z  INFO 1 --- [BookingService] [nio-8081-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 2 ms
eureka          | 2025-12-08T14:42:33.180Z  INFO 1 --- [ServiceRegistry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
eureka          | 2025-12-08T14:43:33.180Z  INFO 1 --- [ServiceRegistry] [a-EvictionTimer] c.n.e.registry.AbstractInstanceRegistry  : Running the evict task with compensationTime 0ms
